<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>Knowledge meets machine learning for smarter decisions, Part 1</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/bmbDwQ0PJ4c/" /><category term="Big Data" /><category term="Machine Learning" /><category term="Python" /><category term="AI/ML" /><category term="business process automation" /><category term="Drools" /><category term="knowledge engineering" /><category term="machine learning model" /><category term="PMML" /><author><name>Donato Marrazzo</name></author><id>https://developers.redhat.com/blog/?p=815627</id><updated>2021-01-14T08:00:15Z</updated><published>2021-01-14T08:00:15Z</published><content type="html">&lt;p&gt;Drools is a popular open source project known for its powerful rules engine. Few users realize that it can also be a gateway to the amazing possibilities of &lt;a href="https://developers.redhat.com/topics/ai-ml"&gt;artificial intelligence&lt;/a&gt;. This two-part article introduces you to using &lt;a href="https://developers.redhat.com/products/red-hat-decision-manager/overview"&gt;Red Hat Decision Manager&lt;/a&gt; and its Drools-based rules engine to combine &lt;a href="https://developers.redhat.com/blog/category/machine-learning/"&gt;machine learning&lt;/a&gt; predictions with deterministic reasoning. In Part 1, we&amp;#8217;ll prepare our machine learning logic. In Part 2, you&amp;#8217;ll learn how to use the machine learning model from a knowledge service.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: Examples in this article are based on Red Hat Decision Manager, but all of the technologies used are open source.&lt;/p&gt; &lt;h2&gt;Machine learning meets knowledge engineering&lt;/h2&gt; &lt;p&gt;Few Red Hat Decision Manager users know about its roots in artificial intelligence (AI), specifically the AI branch of knowledge engineering (also known as knowledge representation and reasoning). This branch aims to solve the problem of how to organize human knowledge so that a computer can treat it. Knowledge engineering uses &lt;i&gt;business rules&lt;/i&gt;, which means a set of knowledge metaphors that subject matter experts can easily understand and use.&lt;/p&gt; &lt;p&gt;The &lt;a target="_blank" rel="nofollow" href="https://www.omg.org/dmn/"&gt;Decision Model and Notation&lt;/a&gt; (DMN) standard recently released a new model and notation for subject matter experts. After years of using different methodologies and tools, we finally have a common language for sharing knowledge representation. A hidden treasure of the DMN is that it makes dealing with machine learning algorithms easier. The connecting link is another well-known standard in data science: The &lt;a target="_blank" rel="nofollow" href="http://dmg.org/pmml/v4-1/GeneralStructure.html"&gt;Predictive Model Markup Language&lt;/a&gt;, or PMML.&lt;/p&gt; &lt;p&gt;Using these tools to connect knowledge engineering and machine learning empowers both domains, so that the whole is greater than the sum of its parts. It opens up a wide range of use cases where combining deterministic knowledge and data science predictions leads to smarter decisions.&lt;/p&gt; &lt;h2&gt;A use case for cooperation&lt;/h2&gt; &lt;p&gt;The idea of algorithms that can learn from large sets of data and understand patterns that we humans cannot see is fascinating. However, overconfidence in machine learning technology leads us to underestimate the value of human knowledge.&lt;/p&gt; &lt;p&gt;Let’s take an example from our daily experience: We are all used to algorithms that use our internet browsing history to show us ads for products we&amp;#8217;ve already purchased. This happens because it’s quite difficult to train a machine learning algorithm to exclude ads for previously purchased products.&lt;/p&gt; &lt;p&gt;What is a difficult problem for machine learning is very easy for knowledge engineering to solve. On the flip side, encoding all possible relationships between searched words and suggested products is extremely tedious. In this realm, machine learning complements knowledge engineering.&lt;/p&gt; &lt;p&gt;Artificial intelligence has many branches—machine learning, knowledge engineering, search optimization, natural language processing, and more. Why not use more than one technique to achieve more intelligent behavior?&lt;/p&gt; &lt;h2&gt;Artificial intelligence, machine learning, and data science&lt;/h2&gt; &lt;p&gt;Artificial intelligence, machine learning, and data science are often used interchangeably. Actually, they are different but overlapping domains. As I already noted, artificial intelligence has a broader scope than machine learning. Machine learning is just one facet of artificial intelligence. Similarly, some argue that data science is a facet of artificial intelligence. Others say the opposite, that data science includes AI.&lt;/p&gt; &lt;p&gt;In the field, data scientists and AI experts offer different kinds of expertise with some overlap. Data science uses many machine learning algorithms, but not all of them. The Venn diagram in Figure 1 shows the spaces where artificial intelligence, machine learning, and data science overlap.&lt;/p&gt; &lt;div id="attachment_815637" style="width: 582px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa25e53ede08.png"&gt;&lt;img aria-describedby="caption-attachment-815637" class="wp-image-815637 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa25e53ede08.png" alt="Artificial intelligence and data science overlap. Machine learning is a subset of artificial intelligence that overlaps with data science." width="572" height="364" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa25e53ede08.png 572w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa25e53ede08-300x191.png 300w" sizes="(max-width: 572px) 100vw, 572px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-815637" class="wp-caption-text"&gt;Figure 1: The overlaps between artificial intelligence, machine learning, and data science.&lt;/p&gt;&lt;/div&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: See &lt;a target="_blank" rel="nofollow" href="https://www.mygreatlearning.com/blog/difference-data-science-machine-learning-ai/"&gt;Data Science vs. Machine Learning and Artificial Intelligence&lt;/a&gt; for more about each of these technology domains and the spaces where they meet.&lt;/p&gt; &lt;h2&gt;Craft your own machine learning model&lt;/h2&gt; &lt;p&gt;Data scientists are in charge of defining machine learning models after careful preparation. This section will look at some of the techniques data scientists use to select and tune a machine learning algorithm. The goal is to understand the workflow and learn how to craft a model that can cope with prediction problems.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: To learn more about data science methods and processes, see Wikipedia&amp;#8217;s &lt;a target="_blank" rel="nofollow" href="https://en.m.wikipedia.org/wiki/Cross-industry_standard_process_for_data_mining"&gt;Cross-industry standard process for data mining&lt;/a&gt; (CRISP-DM) page.&lt;/p&gt; &lt;h3&gt;Prepare and train a machine learning algorithm&lt;/h3&gt; &lt;p&gt;The first step for preparing and training a machine learning algorithm is to collect, analyze, and clean the data that we will use. Data preparation is an important phase that significantly impacts the quality of the final outcome. Data scientists use mathematics and statistics for this phase.&lt;/p&gt; &lt;p&gt;For simplicity, let’s say we have a reliable data set based on a manager’s historical decisions in an order-fulfillment process. The manager receives the following information: Product type (examples are phone, printer, and so on), price, urgency, and category. There are two categories: &lt;i&gt;Basic&lt;/i&gt;, for when the product is required employee equipment, and &lt;i&gt;optional&lt;/i&gt;, for when the product is not necessary for the role.&lt;/p&gt; &lt;p&gt;The two decision outcomes are &lt;i&gt;approved&lt;/i&gt; or &lt;i&gt;denied&lt;/i&gt;. Automating this decision will free the manager from a repetitive task and speed up the overall order-fulfillment process.&lt;/p&gt; &lt;p&gt;As a first attempt, we could take the data as-is to train the model. Instead, let&amp;#8217;s introduce a bit of contextual knowledge. In our fictitious organization, the purchasing department has a price-reference table where target prices are defined for all product types. We can use this information to improve the quality of the data. Instead of training our algorithm to focus on the product type, we’ll train it to consider the target price. This way, we won&amp;#8217;t need to re-train the model when the reference price list changes.&lt;/p&gt; &lt;h3&gt;Choosing a machine learning algorithm&lt;/h3&gt; &lt;p&gt;We now have a typical classification problem: Given the incoming data, the algorithm must find a class for those data. In other words, it has to label each data item &lt;i&gt;approved&lt;/i&gt; or &lt;i&gt;denied&lt;/i&gt;. Because we have the manager’s collected responses, we can use a supervised learning method. We only need to choose the correct algorithm. The major machine learning algorithms are:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Linear Regression&lt;/li&gt; &lt;li&gt;Logistic Regression&lt;/li&gt; &lt;li&gt;K-Nearest Neighbors&lt;/li&gt; &lt;li&gt;Support Vector Machines&lt;/li&gt; &lt;li&gt;Decision Trees and Random Forests&lt;/li&gt; &lt;li&gt;Neural Networks&lt;/li&gt; &lt;/ul&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: For more about each of these algorithms, see&lt;br /&gt; &lt;a target="_blank" rel="nofollow" href="https://www.freecodecamp.org/news/a-no-code-intro-to-the-9-most-important-machine-learning-algorithms-today/"&gt;9 Key Machine Learning Algorithms Explained in Plain English&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Except for linear regression, we could apply any of these algorithms to our classification problem. For this use case, we will use a Logistic Regression model. Fortunately, we don&amp;#8217;t need to understand the algorithm&amp;#8217;s implementation details. We can rely on existing tools for implementation.&lt;/p&gt; &lt;h3&gt;Python and scikit-learn&lt;/h3&gt; &lt;p&gt;We will use Python and the &lt;a target="_blank" rel="nofollow" href="https://scikit-learn.org/"&gt;scikit-learn library&lt;/a&gt; to train our Logistic Regression model. We choose Python because it is concise and easy to understand and learn. It is also the de facto standard for data scientists. Many libraries expressly designed for data science are written in Python.&lt;/p&gt; &lt;h2&gt;The example project&lt;/h2&gt; &lt;p&gt;Before we go further, download the &lt;a target="_blank" rel="nofollow" href="https://github.com/dmarrazzo/rhdm-dmn-pmml-order"&gt;project source code here&lt;/a&gt;. Open the &lt;code&gt;python&lt;/code&gt; folder to find the machine training code (&lt;code&gt;ml-training.py&lt;/code&gt;) and the CSV file we&amp;#8217;ll use to train the algorithm.&lt;/p&gt; &lt;p&gt;Even without experience with Python and machine learning, the code is easy to understand and adapt. The program&amp;#8217;s logical steps are:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Initialize the algorithm to train.&lt;/li&gt; &lt;li&gt;Read the available data from a CSV file.&lt;/li&gt; &lt;li&gt;Randomly split the training and test data sets (40% is used for testing).&lt;/li&gt; &lt;li&gt;Train the model.&lt;/li&gt; &lt;li&gt;Test the model against the testing data set.&lt;/li&gt; &lt;li&gt;Print the test results.&lt;/li&gt; &lt;li&gt;Save the trained model in PMML.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;A nice feature of the &lt;code&gt;scikit-learn&lt;/code&gt; library is that its machine learning algorithms expose nearly all the same APIs. You can switch between the available algorithms by changing one line of code. This means you can easily benchmark different algorithms for accuracy and decide which one best fits your use case. This type of benchmarking is common because it&amp;#8217;s often hard to know in advance which algorithm will perform better for a use case.&lt;/p&gt; &lt;h3&gt;Run the program&lt;/h3&gt; &lt;p&gt;If you run the Python program, you should see results similar to the following, but not exactly the same. The training and test data are randomly selected so that the results will differ each time. The point is to verify that the algorithm works consistently across multiple executions.&lt;/p&gt; &lt;pre&gt;Results for model LogisticRegression Correct: 1522 Incorrect: 78 Accuracy: 95.12% True Positive Rate: 93.35% True Negative Rate: 97.10% &lt;/pre&gt; &lt;p&gt;The results are quite accurate, at 95%. More importantly, the True Negative Rate (measuring specificity) is very high, at 97.1%. In general, there is a tradeoff between the True Negative Rate and True Positive Rate, which measures sensitivity. Intuitively, you can liken the prediction sensitivity to a car alarm: If we increase an alarm&amp;#8217;s sensitivity, it is more likely to go off by mistake and increase the number of false positives. The increase in false positives lowers specificity.&lt;/p&gt; &lt;h3&gt;Tune the algorithm&lt;/h3&gt; &lt;p&gt;In this particular use case, of approving or rejecting a product order, we would reject the order. Manual approval is better than having too many false positives, which would lead to wrongly approved orders. To improve our results, we can adjust the logistic regression to reduce the prediction sensitivity.&lt;/p&gt; &lt;p&gt;Predictive machine learning models are also known as &lt;i&gt;classification&lt;/i&gt; algorithms because they place an input dataset in a specific class. In our case, we have two classes:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&amp;#8220;true&amp;#8221; to approve the order.&lt;/li&gt; &lt;li&gt;&amp;#8220;false&amp;#8221; to refuse it.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;To reduce the likelihood of a false positive, we can tune the &amp;#8220;true&amp;#8221; class weight (note that 1 is the default):&lt;/p&gt; &lt;pre&gt;model = LogisticRegression(class_weight ={    "true" : .6,    "false" : 1 }) &lt;/pre&gt; &lt;h3&gt;Store the model in a PMML file&lt;/h3&gt; &lt;p&gt;Python is handy for analysis, but we might prefer another language or product for running a machine learning model in production. Reasons include better performance and integration with the enterprise ecosystem.&lt;/p&gt; &lt;p&gt;What we need is a way to exchange machine learning model definitions between different software. The PMML format is commonly used for this purpose. The DMN specification includes a direct reference to a PMML model, which makes this option straightforward.&lt;/p&gt; &lt;p&gt;You should make a couple of changes to the PMML file before importing it to the DMN editor. First, you might need to change the Python PMML version tag to 4.3, which is the version supported by Decision Manager 7.7 (the current version as of this writing):&lt;/p&gt; &lt;pre&gt;&amp;#60;PMML version="4.3" xmlns="http://www.dmg.org/PMML-4_3" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"&amp;#62; &lt;/pre&gt; &lt;p&gt;Next, you want to be able to easily identify the predictive model from the DMN modeler. Use the &lt;code&gt;modelName&lt;/code&gt; attribute to name your model:&lt;/p&gt; &lt;pre&gt;&amp;#60;RegressionModel modelName="approvalRegression" functionName="classification" normalizationMethod="logit"&amp;#62; &lt;/pre&gt; &lt;p&gt;The diagram in Figure 2 shows where we are currently with this project.&lt;/p&gt; &lt;div id="attachment_815657" style="width: 447px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa25ef15607b.png"&gt;&lt;img aria-describedby="caption-attachment-815657" class="wp-image-815657 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa25ef15607b.png" alt="The scikit-learn library requires a training set and an algorithm configuration; the outcome is the PMML model." width="437" height="147" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa25ef15607b.png 437w, https://developers.redhat.com/blog/wp-content/uploads/2020/11/img_5fa25ef15607b-300x101.png 300w" sizes="(max-width: 437px) 100vw, 437px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-815657" class="wp-caption-text"&gt;Figure 2: A usage block diagram for scikit-learn.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;So far, you&amp;#8217;ve seen how to create a machine learning model and store it in a PMML file. In the second half of this article, you will learn more about using PMML to store and transfer machine learning models. You&amp;#8217;ll also discover how to consume a predictive model from a deterministic decision using DMN. Finally, we&amp;#8217;ll review the advantages of creating more cooperation between the deterministic world and the predictive one.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F14%2Fknowledge-meets-machine-learning-for-smarter-decisions-part-1%2F&amp;#38;linkname=Knowledge%20meets%20machine%20learning%20for%20smarter%20decisions%2C%20Part%201" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F14%2Fknowledge-meets-machine-learning-for-smarter-decisions-part-1%2F&amp;#38;linkname=Knowledge%20meets%20machine%20learning%20for%20smarter%20decisions%2C%20Part%201" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F14%2Fknowledge-meets-machine-learning-for-smarter-decisions-part-1%2F&amp;#38;linkname=Knowledge%20meets%20machine%20learning%20for%20smarter%20decisions%2C%20Part%201" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F14%2Fknowledge-meets-machine-learning-for-smarter-decisions-part-1%2F&amp;#38;linkname=Knowledge%20meets%20machine%20learning%20for%20smarter%20decisions%2C%20Part%201" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F14%2Fknowledge-meets-machine-learning-for-smarter-decisions-part-1%2F&amp;#38;linkname=Knowledge%20meets%20machine%20learning%20for%20smarter%20decisions%2C%20Part%201" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F14%2Fknowledge-meets-machine-learning-for-smarter-decisions-part-1%2F&amp;#38;linkname=Knowledge%20meets%20machine%20learning%20for%20smarter%20decisions%2C%20Part%201" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F14%2Fknowledge-meets-machine-learning-for-smarter-decisions-part-1%2F&amp;#38;linkname=Knowledge%20meets%20machine%20learning%20for%20smarter%20decisions%2C%20Part%201" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F14%2Fknowledge-meets-machine-learning-for-smarter-decisions-part-1%2F&amp;#038;title=Knowledge%20meets%20machine%20learning%20for%20smarter%20decisions%2C%20Part%201" data-a2a-url="https://developers.redhat.com/blog/2021/01/14/knowledge-meets-machine-learning-for-smarter-decisions-part-1/" data-a2a-title="Knowledge meets machine learning for smarter decisions, Part 1"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/14/knowledge-meets-machine-learning-for-smarter-decisions-part-1/"&gt;Knowledge meets machine learning for smarter decisions, Part 1&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/bmbDwQ0PJ4c" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Drools is a popular open source project known for its powerful rules engine. Few users realize that it can also be a gateway to the amazing possibilities of artificial intelligence. This two-part article introduces you to using Red Hat Decision Manager and its Drools-based rules engine to combine machine learning predictions with deterministic reasoning. In [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/14/knowledge-meets-machine-learning-for-smarter-decisions-part-1/"&gt;Knowledge meets machine learning for smarter decisions, Part 1&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/01/14/knowledge-meets-machine-learning-for-smarter-decisions-part-1/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">815627</post-id><dc:creator>Donato Marrazzo</dc:creator><dc:date>2021-01-14T08:00:15Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/01/14/knowledge-meets-machine-learning-for-smarter-decisions-part-1/</feedburner:origLink></entry><entry><title type="html">This Week in JBoss: 14 January 2021</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/uaU-OLr54XA/weekly-2021-01-14.html" /><category term="wildfly" /><category term="camel" /><category term="keycloak" /><category term="teiid" /><category term="springboot" /><category term="tekton" /><category term="kubernetes" /><category term="codeready" /><category term="quarkus" /><category term="jgroups" /><author><name>Romain Pelisse</name><uri>https://www.jboss.org/people/romain-pelisse</uri><email>do-not-reply@jboss.com</email></author><id>https://www.jboss.org/posts/weekly-2021-01-14.html</id><updated>2021-01-14T00:00:00Z</updated><content type="html">&lt;article class="" data-tags="wildfly, camel, keycloak, teiid, springboot, tekton, kubernetes, codeready, quarkus, jgroups"&gt; &lt;h1&gt;This Week in JBoss: 14 January 2021&lt;/h1&gt; &lt;p class="preamble"&gt;&lt;/p&gt;&lt;p&gt;Welcome to the first installment of our JBoss Editorial for 2021! And to start the year, we have a brand new major release of the core product of the JBoss community! Yes, Wildfly 22 is out!&lt;/p&gt;&lt;p&gt;&lt;/p&gt; &lt;div class="sect1"&gt; &lt;h2 id="_wildfly_22_and_camel_3_7"&gt;Wildfly 22 and Camel 3.7&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;Yes! We have a brand new major version of Wildfly! &lt;a href="https://www.wildfly.org/news/2021/01/13/WildFly22-Final-Released/"&gt;Wildfly 22 is out!&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;This release includes support for use of log4j2 in applications, new base health and metrics subsystems to provide server observability for users who don’t need the application instrumentation that comes with MicroProfile Health and Metrics, and a number of other features related to management, provisioning, messaging and security. Plus numerous bug fixes, enhancements and component upgrades.&lt;/p&gt; &lt;p&gt;On top of that, there is also an updated version of the new tech-preview WildFly Preview distribution. This will allow the community have a look at what Wildfly developers are doing for Jakarta EE 9 support, along with other changes in the server architecture that are expected to appear later in 2021.&lt;/p&gt; &lt;p&gt;Wildfly 22 is already a nice treat, but we also have &lt;a href="https://camel.apache.org/blog/2020/12/Camel37-Whatsnew/"&gt;Camel 3.7&lt;/a&gt;, which also quite exciting, and fortunately for all of us, Claus Ibsen has published a review of what he called &lt;a href="http://www.davsclaus.com/2020/12/apache-camel-37-lts-released-fastest.html"&gt;the fastest Camel ever!&lt;/a&gt; So, go check it out if you want to know more about this camel release.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_tech_bytes"&gt;Tech bytes&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;A few interesting technical articles came out in the last weeks, so we’ll try to catch you up with three of them here. First, we have an excellent one from Bela Ban on &lt;a href="http://belaban.blogspot.com/2020/12/running-jgroups-raft-as-service.html"&gt;running JGroups raft as a service&lt;/a&gt;. It’s very hands on post, focusing on getting everything running. Then we have a longer walkthrough to let you experiment on &lt;a href="https://blog.ramon-gordillo.dev/2020/12/spring-boot-embedded-cache-with-infinispan-in-kubernetes/"&gt;using Spring boot embedded cache with Infinispan on Kubernetes&lt;/a&gt;. Certainly, worth a look, isn’t it? The last one is, of course, on Quarkus, because Quarkus is, as it should, all the rage lately. In this article, Clément Escoffier took the time to explain some of the &lt;a href="https://quarkus.io/blog/magic-control"&gt;magic beneath Quarkus and Vert.x&lt;/a&gt; and why this is the kind magic you to have as a developer.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_evangelists_corner"&gt;Evangelist’s Corner&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;As always, our very own Eric Schabell has been busy in the few last weeks and released a steady stream of new content. First, he published &lt;a href="https://www.schabell.org/2021/01/codeready-containers-installing.html"&gt;part4 - Installing business automation operator&lt;/a&gt; of his series on CodeReady containers. He then revisited the &lt;a href="https://www.schabell.org/2020/12/codeready-containers-exploring-home-loan-mortgage-process.html"&gt;Home loan mortgage process using CodeReady Containers&lt;/a&gt;. Still on the topic of CodeReady Containers, he provided a &lt;a href="https://www.schabell.org/2021/01/codeready-containers-howto-setup-openshift-46-on-local-machine.html"&gt;How to setup the OpenShift Container Platform 4.6 on your local machine&lt;/a&gt; follow by a tutorial on &lt;a href="https://www.schabell.org/2020/12/codeready-containers-building-hr-process-with-openshift-operator.html"&gt;Building a Human Resources Process with an OpenShift Operator&lt;/a&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_releases_releases_releases"&gt;Releases, releases, releases…​&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;As always, the JBoss community has been quite active in the last weeks, and more than a few project releases new version (including the forementionned Wildfly 22 and Apache Camel 3.7):&lt;/p&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.wildfly.org/news/2021/01/13/WildFly22-Final-Released/"&gt;Wildfly 22 Final released!&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://www.keycloak.org//2020/12/keycloak-1201-released.html"&gt;Keycloak 12.0.1 released&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="https://camel.apache.org/blog/2020/12/Camel37-Whatsnew/"&gt;Apache Camel 3.7&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;&lt;a href="http://teiid.blogspot.com/2021/01/teiid-spring-boot-170-released.html"&gt;Teiid Spring Boot 1.7.0 Released&lt;/a&gt;&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_decaf"&gt;Decaf&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;p&gt;You want to break from Java programming, but still learn something relevant to it? Well, take a look at this article on &lt;a href="https://developers.redhat.com/blog/2021/01/13/getting-started-with-tekton-and-pipelines/"&gt;Getting started with Tekton and Pipelines&lt;/a&gt;. It’s more than likely to pique your interest.&lt;/p&gt; &lt;p&gt;&lt;em&gt;That’s all for today! Please join us again in two weeks for another installment of our JBoss editorial! Stay safe and healthy in the meantime.&lt;/em&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="author"&gt; &lt;pfe-avatar pfe-shape="circle" pfe-pattern="squares" pfe-src="/img/people/romain-pelisse.png"&gt;&lt;/pfe-avatar&gt; &lt;span&gt;Romain Pelisse&lt;/span&gt; &lt;/div&gt;&lt;/article&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/uaU-OLr54XA" height="1" width="1" alt=""/&gt;</content><dc:creator>Romain Pelisse</dc:creator><feedburner:origLink>https://www.jboss.org/posts/weekly-2021-01-14.html</feedburner:origLink></entry><entry><title>Getting started with Tekton and Pipelines</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Epbp7VHsb-o/" /><category term="CI/CD" /><category term="Kubernetes" /><category term="Microservices" /><category term="Serverless" /><category term="Continuous Integration" /><category term="kubectl" /><category term="minikube" /><category term="openshift" /><category term="Tekton" /><author><name>Cedric Clyburn</name></author><id>https://developers.redhat.com/blog/?p=793097</id><updated>2021-01-13T08:00:28Z</updated><published>2021-01-13T08:00:28Z</published><content type="html">&lt;p&gt;Tekton is a powerful, &lt;a href="https://developers.redhat.com/blog/2020/04/08/why-kubernetes-native-instead-of-cloud-native/"&gt;Kubernetes-native&lt;/a&gt; framework for creating continuous integration and delivery (CI/CD) systems. In this article, we&amp;#8217;ll use real-world examples to show you how to install Tekton, create Tasks, and eventually create our own pipeline.&lt;/p&gt; &lt;h2&gt;What&amp;#8217;s a pipeline?&lt;/h2&gt; &lt;p&gt;Great question! In software development, pipelines are automated processes that drive software through a process of building, testing, and deploying code. Such an efficient process can help minimize human error, as well as maintain consistency in deployment. Since &lt;a href="https://developers.redhat.com/topics/ci-cd"&gt;Tekton&lt;/a&gt; is cloud-native, its pipelines are containerized and don&amp;#8217;t have dependencies on other projects, mitigating potential issues and saving you time.&lt;/p&gt; &lt;div id="attachment_846497" style="width: 634px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-846497" class=" size-full wp-image-846497 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2020/12/pipeline-concepts.png" src="https://developers.redhat.com/blog/wp-content/uploads/2020/12/pipeline-concepts.png" alt="Defining and running a pipeline from pipeline Tasks through PipelineRun TaskRuns, controllers, and pods." width="624" height="195" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/12/pipeline-concepts.png 624w, https://developers.redhat.com/blog/wp-content/uploads/2020/12/pipeline-concepts-300x94.png 300w" sizes="(max-width: 624px) 100vw, 624px" /&gt;&lt;p id="caption-attachment-846497" class="wp-caption-text"&gt;The structure of a pipeline.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;About Tekton&lt;/h2&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/tektoncd/pipeline"&gt;Tekton&lt;/a&gt; is a &lt;a href="https://developers.redhat.com/topics/serverless-architecture"&gt;Knative&lt;/a&gt;-based framework for CI/CD pipelines, but it&amp;#8217;s unique due to its decoupled nature—meaning that one pipeline can be used to deploy to any Kubernetes cluster across multiple hybrid cloud providers. In addition, Tekton stores everything related to a pipeline as &lt;a target="_blank" rel="nofollow" href="https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/"&gt;custom resources&lt;/a&gt; (CRs) within the cluster, allowing pieces to be used across multiple pipelines.&lt;/p&gt; &lt;h2&gt;Installing Tekton&lt;/h2&gt; &lt;p&gt;For this guide, we&amp;#8217;ll assume you&amp;#8217;re using &lt;a target="_blank" rel="nofollow" href="https://kubernetes.io/docs/tasks/tools/install-minikube/"&gt;Minikube&lt;/a&gt; for your Kubernetes cluster, although we&amp;#8217;ve created a &lt;a href="https://developers.redhat.com/courses/middleware/openshift-pipelines"&gt;Katacoda Tekton scenario&lt;/a&gt; if you don&amp;#8217;t have access to Minikube. Once your cluster is running, install the latest version of Tekton by applying the YAML from the &lt;a href="https://github.com/tektoncd/pipeline/releases"&gt;latest release&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;kubectl apply -f https://storage.googleapis.com/tekton-releases/pipeline/previous/v0.16.3/release.yaml&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This command will create a &lt;code&gt;tekton-pipelines&lt;/code&gt; namespace, as well as other resources to finalize your Tekton install. With that namespace in mind, we can easily track the progress of our install using the command below:&lt;/p&gt; &lt;p&gt;&lt;code&gt;kubectl get pods --namespace tekton-pipelines --watch&lt;/code&gt;&lt;/p&gt; &lt;p&gt;Finally, to interact with Tekton through the console, we need to install the Tekton CLI, also known as &lt;code&gt;tkn&lt;/code&gt;. Depending on your operating system, please use the instructions from the &lt;a target="_blank" rel="nofollow" href="https://github.com/tektoncd/cli"&gt;official repository&lt;/a&gt; to install the latest binary executable.&lt;/p&gt; &lt;h2&gt;Optional: Install the tutorial repo&lt;/h2&gt; &lt;p&gt;The &lt;a href="https://developers.redhat.com/openshift"&gt;Red Hat OpenShift&lt;/a&gt; developer advocate team has created a &lt;a target="_blank" rel="nofollow" href="https://github.com/joellord/handson-tekton"&gt;repository&lt;/a&gt; to help you get started and master Tekton concepts. If you&amp;#8217;re interested in seeing more concepts and getting hands-on, feel free to clone our repo to your local directory:&lt;/p&gt; &lt;p&gt;&lt;code&gt;git clone https://github.com/joellord/handson-tekton&lt;/code&gt;&lt;/p&gt; &lt;p&gt;Once you&amp;#8217;ve cloned the tutorial repository, be sure to &lt;code&gt;cd&lt;/code&gt; into the folder with:&lt;/p&gt; &lt;p&gt;&lt;code&gt;cd handson-tekton&lt;/code&gt;&lt;/p&gt; &lt;h2&gt;Creating our first Task&lt;/h2&gt; &lt;p&gt;For our introduction to Tasks, let&amp;#8217;s start off with a simple &amp;#8220;Hello World&amp;#8221; Task. Task resources are essential building block components for creating a Pipeline, and this first Task will allow us to use a &lt;a href="https://developers.redhat.com/blog/category/ubi/"&gt;Red Hat Universal Base Image&lt;/a&gt; and echo a &amp;#8220;Hello World&amp;#8221;. To begin, let&amp;#8217;s open the file &lt;code&gt;01-hello.yaml&lt;/code&gt; in the &lt;code&gt;/demo&lt;/code&gt; folder:&lt;/p&gt; &lt;pre&gt;&lt;span class="pl-ent"&gt;apiVersion&lt;/span&gt;: &lt;span class="pl-s"&gt;tekton.dev/v1beta1&lt;/span&gt; &lt;span class="pl-ent"&gt;kind&lt;/span&gt;: &lt;span class="pl-s"&gt;Task&lt;/span&gt; &lt;span class="pl-ent"&gt;metadata&lt;/span&gt;: &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;hello&lt;/span&gt; &lt;span class="pl-ent"&gt;spec&lt;/span&gt;: &lt;span class="pl-ent"&gt;steps&lt;/span&gt;: - &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;say-hello&lt;/span&gt; &lt;span class="pl-ent"&gt;image&lt;/span&gt;: &lt;span class="pl-s"&gt;registry.access.redhat.com/ubi8/ubi&lt;/span&gt; &lt;span class="pl-ent"&gt;command&lt;/span&gt;: - &lt;span class="pl-s"&gt;/bin/bash&lt;/span&gt; &lt;span class="pl-ent"&gt;args&lt;/span&gt;: &lt;span class="pl-s"&gt;['-c', 'echo Hello World']&lt;/span&gt;&lt;/pre&gt; &lt;p&gt;You&amp;#8217;ll notice several details above, from the &lt;code&gt;kind&lt;/code&gt; being a Task, to the &lt;code&gt;step&lt;/code&gt; of &amp;#8220;say-hello&amp;#8221;, and the &lt;code&gt;args&lt;/code&gt; being to simply output an &lt;code&gt;echo&lt;/code&gt; command to the console. Let&amp;#8217;s apply this Task to our cluster, similar to any other Kubernetes object:&lt;/p&gt; &lt;p&gt;&lt;code&gt;kubectl apply -f ./demo/01-hello.yaml&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;tkn task start --showlog hello&lt;/code&gt;&lt;/p&gt; &lt;p&gt;Great work! After running this &lt;code&gt;tkn&lt;/code&gt; command, you&amp;#8217;ll soon see an output from the Task in the console like such:&lt;/p&gt; &lt;pre&gt;TaskRun started: hello-run-6cgf5 Waiting for logs to be available... [say-hello] Hello World&lt;/pre&gt; &lt;h2&gt;Adding parameters to a task&lt;/h2&gt; &lt;p&gt;An important feature of Tasks is the ability to take in and pass parameters. If you&amp;#8217;re looking to build out various Pipelines, parameters, or &lt;code&gt;params&lt;/code&gt;, are instrumental. These properties are constructed of a &lt;code&gt;name&lt;/code&gt; and &lt;code&gt;type&lt;/code&gt;, but can also accept a &lt;code&gt;description&lt;/code&gt; and &lt;code&gt;default&lt;/code&gt; value. To take a better look at how parameters work, let&amp;#8217;s open up the file &lt;code&gt;02-param.yaml&lt;/code&gt; in the &lt;code&gt;/demo&lt;/code&gt; folder:&lt;/p&gt; &lt;pre&gt;&lt;span class="pl-ent"&gt;apiVersion&lt;/span&gt;: &lt;span class="pl-s"&gt;tekton.dev/v1beta1&lt;/span&gt; &lt;span class="pl-ent"&gt;kind&lt;/span&gt;: &lt;span class="pl-s"&gt;Task&lt;/span&gt; &lt;span class="pl-ent"&gt;metadata&lt;/span&gt;: &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;hello&lt;/span&gt; &lt;span class="pl-ent"&gt;spec&lt;/span&gt;: &lt;span class="pl-ent"&gt;params&lt;/span&gt;: - &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;person&lt;/span&gt; &lt;span class="pl-ent"&gt;description&lt;/span&gt;: &lt;span class="pl-s"&gt;Name of person to greet&lt;/span&gt; &lt;span class="pl-ent"&gt;default&lt;/span&gt;: &lt;span class="pl-s"&gt;World&lt;/span&gt; &lt;span class="pl-ent"&gt;type&lt;/span&gt;: &lt;span class="pl-s"&gt;string&lt;/span&gt; &lt;span class="pl-ent"&gt;steps&lt;/span&gt;: - &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;say-hello&lt;/span&gt; &lt;span class="pl-ent"&gt;image&lt;/span&gt;: &lt;span class="pl-s"&gt;registry.access.redhat.com/ubi8/ubi&lt;/span&gt; &lt;span class="pl-ent"&gt;command&lt;/span&gt;: - &lt;span class="pl-s"&gt;/bin/bash&lt;/span&gt; &lt;span class="pl-ent"&gt;args&lt;/span&gt;: &lt;span class="pl-s"&gt;['-c', 'echo Hello $(params.person)']&lt;/span&gt;&lt;/pre&gt; &lt;p&gt;Building from our &amp;#8220;Hello World&amp;#8221; example, we&amp;#8217;ve added in a &lt;code&gt;person&lt;/code&gt; parameter with generic values. In addition, to access the new param, we can call it using &lt;code&gt;$(params.person)&lt;/code&gt;. In order to run this new Task, we can add it to our cluster and run the Task with the following command:&lt;/p&gt; &lt;p&gt;&lt;code&gt;kubectl apply -f ./demo/02-param.yaml&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;tkn task start --showlog hello&lt;/code&gt;&lt;/p&gt; &lt;p&gt;Looks good! Now, it looks as if the console is asking for us to specify the parameter in the command line, similar to below:&lt;/p&gt; &lt;pre&gt;? Value for param `person` of type `string`? (Default is `World`) Cedric TaskRun started: hello-run-z4gsw Waiting for logs to be available... [say-hello] Hello Cedric&lt;/pre&gt; &lt;h2&gt;Creating a Pipeline&lt;/h2&gt; &lt;p&gt;Now that you understand Tasks and parameters, let&amp;#8217;s dive into creating a Pipeline. For consistency, Tasks are meant for single actions, while a Pipeline is a series of Tasks that can be run either in parallel or sequentially. For this example, we&amp;#8217;ll use the &lt;code&gt;04-tasks.yaml&lt;/code&gt; file in the &lt;code&gt;/demo&lt;/code&gt; folder for our Pipeline:&lt;/p&gt; &lt;pre&gt;&lt;span class="pl-ent"&gt;apiVersion&lt;/span&gt;: &lt;span class="pl-s"&gt;tekton.dev/v1beta1&lt;/span&gt; &lt;span class="pl-ent"&gt;kind&lt;/span&gt;: &lt;span class="pl-s"&gt;Task&lt;/span&gt; &lt;span class="pl-ent"&gt;metadata&lt;/span&gt;: &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;say-something&lt;/span&gt; &lt;span class="pl-ent"&gt;spec&lt;/span&gt;: &lt;span class="pl-ent"&gt;params&lt;/span&gt;: - &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;say-what&lt;/span&gt; &lt;span class="pl-ent"&gt;description&lt;/span&gt;: &lt;span class="pl-s"&gt;What should I say&lt;/span&gt; &lt;span class="pl-ent"&gt;default&lt;/span&gt;: &lt;span class="pl-s"&gt;hello&lt;/span&gt; &lt;span class="pl-ent"&gt;type&lt;/span&gt;: &lt;span class="pl-s"&gt;string&lt;/span&gt; - &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;pause-duration&lt;/span&gt; &lt;span class="pl-ent"&gt;description&lt;/span&gt;: &lt;span class="pl-s"&gt;How long to wait before saying something&lt;/span&gt; &lt;span class="pl-ent"&gt;default&lt;/span&gt;: &lt;span class="pl-c1"&gt;0&lt;/span&gt; &lt;span class="pl-ent"&gt;type&lt;/span&gt;: &lt;span class="pl-s"&gt;string&lt;/span&gt; &lt;span class="pl-ent"&gt;steps&lt;/span&gt;: - &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;say-it&lt;/span&gt; &lt;span class="pl-ent"&gt;image&lt;/span&gt;: &lt;span class="pl-s"&gt;registry.access.redhat.com/ubi8/ubi&lt;/span&gt; &lt;span class="pl-ent"&gt;command&lt;/span&gt;: - &lt;span class="pl-s"&gt;/bin/bash&lt;/span&gt; &lt;span class="pl-ent"&gt;args&lt;/span&gt;: &lt;span class="pl-s"&gt;['-c', 'sleep $(params.pause-duration) &amp;#38;&amp;#38; echo $(params.say-what)']&lt;/span&gt;&lt;/pre&gt; &lt;p&gt;With this generic Task file, which will &lt;code&gt;echo&lt;/code&gt; whatever it receives in its parameters, we can build our first Pipeline. With the &lt;code&gt;05-pipeline.yaml&lt;/code&gt; file in the &lt;code&gt;/demo&lt;/code&gt; folder, we can manipulate the &lt;code&gt;04-tasks.yaml&lt;/code&gt; Task twice, with different outputs:&lt;/p&gt; &lt;pre&gt;apiVersion: tekton.dev/v1beta1 kind: Pipeline metadata: name: say-things spec: tasks: - name: first-task params: - name: pause-duration value: "2" - name: say-what value: "Hello, this is the first task" taskRef: name: say-something - name: second-task params: - name: say-what value: "And this is the second task" taskRef: name: say-something&lt;/pre&gt; &lt;p&gt;We&amp;#8217;re now ready to apply the generic Task and the new Pipeline to our cluster, and officially start the Pipeline. Using &lt;code&gt;tkn pipeline start&lt;/code&gt;, we create a &lt;code&gt;PipelineRun&lt;/code&gt; resource automatically with a random name:&lt;/p&gt; &lt;p&gt;&lt;code&gt;kubectl apply -f ./demo/04-tasks.yaml&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;kubectl apply -f ./demo/05-pipeline.yaml&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;tkn pipeline start say-things --showlog&lt;/code&gt;&lt;/p&gt; &lt;p&gt;Congrats! You&amp;#8217;ll notice the console has to output the logs from the &lt;code&gt;PipelineRun.&lt;/code&gt; However, the order seems to be confused.&lt;/p&gt; &lt;pre&gt;PipelineRun started: say-things-run-ncfsq Waiting for logs to be available... [second-task : say-it] And this is the second task [first-task : say-it] Hello, this is the first task&lt;/pre&gt; &lt;p&gt;You&amp;#8217;ll notice that the first task seems to happen after the second task, and this is due to Tekton naturally running all the tasks simultaneously.&lt;/p&gt; &lt;h2&gt;Run in parallel or sequentially&lt;/h2&gt; &lt;p&gt;For Tasks to run in a specific order, the &lt;code&gt;runAfter&lt;/code&gt; parameter is needed in the task definition of your Pipeline. Let&amp;#8217;s open up the &lt;code&gt;06-pipeline-order.yaml&lt;/code&gt; file in the &lt;code&gt;/demo&lt;/code&gt; folder:&lt;/p&gt; &lt;pre&gt;&lt;span class="pl-ent"&gt;apiVersion&lt;/span&gt;: &lt;span class="pl-s"&gt;tekton.dev/v1beta1&lt;/span&gt; &lt;span class="pl-ent"&gt;kind&lt;/span&gt;: &lt;span class="pl-s"&gt;Pipeline&lt;/span&gt; &lt;span class="pl-ent"&gt;metadata&lt;/span&gt;: &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;say-things-in-order&lt;/span&gt; &lt;span class="pl-ent"&gt;spec&lt;/span&gt;: &lt;span class="pl-ent"&gt;tasks&lt;/span&gt;: - &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;first-task&lt;/span&gt; &lt;span class="pl-ent"&gt;params&lt;/span&gt;: - &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;pause-duration&lt;/span&gt; &lt;span class="pl-ent"&gt;value&lt;/span&gt;: &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;2&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; - &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;say-what&lt;/span&gt; &lt;span class="pl-ent"&gt;value&lt;/span&gt;: &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Hello, this is the first task&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-ent"&gt;taskRef&lt;/span&gt;: &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;say-something&lt;/span&gt; - &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;second-task&lt;/span&gt; &lt;span class="pl-ent"&gt;params&lt;/span&gt;: - &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;say-what&lt;/span&gt; &lt;span class="pl-ent"&gt;value&lt;/span&gt;: &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Happening after task 1, in parallel with task 3&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; - &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;pause-duration&lt;/span&gt; &lt;span class="pl-ent"&gt;value&lt;/span&gt;: &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;2&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-ent"&gt;taskRef&lt;/span&gt;: &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;say-something&lt;/span&gt; &lt;span class="pl-ent"&gt;runAfter&lt;/span&gt;: - &lt;span class="pl-s"&gt;first-task&lt;/span&gt; - &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;third-task&lt;/span&gt; &lt;span class="pl-ent"&gt;params&lt;/span&gt;: - &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;say-what&lt;/span&gt; &lt;span class="pl-ent"&gt;value&lt;/span&gt;: &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Happening after task 1, in parallel with task 2&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; - &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;pause-duration&lt;/span&gt; &lt;span class="pl-ent"&gt;value&lt;/span&gt;: &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;1&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-ent"&gt;taskRef&lt;/span&gt;: &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;say-something&lt;/span&gt; &lt;span class="pl-ent"&gt;runAfter&lt;/span&gt;: - &lt;span class="pl-s"&gt;first-task&lt;/span&gt; - &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;fourth-task&lt;/span&gt; &lt;span class="pl-ent"&gt;params&lt;/span&gt;: - &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;say-what&lt;/span&gt; &lt;span class="pl-ent"&gt;value&lt;/span&gt;: &lt;span class="pl-s"&gt;&lt;span class="pl-pds"&gt;"&lt;/span&gt;Happening after task 2 and 3&lt;span class="pl-pds"&gt;"&lt;/span&gt;&lt;/span&gt; &lt;span class="pl-ent"&gt;taskRef&lt;/span&gt;: &lt;span class="pl-ent"&gt;name&lt;/span&gt;: &lt;span class="pl-s"&gt;say-something&lt;/span&gt; &lt;span class="pl-ent"&gt;runAfter&lt;/span&gt;: - &lt;span class="pl-s"&gt;second-task&lt;/span&gt; - &lt;span class="pl-s"&gt;third-task&lt;/span&gt;&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;runAfter&lt;/code&gt; parameter is being applied to specific numbered tasks, and after applying this Pipeline to our cluster, we&amp;#8217;ll be able to see logs from each task, but ordered:&lt;/p&gt; &lt;p&gt;&lt;code&gt;kubectl apply -f ./demo/06-pipeline-order.yaml&lt;/code&gt;&lt;/p&gt; &lt;p&gt;&lt;code&gt;tkn pipeline start say-things-in-order --showlog&lt;/code&gt;&lt;/p&gt; &lt;p&gt;After running &lt;code&gt;tkn&lt;/code&gt;, your CLI output should be similar to this example:&lt;/p&gt; &lt;pre&gt;PipelineRun started: say-things-in-order-run-5dklz Waiting for logs to be available... [first-task : say-it] Hello, this is the first task [second-task : say-it] Happening after task 1, in parallel with task 3 [third-task : say-it] Happening after task 1, in parallel with task 2 [fourth-task : say-it] Happening after task 2 and 3&lt;/pre&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;Feel free to &lt;a target="_blank" rel="nofollow" href="https://github.com/joellord/handson-tekton"&gt;continue the demo here&lt;/a&gt;, and try out our &lt;a href="https://developers.redhat.com/courses/middleware/openshift-pipelines"&gt;guided Katacoda scenario here&lt;/a&gt; as well, which offers an interactive environment right in your browser.&lt;/p&gt; &lt;p&gt;For more interactive demonstrations of many of the examples you&amp;#8217;ve seen here, check out our video!&lt;/p&gt; &lt;p&gt;&lt;iframe class='youtube-player' type='text/html' width='640' height='360' src='https://www.youtube.com/embed/pEmyyrjLrBE?version=3&amp;#038;rel=1&amp;#038;fs=1&amp;#038;autohide=2&amp;#038;showsearch=0&amp;#038;showinfo=1&amp;#038;iv_load_policy=1&amp;#038;wmode=transparent' allowfullscreen='true' style='border:0;'&gt;&lt;/iframe&gt;&lt;/p&gt; &lt;h2&gt;Resources&lt;/h2&gt; &lt;p&gt;If you want to keep learning about Tekton, start with these articles on Red Hat Developer:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2020/08/14/introduction-to-cloud-native-ci-cd-with-tekton-kubecon-europe-2020/"&gt;Introduction to cloud-native CI/CD with Tekton&lt;/a&gt; (Jan Kleinert &amp;#38; Joel Lord)&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2020/01/08/the-new-tekton-pipelines-extension-for-visual-studio-code/"&gt;The new Tekton Pipelines extension for Visual Studio Code&lt;/a&gt; (Denis Golovin &amp;#38; Lindsey Tulloch)&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2020/04/30/creating-pipelines-with-openshift-4-4s-new-pipeline-builder-and-tekton-pipelines/"&gt;Creating Pipelines with OpenShift 4.4’s new Pipeline Builder and Tekton Pipelines&lt;/a&gt; (Joel Lord)&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F13%2Fgetting-started-with-tekton-and-pipelines%2F&amp;#38;linkname=Getting%20started%20with%20Tekton%20and%20Pipelines" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F13%2Fgetting-started-with-tekton-and-pipelines%2F&amp;#38;linkname=Getting%20started%20with%20Tekton%20and%20Pipelines" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F13%2Fgetting-started-with-tekton-and-pipelines%2F&amp;#38;linkname=Getting%20started%20with%20Tekton%20and%20Pipelines" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F13%2Fgetting-started-with-tekton-and-pipelines%2F&amp;#38;linkname=Getting%20started%20with%20Tekton%20and%20Pipelines" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F13%2Fgetting-started-with-tekton-and-pipelines%2F&amp;#38;linkname=Getting%20started%20with%20Tekton%20and%20Pipelines" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F13%2Fgetting-started-with-tekton-and-pipelines%2F&amp;#38;linkname=Getting%20started%20with%20Tekton%20and%20Pipelines" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F13%2Fgetting-started-with-tekton-and-pipelines%2F&amp;#38;linkname=Getting%20started%20with%20Tekton%20and%20Pipelines" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F13%2Fgetting-started-with-tekton-and-pipelines%2F&amp;#038;title=Getting%20started%20with%20Tekton%20and%20Pipelines" data-a2a-url="https://developers.redhat.com/blog/2021/01/13/getting-started-with-tekton-and-pipelines/" data-a2a-title="Getting started with Tekton and Pipelines"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/13/getting-started-with-tekton-and-pipelines/"&gt;Getting started with Tekton and Pipelines&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Epbp7VHsb-o" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;Tekton is a powerful, Kubernetes-native framework for creating continuous integration and delivery (CI/CD) systems. In this article, we&amp;#8217;ll use real-world examples to show you how to install Tekton, create Tasks, and eventually create our own pipeline. What&amp;#8217;s a pipeline? Great question! In software development, pipelines are automated processes that drive software through a process of [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/13/getting-started-with-tekton-and-pipelines/"&gt;Getting started with Tekton and Pipelines&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/01/13/getting-started-with-tekton-and-pipelines/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">2</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">793097</post-id><dc:creator>Cedric Clyburn</dc:creator><dc:date>2021-01-13T08:00:28Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/01/13/getting-started-with-tekton-and-pipelines/</feedburner:origLink></entry><entry><title type="html">WildFly 22 is released!</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/YrzhXaPcNgs/" /><author><name>Brian Stansberry</name></author><id>https://wildfly.org//news/2021/01/13/WildFly22-Final-Released/</id><updated>2021-01-13T00:00:00Z</updated><content type="html">I’m pleased to announce that the WildFly 22 Final zip is now available . Let’s have a look at what’s new. NEW FEATURES LOGGING * In response to a great deal of user demand, WildFly has added . Applications deployed in the server can use the log4j2 API which will delegate to the JBoss Log Manager. PROVISIONING AND MANAGING WILDFLY * It is now possible to use a to into your WildFly installation, instead of having to unzip content manually into your installation and update your config using the CLI. These Keycloak adapters allow you to secure deployments using OpenID Connect. * A new is available. Use it to provision the Distributable Web subsystem configured with a local web container cache. * New and subsystems are available. These provide a foundation for updated versions of the corresponding 'microprofile-health-smallrye' and 'microprofile-metrics-smallrye' subsystems. They also allow users who don’t need the custom deployment-specific health and metrics information provided by Eclipse MicroProfile Health and Metrics to still get general server health and metrics information via the management endpoint without needing to include the MicroProfile Health and Metrics libraries in their server installation. This is discussed further in the Feature Pack Changes section below. * If the --read-only-server-config startup param is used, the server will now run . This allows non-writable storage to be mounted as the configuration directory. * The high-level CLI command command has been enhanced to . MESSAGING * The management API can now be used to thus stopping all the subscribers from receiving new messages from a paused topic. * In order to help mitigate the possibility of split brain problems ActiveMQ Artemis has the ability to ping a configurable list of hosts to check the health of the broker’s network connection. This Artemis feature can now be . SECURITY * WildFly now provides the ability to . This self-signed certificate should only be used for testing purposes. It should never be used in a production environment. * It is now possible to to convert a principal to upper or lower case. Previously, a custom transformer was required to adjust a principal’s username to upper/lower case. Elytron now provides a principal transformer for this use case. WILDFLY PREVIEW As I when we released WildFly 22 Alpha1, along with our traditional Jakarta EE 8 distribution we want to give our users a preview of what will be coming in WildFly as we move on to EE 9 and later. We call this distribution "WildFly Preview". The WildFly 22.0.0.Final release includes an update to WildFly Preview. Even though this is coming from a .Final tag of the WildFly codebase, WildFly Preview should always be regarded as a tech-preview/beta distribution. EE 9 is primarily about implementing the necessary change in the Jakarta EE APIs from the javax.* package namespace to the jakarta.* namespace. This is a big change that is going to take a while to percolate through the EE ecosystem, e.g. for the many projects that compile against the EE APIs to provide versions that use jakarta.*. While this happens we want to continue to deliver new features and fixes to our community, so the primary WildFly distribution will continue to provide the EE 8 APIs. EE 9 VIA BYTECODE TRANSFORMATION AND THE 'WILDFLY-PREVIEW' GALLEON FEATURE PACK The large majority of the libraries included in WildFly Preview that were compiled against EE APIs were based on the javax.* EE 8 APIs. This includes the libraries produced from WildFly’s own code base and by WildFly Core. But the EE APIs libraries available in the WildFly Preview runtime all use the jakarta.* packages. How can this work? The solution we’ve come up with for this is to provide a new 'wildfly-preview' Galleon feature pack, in addition to the standard 'wildfly' feature pack. (Recall that any WildFly server installation, including the ones that are zipped up and made available for download here, is produced by telling Galleon tooling to provision from a feature pack.) The 'wildfly-preview' feature pack differs from the standard 'wildfly' one in a number of ways, with the key ones relevant to EE 9 being: * Where suitable EE 9 spec API jars were available from Eclipse, those were used instead of the EE 8 spec jars used in standard WildFly. * Where suitable 'native' EE 9 implementation libraries (i.e. ones compiled against jakarta.*) were available, those were used. This includes Weld, Hibernate Validator, Mojarra, Yasson, Jakarta EL and Jakarta JSON. * Any libraries that were using EE 8 APIs were detected and instructions were incorporated in the feature pack telling Galleon to do byte code transformation of that library whenever it provisions a server using the feature pack. The last item is the key point. When Galleon provisions a 'wildfly-preview' server by pulling jars down from maven, it knows that some artifacts were compiled against EE 8 javax.* packages. So it bytecode transforms those jars to alter references to EE 8 packages in the class file constant tables to change from javax.* to jakarta.*. The transformation goes beyond simple package renames; a number of other known differences between EE 8 and EE 9 are handled. Thanks to the project for their work on the underlying transformation tool. You can use the Galleon CLI tool to provision a server from the wildfly-preview feature pack yourself: galleon.sh install wildfly-preview:current --dir=my-wildfly-server Note the use of 'wildfly-preview' instead of 'wildfly'. As Galleon provisions the server it will log quite a bit of information about the transformation work it is doing. Please note that the transformation adds a fair bit to the amount of time it takes to provision the server. WILDFLY PREVIEW SUPPORT FOR EE 8 DEPLOYMENTS The APIs that WildFly Preview exposes to deployments are the EE 9 APIs, so all the classes and interfaces are in the jakarta.* packages. But what if you want to run an existing EE 8 application on WildFly Preview? We expect that to be a very important use case in the long run. Eventually the jakarta.* APIs will be what’s provided by the standard WildFly distribution, but many WildFly users will have existing applications that they’ll want to continue to run unchanged. So we wanted to make sure from the very beginning that that works. What we’ve done is we’ve added to the server’s handling of managed deployments the same basic transformation that’s applied to the server artifacts when provisioning. A managed deployment is one where a management client (the CLI, HAL console or the deployment scanner) presents deployment content to the server and the server makes a copy of it in its internal deployment content repository. The content that gets installed into the runtime is that internal copy. A WildFly Preview server, when it reads in deployment content to store in the content repository, will transform any EE 8 content into EE 9. In the long run I feel it’s better for users if they either convert their application source to EE 9 APIs, or use build-time tooling that we and the rest of the Jakarta community will work to provide to do transformation at build time. But some applications just can’t be changed, so the server-side solution we’re using can handle those cases. FEATURE PACK CHANGES The WildFly server is provisioned using five Galleon feature packs. The composition of these feature packs has changed somewhat in WildFly 22. The five feature packs are: * wildfly-core — provides the functionality provided by the project. * wildfly-servlet — depends on wildfly-core and adds the functionality needed for the "Servlet-Only Distribution" you can find for each WildFly release on the . * wildfly-ee — depends on wildfly-servlet and adds the functionality needed for a full EE appserver, plus other long-standing appserver functionality like clustering support. * wildfly — depends on wildfly-ee and adds Eclipse MicroProfile functionality. This is the feature pack used to provision the standard WildFly distribution found on the , and is the feature pack that we expect most users who provision their own server or bootable jar to use. * wildfly-preview — depends on wildfly-core and adds all other functionality needed for the WildFly Preview distribution. In WildFly 22 we corrected a conceptual problem in WildFly 21 and earlier where the 'wildfly-ee' feature pack was including five MicroProfile specifications: Config, Health, Metrics, OpenTracing and Rest Client. We want the support for the faster moving, more-open-to-breaking-changes MicroProfile specs to only come from the top level 'wildfly' feature pack. So in WildFly 22 we moved that functionality out of 'wildfly-ee' and into 'wildfly'. People only using only 'wildfly-ee' to provision will no longer have access to those specifications. We do want 'wildfly-ee' users to be able to continue to use the WildFly management interface to do server health and readiness checks and to get JVM and container metrics in Prometheus format. To support this we have added new and subsystems to wildfly-ee. These subsystems do not provide any sort of API to deployments; e.g. you can’t use them to provide your own health checks or metrics in your application code. If you want that you should use the 'wildfly' feature pack and the MicroProfile Health and Metrics subsystems. The MicroProfile Health and Metrics subsystems now require the presence in the config of the base health and base metrics subsystems. Users migrating from WildFly 21 or earlier should add these new extensions/subsystems to their configuration. We anticipate further evolution in these feature packs in WildFly 23. In particular, it is likely the 'wildfly-ee' feature pack will no longer depend on 'wildfly-servlet' or transitively on 'wildfly-core'. Instead it will directly provide the content currently provided by those feature packs. STANDARDS SUPPORT WildFly 22.0.0 is a Jakarta EE 8 compatible implementation, with both the Full Platform and the Web Profile. Evidence supporting our certification is available and . WildFly 22 is also a compatible implementation of Java EE 8. WildFly 22 is also a compliant implementation of the Eclipse MicroProfile 3.3 platform specification. The WildFly Preview distribution released today is not yet a compatible implementation of Jakarta EE 9 or MicroProfile 3.3. We’re continuing to make good progress toward being able to certify compatibility, but we’re not there yet. The main area where users may hit meaningful issues related to EE compliance is in webservices if deployment descriptors using the EE 9 xml schemas are used. This can be worked around by using EE 8 schemas, which are functionally equivalent. JDK SUPPORT Our recommendation is that you run WildFly on the most recent long-term support JDK release, i.e. on JDK 11 for WildFly 22. While we do do some testing of WildFly on JDK 12 and 13, we do considerably more testing of WildFly itself on the LTS JDKs, and we make no attempt to ensure the projects producing the various libraries we integrate are testing their libraries on anything other than JDK 8 or 11. WildFly 22 also is heavily tested and runs well on Java 8. We plan to continue to support Java 8 at least through WildFly 23, and probably beyond. While we recommend using an LTS JDK release, I do believe WildFly runs well on JDK 13. By run well, I mean the main WildFly testsuite runs with no more than a few failures in areas not expected to be commonly used. We want developers who are trying to evaluate what a newer JVM means for their applications to be able to look to WildFly as a useful development platform. We do see a couple of test failures with JDK 13 when using the deprecated Picketlink subsystem and WS Trust. Work to allow WildFly to run on JDK 14 and 15 is ongoing. We’re continuing our work to digest fully some of the package removals that came in JDK 14, particularly in the security area. The biggest barrier we face is the deprecated legacy security implementation based on Picketbox cannot support JDK 14. We intend to remove support for that security implementation after WildFly 23 and to only provide Elytron-based security. A lot of behind-the-scenes work to make that possible got accomplished during the WildFly 21 cycle. Please note that WildFly runs on Java 11 and later in classpath mode. DOCUMENTATION The WildFly 22 documentation is available at the . The WildFly 22 management API documentation is in the . JIRA RELEASE NOTES The full list of issues resolved is available . Issues resolved in the WildFly Core 14 releases included with WildFly 22 are available . ENJOY! We hope you enjoy WildFly 22. We’d love to hear your feedback at the . But most important, please stay safe and well!&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/YrzhXaPcNgs" height="1" width="1" alt=""/&gt;</content><dc:creator>Brian Stansberry</dc:creator><feedburner:origLink>https://wildfly.org//news/2021/01/13/WildFly22-Final-Released/</feedburner:origLink></entry><entry><title>Develop Eclipse MicroProfile applications on Red Hat JBoss Enterprise Application Platform XP 2.0</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/cmgVgrBpkwY/" /><category term="Containers" /><category term="DevOps" /><category term="Java" /><category term="Microservices" /><category term="codeready" /><category term="CodeReady Studio" /><category term="jboss" /><category term="MicroProfile" /><category term="MicroProfile Config" /><author><name>Emmanuel Hugonnet</name></author><id>https://developers.redhat.com/blog/?p=850617</id><updated>2021-01-12T08:00:45Z</updated><published>2021-01-12T08:00:45Z</published><content type="html">&lt;p&gt;This article shows you how to install &lt;a href="https://developers.redhat.com/products/eap/overview"&gt;Red Hat JBoss Enterprise Application Platform (JBoss EAP)&lt;/a&gt; XP 2.0.0 GA with support for Eclipse MicroProfile. Once you&amp;#8217;ve enabled Eclipse MicroProfile, you will be able to use its quickstart examples to start developing your own MicroProfile applications with &lt;a href="https://developers.redhat.com/products/codeready-studio/overview"&gt;Red Hat CodeReady Studio&lt;/a&gt;. In this demonstration, you&amp;#8217;ll learn two ways to build and run the &lt;a href="https://developers.redhat.com/cheat-sheets/microprofile-config"&gt;MicroProfile Config&lt;/a&gt; quickstart application.&lt;/p&gt; &lt;h2&gt;Installing JBoss EAP XP 2.0.0 GA&lt;/h2&gt; &lt;p&gt;To install JBoss EAP XP 2.0.0 GA:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Download the following software from the &lt;a href="https://developers.redhat.com/products/eap/download"&gt;product download page&lt;/a&gt;: &lt;ul&gt; &lt;li&gt;JBoss EAP XP 2.0.0 GA manager&lt;/li&gt; &lt;li&gt;JBoss EAP 7.3.4 GA patch&lt;/li&gt; &lt;li&gt;JBoss EAP XP 2.0.0 GA patch&lt;/li&gt; &lt;/ul&gt; &lt;/li&gt; &lt;li&gt;Apply the JBoss EAP 7.3.4 GA patch: &lt;pre&gt;$ patch apply /DOWNLOAD/PATH/jboss-eap-7.3.4-patch.zip &lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Set up the JBoss EAP XP manager: &lt;pre&gt;$ java -jar jboss-eap-xp-2.0.0.GA-manager.jar setup --jboss-home=/INSTALL_PATH/jboss-eap-7.3 &lt;/pre&gt; &lt;/li&gt; &lt;li&gt;Apply the JBoss EAP XP 2.0 patch using the following management command: &lt;pre&gt;$ java -jar jboss-eap-xp-2.0.0.GA-manager.jar patch-apply --jboss-home=/INSTALL_PATH/jboss-eap-7.3 --patch=/DOWNLOAD/PATH/jboss-eap-xp-2.0.0.GA-patch.zip &lt;/pre&gt; &lt;/li&gt; &lt;/ol&gt; &lt;h2&gt;Configuring CodeReady Studio&lt;/h2&gt; &lt;p&gt;To enable Eclipse MicroProfile support on JBoss EAP, we first need to register a runtime server for our newly installed JBoss EAP XP 2.0.0 instance. For this, we will create a new JBoss EAP 7.3 server called Red Hat JBoss EAP 7.3 XP 2.0.&lt;/p&gt; &lt;p&gt;The server will use a new JBoss EAP 7.3 XP 2.0 runtime that points to the runtime that we&amp;#8217;ve just installed. The JBoss EAP 7.3 XP 2.0 runtime uses the &lt;code&gt;standalone-microprofile.xml&lt;/code&gt; configuration file.&lt;/p&gt; &lt;p&gt;Select or enter the following configurations in the &lt;strong&gt;Define a New Server&lt;/strong&gt; dialog, as shown in Figure 1:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Select the server type &lt;b&gt;Red Hat JBoss Enterprise Application Platform 7.3&lt;/b&gt;.&lt;/li&gt; &lt;li&gt;Set the server’s hostname to &lt;b&gt;localhost&lt;/b&gt;.&lt;/li&gt; &lt;li&gt;Enter &lt;b&gt;Red Hat JBoss EAP 7.3 XP 2.0&lt;/b&gt; as the server name.&lt;/li&gt; &lt;li&gt;Click &lt;b&gt;Next&lt;/b&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;div id="attachment_850737" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_1.png"&gt;&lt;img aria-describedby="caption-attachment-850737" class="wp-image-850737 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_1-926x1024.png" alt="Create your new Red Hat JBoss EAP 7.3 XP 2.0 server." width="640" height="708" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_1-926x1024.png 926w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_1-271x300.png 271w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_1-768x849.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_1.png 954w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-850737" class="wp-caption-text"&gt;Figure 1: Define your new server.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;The next screen invites you to create a new server adapter. Keep the defaults and select &lt;strong&gt;Create new runtime&lt;/strong&gt; to continue, as shown in Figure 2.&lt;/p&gt; &lt;div id="attachment_850757" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_2.png"&gt;&lt;img aria-describedby="caption-attachment-850757" class="wp-image-850757 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_2-1019x1024.png" alt="Create a new Server Adapter." width="640" height="643" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_2-1019x1024.png 1019w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_2-150x150.png 150w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_2-300x300.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_2-768x772.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_2.png 1050w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-850757" class="wp-caption-text"&gt;Figure 2: Select &amp;#8216;Create new runtime&amp;#8217; to continue.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;In the next dialog, you will configure your new runtime server. Enter the configurations shown in Figure 3:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Set the home directory if you don’t want to use the default setting.&lt;/li&gt; &lt;li&gt;Make sure your execution environment is set to &lt;b&gt;JavaSE-1.8&lt;/b&gt; (but you can use &lt;b&gt;JavaSE-11&lt;/b&gt;).&lt;/li&gt; &lt;li&gt;Change the settings for the server base directory and configuration file if you don’t want the defaults.&lt;/li&gt; &lt;li&gt;Click &lt;b&gt;Finish&lt;/b&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;div id="attachment_850767" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_3.png"&gt;&lt;img aria-describedby="caption-attachment-850767" class="wp-image-850767 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_3-1024x799.png" alt="An overview of the server's settings." width="640" height="499" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_3-1024x799.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_3-300x234.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_3-768x599.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_3.png 1352w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-850767" class="wp-caption-text"&gt;Figure 3: Configure the server runtime.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Before we can run the MicroProfile quickstarts (see Figure 5), we need to set the environment variables on our runtime. Navigate to the Red Hat JBoss EAP 7.3 XP 2.0 Server Overview dialog and click &lt;b&gt;Open launch configuration&lt;/b&gt;. You will see the option to set the environment variables, as shown in Figure 4.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Set &lt;b&gt;JAEGER_REPORTER_LOG_SPANS&lt;/b&gt; to &lt;b&gt;true&lt;/b&gt;.&lt;/li&gt; &lt;li&gt;Set &lt;b&gt;JAEGER_SAMPLER_PARAM&lt;/b&gt; to &lt;b&gt;1&lt;/b&gt;.&lt;/li&gt; &lt;li&gt;Set &lt;b&gt;JAEGER_SAMPLER_TYPE&lt;/b&gt; to &lt;b&gt;const&lt;/b&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;div id="attachment_850777" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_4.png"&gt;&lt;img aria-describedby="caption-attachment-850777" class="wp-image-850777 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_4-1024x1017.png" alt="The newly defined environment variables." width="640" height="636" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_4-1024x1017.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_4-150x150.png 150w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_4-300x298.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_4-768x762.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-create_server_4.png 1095w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-850777" class="wp-caption-text"&gt;Figure 4: Configure your runtime’s environment variables.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Running the Eclipse MicroProfile quickstarts&lt;/h2&gt; &lt;p&gt;The Eclipse MicroProfile quickstarts offer the following examples, which you can run and test on your installed server:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Eclipse MicroProfile Config&lt;/li&gt; &lt;li&gt;Eclipse MicroProfile Fault-tolerance&lt;/li&gt; &lt;li&gt;Eclipse MicroProfile Health&lt;/li&gt; &lt;li&gt;Eclipse MicroProfile JWT&lt;/li&gt; &lt;li&gt;Eclipse MicroProfile Metrics&lt;/li&gt; &lt;li&gt;Eclipse MicroProfile OpenAPI&lt;/li&gt; &lt;li&gt;Eclipse MicroProfile OpenTracing&lt;/li&gt; &lt;li&gt;Eclipse MicroProfile REST Client&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;To turn on the quickstarts, open your project explorer, then select and import the &lt;code&gt;quickstart-parent&lt;/code&gt; &lt;code&gt;pom.xml&lt;/code&gt;. You will see the list of quickstarts shown in Figure 5.&lt;/p&gt; &lt;div id="attachment_850797" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-projects_5.png"&gt;&lt;img aria-describedby="caption-attachment-850797" class="wp-image-850797 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-projects_5.png" alt="Project Explorer with quickstart-parent selected." width="640" height="643" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-projects_5.png 640w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-projects_5-150x150.png 150w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-projects_5-300x300.png 300w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-850797" class="wp-caption-text"&gt;Figure 5: Importing the quickstart parent turns on quickstarts.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Running the Eclipse MicroProfile Config quickstart&lt;/h2&gt; &lt;p&gt;There are two ways to run the Eclipse MicroProfile Config application: A bare-metal installation of JBoss EAP XP Server or a bootable JAR application. I&amp;#8217;ll show you how to do both.&lt;/p&gt; &lt;h3&gt;Bare-metal installation&lt;/h3&gt; &lt;p&gt;If you are installing &lt;code&gt;microprofile-config&lt;/code&gt; on bare metal, do the following:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Right-click on the &lt;b&gt;microprofile-config&lt;/b&gt; file.&lt;/li&gt; &lt;li&gt;Select &lt;b&gt;Run As&lt;/b&gt;.&lt;/li&gt; &lt;li&gt;Left-click &lt;b&gt;1 Run on Server&lt;/b&gt;.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;This configuration, shown in Figure 6, starts the server with the &lt;code&gt;microprofile-config&lt;/code&gt; application deployed.&lt;/p&gt; &lt;div id="attachment_851147" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-run_on_server_6.png"&gt;&lt;img aria-describedby="caption-attachment-851147" class="wp-image-851147" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-run_on_server_6.png" alt="Selections to run the microprofile-config project on a local server." width="640" height="683" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-run_on_server_6.png 810w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-run_on_server_6-281x300.png 281w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-run_on_server_6-768x820.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-851147" class="wp-caption-text"&gt;Figure 6: A bare-metal installation.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Install the application as a bootable JAR&lt;/h3&gt; &lt;p&gt;Instead of running your application on a bare-metal installation of JBoss EAP XP server, you can now package a JBoss EAP XP server and Eclipse MicroProfile application inside a bootable JAR. You can then run the application on a JBoss EAP XP bare-metal platform.&lt;/p&gt; &lt;p&gt;For demonstration purposes, we&amp;#8217;ve defined a Maven project for &lt;code&gt;microprofile-config&lt;/code&gt;. The project includes the following &lt;code&gt;bootable-jar&lt;/code&gt; profile:&lt;/p&gt; &lt;pre&gt; ---- &amp;#60;profile&amp;#62; &amp;#60;id&amp;#62;bootable-jar&amp;#60;/id&amp;#62; &amp;#60;build&amp;#62; &amp;#60;plugins&amp;#62; &amp;#60;plugin&amp;#62; &amp;#60;groupId&amp;#62;org.wildfly.plugins&amp;#60;/groupId&amp;#62; &amp;#60;artifactId&amp;#62;wildfly-jar-maven-plugin&amp;#60;/artifactId&amp;#62; &amp;#60;configuration&amp;#62; &amp;#60;feature-pack-location&amp;#62;org.jboss.eap:wildfly-galleon-pack:${version.server.bootable-jar}&amp;#60;/feature-pack-location&amp;#62; &amp;#60;layers&amp;#62; &amp;#60;layer&amp;#62;jaxrs-server&amp;#60;/layer&amp;#62; &amp;#60;layer&amp;#62;microprofile-platform&amp;#60;/layer&amp;#62; &amp;#60;/layers&amp;#62; &amp;#60;/configuration&amp;#62; &amp;#60;executions&amp;#62; &amp;#60;execution&amp;#62; &amp;#60;goals&amp;#62; &amp;#60;goal&amp;#62;package&amp;#60;/goal&amp;#62; &amp;#60;/goals&amp;#62; &amp;#60;/execution&amp;#62; &amp;#60;/executions&amp;#62; &amp;#60;/plugin&amp;#62; &amp;#60;/plugins&amp;#62; &amp;#60;/build&amp;#62; &amp;#60;/profile&amp;#62; ---- &lt;/pre&gt; &lt;p&gt;As you can see, we have selected the &lt;code&gt;jaxrs-server&lt;/code&gt; and the &lt;code&gt;microprofile-plateform&lt;/code&gt; layers to construct a slim version of the JBoss EAP XP server, which encapsulates our application. All you need to do is select the correct profile, as shown in Figure 7:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Right-click on the &lt;b&gt;pom.xml&lt;/b&gt;.&lt;/li&gt; &lt;li&gt;Navigate to &lt;b&gt;Maven&lt;/b&gt; and choose &lt;b&gt;Select Maven Profiles&lt;/b&gt;.&lt;/li&gt; &lt;li&gt;Check &lt;b&gt;bootable-jar&lt;/b&gt;.&lt;/li&gt; &lt;/ol&gt; &lt;div id="attachment_851157" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-select_maven_profile_7.png"&gt;&lt;img aria-describedby="caption-attachment-851157" class="wp-image-851157" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-select_maven_profile_7.png" alt="Dialog to select the apache Maven profile to use." width="640" height="735" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-select_maven_profile_7.png 873w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-select_maven_profile_7-261x300.png 261w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-select_maven_profile_7-768x882.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-851157" class="wp-caption-text"&gt;Figure 7: Select the Apache Maven profile.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Next, we need to build the bootable JAR using Apache Maven. Right-click on the &lt;code&gt;pom.xml&lt;/code&gt;. Then, go into the &lt;strong&gt;Run As&lt;/strong&gt; menu, and select &lt;strong&gt;9 Maven install&lt;/strong&gt;. Figure 8 shows these selections.&lt;/p&gt; &lt;div id="attachment_851167" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-build_bootable_jar_8.png"&gt;&lt;img aria-describedby="caption-attachment-851167" class="wp-image-851167" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-build_bootable_jar_8.png" alt="Building the bootable JAR using Apache Maven," width="640" height="717" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-build_bootable_jar_8.png 751w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-build_bootable_jar_8-268x300.png 268w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-851167" class="wp-caption-text"&gt;Figure 8: Build the bootable JAR.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Once the bootable JAR is built, we need to run our application from CodeReady Studio. We will create a new Apache Maven run configuration for this purpose. As shown in Figure 9, right-click on the &lt;code&gt;pom.xml&lt;/code&gt; and navigate to the &lt;strong&gt;Run As&lt;/strong&gt; menu, then select &lt;strong&gt;5 Maven build&lt;/strong&gt;. Set &lt;strong&gt;org.wildfly.plugins:wildfly-jar-maven-plugin:run&lt;/strong&gt; as the goal and rename the execution to &lt;strong&gt;microprofile-config bootable run&lt;/strong&gt;, then click &lt;strong&gt;Run&lt;/strong&gt;.&lt;/p&gt; &lt;div id="attachment_851177" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-run_bootable_jar_9.png"&gt;&lt;img aria-describedby="caption-attachment-851177" class="wp-image-851177 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-run_bootable_jar_9-1024x801.png" alt="The dialog to run the bootable JAR using Apache Maven." width="640" height="501" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-run_bootable_jar_9-1024x801.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-run_bootable_jar_9-300x235.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-run_bootable_jar_9-768x601.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-run_bootable_jar_9.png 1389w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-851177" class="wp-caption-text"&gt;Figure 9: Run the bootable JAR.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;When the server starts, the application will be available as the root context, at &lt;a target="_blank" rel="nofollow" href="http://localhost:8080/config/value"&gt;http://localhost:8080/config/value&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Shutting down the server&lt;/h2&gt; &lt;p&gt;Closing or terminating the terminal will not stop the running server, so we need another run configuration to shut down the server. The easiest approach is to copy the run configuration we&amp;#8217;ve just created, rename it &lt;strong&gt;microprofile-config bootable shutdown&lt;/strong&gt;, and use the goal &lt;strong&gt;org.wildfly.plugins:wildfly-jar-maven-plugin:shutdown&lt;/strong&gt;, as shown in Figure 10.&lt;/p&gt; &lt;div id="attachment_851197" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-run_bootable_jar_10.png"&gt;&lt;img aria-describedby="caption-attachment-851197" class="wp-image-851197 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-run_bootable_jar_10-1024x801.png" alt="Create a new run configuration to shut down the server." width="640" height="501" srcset="https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-run_bootable_jar_10-1024x801.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-run_bootable_jar_10-300x235.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-run_bootable_jar_10-768x601.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2021/01/crs-run_bootable_jar_10.png 1389w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-851197" class="wp-caption-text"&gt;Figure 10: Create a new run configuration to shut down the server.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;This article showed you how to install JBoss Enterprise Application Platform XP 2.0.0 GA with Eclipse MicroProfile support. I then showed you two ways to configure and run a MicroProfile Config quickstart project using Red Hat CodeReady Studio.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F12%2Fdevelop-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-xp-2-0%2F&amp;#38;linkname=Develop%20Eclipse%20MicroProfile%20applications%20on%20Red%20Hat%20JBoss%20Enterprise%20Application%20Platform%20XP%202.0" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F12%2Fdevelop-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-xp-2-0%2F&amp;#38;linkname=Develop%20Eclipse%20MicroProfile%20applications%20on%20Red%20Hat%20JBoss%20Enterprise%20Application%20Platform%20XP%202.0" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F12%2Fdevelop-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-xp-2-0%2F&amp;#38;linkname=Develop%20Eclipse%20MicroProfile%20applications%20on%20Red%20Hat%20JBoss%20Enterprise%20Application%20Platform%20XP%202.0" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F12%2Fdevelop-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-xp-2-0%2F&amp;#38;linkname=Develop%20Eclipse%20MicroProfile%20applications%20on%20Red%20Hat%20JBoss%20Enterprise%20Application%20Platform%20XP%202.0" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F12%2Fdevelop-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-xp-2-0%2F&amp;#38;linkname=Develop%20Eclipse%20MicroProfile%20applications%20on%20Red%20Hat%20JBoss%20Enterprise%20Application%20Platform%20XP%202.0" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F12%2Fdevelop-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-xp-2-0%2F&amp;#38;linkname=Develop%20Eclipse%20MicroProfile%20applications%20on%20Red%20Hat%20JBoss%20Enterprise%20Application%20Platform%20XP%202.0" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F12%2Fdevelop-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-xp-2-0%2F&amp;#38;linkname=Develop%20Eclipse%20MicroProfile%20applications%20on%20Red%20Hat%20JBoss%20Enterprise%20Application%20Platform%20XP%202.0" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F12%2Fdevelop-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-xp-2-0%2F&amp;#038;title=Develop%20Eclipse%20MicroProfile%20applications%20on%20Red%20Hat%20JBoss%20Enterprise%20Application%20Platform%20XP%202.0" data-a2a-url="https://developers.redhat.com/blog/2021/01/12/develop-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-xp-2-0/" data-a2a-title="Develop Eclipse MicroProfile applications on Red Hat JBoss Enterprise Application Platform XP 2.0"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/12/develop-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-xp-2-0/"&gt;Develop Eclipse MicroProfile applications on Red Hat JBoss Enterprise Application Platform XP 2.0&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/cmgVgrBpkwY" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;This article shows you how to install Red Hat JBoss Enterprise Application Platform (JBoss EAP) XP 2.0.0 GA with support for Eclipse MicroProfile. Once you&amp;#8217;ve enabled Eclipse MicroProfile, you will be able to use its quickstart examples to start developing your own MicroProfile applications with Red Hat CodeReady Studio. In this demonstration, you&amp;#8217;ll learn two [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/12/develop-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-xp-2-0/"&gt;Develop Eclipse MicroProfile applications on Red Hat JBoss Enterprise Application Platform XP 2.0&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/01/12/develop-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-xp-2-0/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">850617</post-id><dc:creator>Emmanuel Hugonnet</dc:creator><dc:date>2021-01-12T08:00:45Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/01/12/develop-eclipse-microprofile-applications-on-red-hat-jboss-enterprise-application-platform-xp-2-0/</feedburner:origLink></entry><entry><title type="html">Bored with magic tricks?</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/5Xd-KucGQfc/" /><author><name /></author><id>https://quarkus.io/blog/magic-control/</id><updated>2021-01-12T00:00:00Z</updated><content type="html">Just before my PTO, someone told me: 'I don’t like magic.' In this context, magic refers to the amount of hidden stuff done by Quarkus under the hood for the sake of simplicity. It includes dependency injection, annotations, and so on. It’s not the first time that I get that...&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/5Xd-KucGQfc" height="1" width="1" alt=""/&gt;</content><dc:creator /><feedburner:origLink>https://quarkus.io/blog/magic-control/</feedburner:origLink></entry><entry><title>Getting started with Buildah</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/C-oFmv-GD0U/" /><category term="Containers" /><category term="Kubernetes" /><category term="Linux" /><category term="buildah" /><category term="container image" /><category term="Docker" /><category term="openshift" /><category term="Podman" /><author><name>Cedric Clyburn</name></author><id>https://developers.redhat.com/blog/?p=758807</id><updated>2021-01-11T08:00:01Z</updated><published>2021-01-11T08:00:01Z</published><content type="html">&lt;p&gt;If you&amp;#8217;re looking to build Open Container Initiative (OCI) container images without a full container runtime or daemon installed, &lt;a target="_blank" rel="nofollow" href="https://buildah.io/"&gt;Buildah&lt;/a&gt; is the perfect solution. Now, Buildah is an open source, Linux-based tool that can build Docker- and &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt;-compatible images, and is easy to incorporate into scripts and build pipelines. In addition, Buildah has overlap functionality with &lt;a target="_blank" rel="nofollow" href="https://podman.io/"&gt;Podman&lt;/a&gt;, &lt;a target="_blank" rel="nofollow" href="https://github.com/containers/skopeo"&gt;Skopeo&lt;/a&gt;, and &lt;a target="_blank" rel="nofollow" href="https://cri-o.io/"&gt;CRI-O&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Buildah has the ability to create a working &lt;a href="https://developers.redhat.com/topics/containers/"&gt;container&lt;/a&gt; from scratch, but also from a pre-existing Dockerfile. Plus, with it not needing a daemon, you&amp;#8217;ll never have to worry about Docker daemon issues when building container images.&lt;/p&gt; &lt;p&gt;Let&amp;#8217;s cover some real-world examples to show how easy it is to get started with Buildah, and how easy it is to create a container image.&lt;/p&gt; &lt;h2&gt;Installing Buildah&lt;/h2&gt; &lt;p&gt;If you&amp;#8217;re running &lt;a href="https://developers.redhat.com/products/rhel/overview"&gt;Red Hat Enterprise Linux&lt;/a&gt; (RHEL) 8, follow the steps below. For Fedora users, be sure to replace &lt;code&gt;yum&lt;/code&gt; with &lt;code&gt;dnf&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;$ yum -y install buildah&lt;/pre&gt; &lt;p&gt;However, if you don&amp;#8217;t have Linux available, you can use &lt;a target="_blank" rel="nofollow" href="https://www.katacoda.com/courses/containers-without-docker/building-container-images-with-buildah"&gt;Buildah online with Katacoda&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Basic commands&lt;/h2&gt; &lt;p&gt;To get to know Buildah, let&amp;#8217;s play around with some basic commands. The command &lt;code&gt;buildah --version&lt;/code&gt; will output the current version of our Buildah install, and &lt;code&gt;buildah --help&lt;/code&gt; will help if you get stuck.&lt;/p&gt; &lt;p&gt;For example, in order to pull a container image from a repository, use the &lt;code&gt;from&lt;/code&gt; variable. For example, if your favorite Linux distribution is CentOS:&lt;/p&gt; &lt;pre&gt;$ buildah from centos&lt;/pre&gt; &lt;p&gt;After pulling the image and storing it on the host, list our current images by running &lt;code&gt;buildah images&lt;/code&gt;. This behavior is similar to Podman and Docker, as many commands are cross-compatible. To get a list of our running containers, which are provisioned as soon as the image pull is completed, use &lt;code&gt;buildah containers&lt;/code&gt;. For an example, see Figure 1.&lt;/p&gt; &lt;div id="attachment_763307" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Buildah-containers.png"&gt;&lt;img aria-describedby="caption-attachment-763307" class="wp-image-763307 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Buildah-containers-1024x127.png" alt="The output of the command &amp;#34;buildah containers&amp;#34;, showing CONTAINER ID, BUILDER, IMAGE ID, IMAGE NAME, and CONTAINER #" width="640" height="79" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Buildah-containers-1024x127.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Buildah-containers-300x37.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Buildah-containers-768x95.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-763307" class="wp-caption-text"&gt;Figure 1: Run &amp;#8220;buildah containers&amp;#8221; to see your provisioned containers.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Finally, since we&amp;#8217;ve pulled and displayed a container, let&amp;#8217;s clean up and remove our running containers with &lt;code&gt;buildah rm -all&lt;/code&gt;. Be sure to exercise caution, however, as Buildah has the ability to remove a running container while Docker does not.&lt;/p&gt; &lt;h2&gt;Building a container&lt;/h2&gt; &lt;p&gt;Time to get hands-on with Buildah and build an Apache web server that will run inside a container. To get things started, let&amp;#8217;s pull a CentOS base image and start working:&lt;/p&gt; &lt;pre&gt;$ buildah from centos&lt;/pre&gt; &lt;p&gt;You&amp;#8217;ll see the default image name as output in the console like &lt;code&gt;centos-working-container&lt;/code&gt;, giving us the ability to run commands within the specified container. For our case, we&amp;#8217;ll be installing an &lt;a target="_blank" rel="nofollow" href="https://httpd.apache.org/docs/current/programs/httpd.html"&gt;httpd&lt;/a&gt; package, which can be done using the following command:&lt;/p&gt; &lt;pre&gt;$ buildah run centos-working-container yum install httpd -y&lt;/pre&gt; &lt;p&gt;Once we&amp;#8217;ve installed &lt;code&gt;httpd&lt;/code&gt;, we can take our attention to creating a main page to be directed to on our web server, commonly known as an &lt;code&gt;index.html&lt;/code&gt; file. To create a simple file without having to worry about formatting, use the &lt;code&gt;echo&lt;/code&gt; command below:&lt;/p&gt; &lt;pre&gt;$ echo "Hello from Red Hat" &amp;#62; index.html&lt;/pre&gt; &lt;p&gt;In addition, after creating this new file, let&amp;#8217;s copy it into our current working container with the Buildah &lt;code&gt;copy&lt;/code&gt; function. The default location for publicly accessible files is also included:&lt;/p&gt; &lt;pre&gt;$ buildah copy centos-working-container index.html /var/www/html/index.html&lt;/pre&gt; &lt;p&gt;To start this container, we must configure an entry point for a container, which is used to start &lt;code&gt;httpd&lt;/code&gt; as the container begins and keep it in the foreground:&lt;/p&gt; &lt;pre&gt;$ buildah config --entrypoint "/usr/sbin/httpd -DFOREGROUND" centos-working-container&lt;/pre&gt; &lt;p&gt;Finally, let&amp;#8217;s &lt;code&gt;commit&lt;/code&gt; our changes to the container, and prepare it to be pushed to any container registry you&amp;#8217;d like (ex. &lt;a href="https://developers.redhat.com/blog/2019/02/21/podman-and-buildah-for-docker-users/"&gt;Docker and Quay.io&lt;/a&gt;):&lt;/p&gt; &lt;pre&gt;$ buildah commit centos-working-container redhat-website&lt;/pre&gt; &lt;p&gt;Your &lt;code&gt;redhat-website&lt;/code&gt; image is ready to &lt;a href="https://developers.redhat.com/blog/2019/08/14/best-practices-for-running-buildah-in-a-container/"&gt;run with Podman&lt;/a&gt;, or push to your registry of choice.&lt;/p&gt; &lt;h2&gt;Building with a Dockerfile&lt;/h2&gt; &lt;p&gt;Another significant part of Buildah is the ability to build images using a Dockerfile, and the &lt;code&gt;build-using-dockerfile&lt;/code&gt;, or &lt;code&gt;bud&lt;/code&gt; command can do just that. Let&amp;#8217;s take an example Dockerfile as input, and output an OCI image:&lt;/p&gt; &lt;pre&gt;# &lt;strong&gt;CoreOS Base&lt;/strong&gt; FROM fedora:latest # &lt;strong&gt;Install httpd&lt;/strong&gt; RUN echo "Installing httpd"; yum -y install httpd # &lt;strong&gt;Expose the default httpd port 80&lt;/strong&gt; EXPOSE 80 # &lt;strong&gt;Run httpd&lt;/strong&gt; CMD ["/usr/sbin/httpd", "-DFOREGROUND"]&lt;/pre&gt; &lt;p&gt;Once we save this file as &lt;code&gt;Dockerfile&lt;/code&gt; in our local directory, we can use the &lt;code&gt;bud&lt;/code&gt; command to build the image:&lt;/p&gt; &lt;pre&gt;$ buildah bud -t fedora-httpd&lt;/pre&gt; &lt;p&gt;To double-check our progress, let&amp;#8217;s run &lt;code&gt;buildah images&lt;/code&gt; and ensure we can see our new &lt;code&gt;fedora-httpd&lt;/code&gt; image resting in our localhost repository. Now, feel free to again &lt;a href="https://developers.redhat.com/blog/2019/08/14/best-practices-for-running-buildah-in-a-container/"&gt;run the image with Podman&lt;/a&gt;, or push it to your favorite registry.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;Great job! We&amp;#8217;ve gone through building a container from scratch, as well as from a predefined Dockerfile. Buildah is a lightweight and flexible way to create container images without the need for a runtime or daemon installed.&lt;/p&gt; &lt;p&gt;You can continue to experiment with Buildah by setting up &lt;a target="_blank" rel="nofollow" href="https://www.katacoda.com/courses/containers-without-docker/building-container-images-with-buildah"&gt;this Katacoda scenario&lt;/a&gt;, which offers you an interactive environment right in your browser.&lt;/p&gt; &lt;p&gt;If you need container orchestration, you can use Buildah with &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; or &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt;. To get started with these platforms, see &lt;a target="_blank" rel="nofollow" href="https://kubernetesbyexample.com/"&gt;kubernetesbyexample.com&lt;/a&gt; and &lt;a target="_blank" rel="nofollow" href="https://learn.openshift.com/"&gt;learn.openshift.com.&lt;/a&gt;&lt;/p&gt; &lt;p&gt;For interactive demonstrations of many of the examples you&amp;#8217;ve seen here, watch this video:&lt;/p&gt; &lt;p&gt;&lt;iframe class='youtube-player' type='text/html' width='640' height='360' src='https://www.youtube.com/embed/SNDjOfs2zCM?version=3&amp;#038;rel=1&amp;#038;fs=1&amp;#038;autohide=2&amp;#038;showsearch=0&amp;#038;showinfo=1&amp;#038;iv_load_policy=1&amp;#038;wmode=transparent' allowfullscreen='true' style='border:0;'&gt;&lt;/iframe&gt;&lt;/p&gt; &lt;h2&gt;Resources&lt;/h2&gt; &lt;p&gt;Learn more about Buildah:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2019/02/21/podman-and-buildah-for-docker-users/"&gt;Podman and Buildah for Docker users&lt;/a&gt; (William Henry)&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2019/08/14/best-practices-for-running-buildah-in-a-container/"&gt;Best practices for running Buildah in a container&lt;/a&gt; (Daniel Walsh)&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2019/04/04/build-and-run-buildah-inside-a-podman-container/"&gt;Build and run Buildah inside a Podman container&lt;/a&gt; (Tom Sweeney)&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F11%2Fgetting-started-with-buildah%2F&amp;#38;linkname=Getting%20started%20with%20Buildah" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F11%2Fgetting-started-with-buildah%2F&amp;#38;linkname=Getting%20started%20with%20Buildah" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F11%2Fgetting-started-with-buildah%2F&amp;#38;linkname=Getting%20started%20with%20Buildah" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F11%2Fgetting-started-with-buildah%2F&amp;#38;linkname=Getting%20started%20with%20Buildah" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F11%2Fgetting-started-with-buildah%2F&amp;#38;linkname=Getting%20started%20with%20Buildah" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F11%2Fgetting-started-with-buildah%2F&amp;#38;linkname=Getting%20started%20with%20Buildah" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F11%2Fgetting-started-with-buildah%2F&amp;#38;linkname=Getting%20started%20with%20Buildah" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F11%2Fgetting-started-with-buildah%2F&amp;#038;title=Getting%20started%20with%20Buildah" data-a2a-url="https://developers.redhat.com/blog/2021/01/11/getting-started-with-buildah/" data-a2a-title="Getting started with Buildah"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/11/getting-started-with-buildah/"&gt;Getting started with Buildah&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/C-oFmv-GD0U" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;If you&amp;#8217;re looking to build Open Container Initiative (OCI) container images without a full container runtime or daemon installed, Buildah is the perfect solution. Now, Buildah is an open source, Linux-based tool that can build Docker- and Kubernetes-compatible images, and is easy to incorporate into scripts and build pipelines. In addition, Buildah has overlap functionality [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/11/getting-started-with-buildah/"&gt;Getting started with Buildah&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/01/11/getting-started-with-buildah/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">758807</post-id><dc:creator>Cedric Clyburn</dc:creator><dc:date>2021-01-11T08:00:01Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/01/11/getting-started-with-buildah/</feedburner:origLink></entry><entry><title type="html">How to setup the OpenShift Container Platform 4.6 on your local machine</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/MQVlbKEcJuk/codeready-containers-howto-setup-openshift-46-on-local-machine.html" /><author><name>Eric D. Schabell</name></author><id>http://feedproxy.google.com/~r/schabell/jboss/~3/W5rqdLQSbvk/codeready-containers-howto-setup-openshift-46-on-local-machine.html</id><updated>2021-01-11T06:00:00Z</updated><content type="html">Are you looking to develop a few projects on your local machine and push them on to a real OpenShift Container Platform without having to worry about cloud hosting of your container platform? Would you like to do that on one of the newer versions of OpenShift Container Platform such as version 4.6? Look no further as CodeReady Containers puts it all at your fingertips. Experience the joys of cloud native development and automated rolling deployments.  The idea was to make this as streamlined of an experience as possible by using the same  project. Let's take a look at what this looks like. Below is a walk through step by step, putting the latest OpenShift Container Platform on your local developer machine. LINUX OR MAC INSTALLATION This installation requires the following (all freely available): &gt; 1. HyperKit for OSX, Hyper-V for Windows, or Libvirt for Linux &gt; 2. Code Ready Containers (OCP 4.6) &gt; 3. OpenShift Client (oc) v4.6 First you need to ensure your virtualization tooling is installed for your platform, just search online for how to do that or your specific platform. Second you need to download the CodeReady Containers. Finally, you need the OpenShift client. Normally you'd expect to have to track these last two down but we've made this all easy by just including checks during the installation. If you have something installed, it checks the version, if good then it moves on with next steps. If anything is missing or the wrong version, the installation stops and notifies you where to find that component for your platform (including URL). Let's get started by downloading the  project and unzipping in some directory. This gives you a file called ocp-install-demo-main.zip,just unzip and run the init.sh as follows:      $ ./init.sh  Follow the instructions as each of the dependencies is checked and you're provided with pointers to getting the versions you need for your platform. Note: Each CodeReady Container download is tied to an embedded secret. This secret you need to download (link will be provided) as a file and you'll be asked to point to that secret to start your container platform. Once you've gotten all the dependencies sorted out, the install runs like this: A little ASCII art and then it's checking for my platform's virtualization (Hyperkit), then looking for the OpenShift client version (oc client), then running a setup (crc setup). The next steps are providing the pull-secret-file, you can set this in the variables at the top of the installation script. Now the moment of truth, the CodeReady Containers cluster starts, which takes some time depending on your network (crc start). With a good network it's about a five minute wait. This is the logging you'll see as the OpenShift cluster starts on your local machine. The warning is normal, just some of the features have been trimmed to speed up deployment. At the end we'll retrieve the admin password for logging in to the cluster's console, pick up the host URL, test the deployment by logging in with our client (oc login), and finally you're given all the details in a nice box. You have the option to stop, start it again, or delete the OpenShift Container Platform cluster as shown in the dialog. Next open the web console using URL and login 'kubeadmin' with the corresponding password. In our case it's the URL: https://console-openshift-console.apps-crc.testing Login with user: kubeadmin Password in our case: duduw-yPT9Z-hsUpq-f3pre That opens the main dashboard: Verify the version you are running by clicking on the top right question mark and then About option: Close the version window by clicking on the X. As we are interested in developing using the tooling and container images provided by CodeReady Containers, let's change the view from Administrator to Developer in the left top menu selecting Topology and then via Project drop down menu at the top choose Default: You can browse the offerings in the provided container catalog by selecting From Catalog and then for example, Middleware to view the offerings available: Looking to get started with an example usage, try the  or examples that leverage the provided developer catalog container images. You can also explore how an existing project is set up using one of the developer catalog container images with a . This concludes the installation and tour of an OpenShift Container Platform on our local machine using CodeReady Containers. WHAT ABOUT WINDOWS? If you are a sharp observer, you'll notice there is a file called init.bat for windows platforms to install with. The problem is I've not been able to test this yet on a windows machine, so I'd love to call out to the readers out there that might have some time to contribute to test this script and help us complete the installation. You'll notice a few TODO's marked in the scripts code, as they are untested areas in the installation. You can  and help us complete the windows based installation and get your name added to the contributors list. We'd be really thankful! Stay tuned for more on cloud-native development using other Red Hat technologies on your new OpenShift Container Platform installed locally on your own machine!&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/MQVlbKEcJuk" height="1" width="1" alt=""/&gt;</content><dc:creator>Eric D. Schabell</dc:creator><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/W5rqdLQSbvk/codeready-containers-howto-setup-openshift-46-on-local-machine.html</feedburner:origLink></entry><entry><title>Message broker integration made simple with Red Hat Fuse</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/q9tJPZcfkZ8/" /><category term="Event-Driven" /><category term="Java" /><category term="Spring Boot" /><category term="apache camel" /><category term="jboss" /><category term="message broker" /><category term="red hat amq" /><category term="Red Hat Fuse" /><author><name>Francesco Marchioni</name></author><id>https://developers.redhat.com/blog/?p=807297</id><updated>2021-01-08T08:00:00Z</updated><published>2021-01-08T08:00:00Z</published><content type="html">&lt;p&gt;This article presents a sample integration between &lt;a href="https://developers.redhat.com/products/amq/overview"&gt;Red Hat AMQ 7&lt;/a&gt; and &lt;a target="_blank" rel="nofollow" href="https://www.ibm.com/products/mq"&gt;IBM MQ&lt;/a&gt;, using &lt;a href="https://developers.redhat.com/products/fuse/download"&gt;Red Hat Fuse 7&lt;/a&gt; for the integration. Traditionally, developers have used resource adapters for message bridging with external systems. A &lt;i&gt;resource adapter&lt;/i&gt; is a system library that provides connectivity to an enterprise information system (EIS). Similar to how a Java Database Connectivity (JDBC) driver provides connectivity to a database management system, a resource adapter plugs into an application server such as &lt;a href="https://developers.redhat.com/products/eap/download"&gt;Red Hat JBoss Enterprise Application Platform&lt;/a&gt; (JBoss EAP). It then connects the application server, enterprise information system, and the enterprise application.&lt;/p&gt; &lt;p&gt;Resource adapters work well, but the configuration can be overwhelming, especially for scenarios that require adding numerous modules on top of the application server or where the resource adapter contract requires extensive administrative resources. Some scenarios require configuring multiple resource adapters and then arranging the message exchange between them.&lt;/p&gt; &lt;p&gt;Red Hat Fuse provides a simpler, more flexible pattern for routing messages between components. Fuse leverages Apache Camel&amp;#8217;s &lt;a target="_blank" rel="nofollow" href="https://camel.apache.org/components/latest/jms-component.html"&gt;JMS component&lt;/a&gt; to exchange messages via a Java Message Service (JMS) queue or topic. It relies on Spring’s JMS support for declarative transactions.&lt;/p&gt; &lt;p&gt;Follow the demonstration in the next sections to see for yourself how the JMS component works in a Red Hat Fuse integration.&lt;/p&gt; &lt;h2&gt;Set up the Red Hat Fuse project&lt;/h2&gt; &lt;p&gt;For this demonstration, we will create a &lt;a href="https://developers.redhat.com/topics/spring-boot"&gt;Spring Boot&lt;/a&gt;-based Fuse application that uses a Camel route to exchange messages between Red Hat AMQ and IBM MQ. To start, open a shell prompt and enter the following &lt;code&gt;mvn&lt;/code&gt; command:&lt;/p&gt; &lt;pre&gt;mvn org.apache.maven.plugins:maven-archetype-plugin:2.4:generate \ -DarchetypeCatalog=https://maven.repository.redhat.com/ga/io/fabric8/archetypes/archetypes-catalog/2.2.0.fuse-760024-redhat-00001/archetypes-catalog-2.2.0.fuse-760024-redhat-00001-archetype-catalog.xml \ -DarchetypeGroupId=org.jboss.fuse.fis.archetypes \ -DarchetypeArtifactId=spring-boot-camel-xml-archetype \ -DarchetypeVersion=2.2.0.fuse-760024-redhat-00001 &lt;/pre&gt; &lt;p&gt;This command creates the basic project structure, including the &lt;code&gt;Application&lt;/code&gt; class:&lt;/p&gt; &lt;pre&gt;package com.sample; import org.springframework.boot.SpringApplication; import org.springframework.boot.autoconfigure.SpringBootApplication; @SpringBootApplication public class Application { public static void main(String[] args) { SpringApplication.run(Application.class, args); } } &lt;/pre&gt; &lt;p&gt;So far, the code should look familiar.&lt;/p&gt; &lt;h2&gt;Configure the brokers&lt;/h2&gt; &lt;p&gt;Next, we&amp;#8217;ll configure the two brokers. Start by adding a &lt;code&gt;@Configuration&lt;/code&gt; bean that contains the following &lt;code&gt;JmsComponent&lt;/code&gt; bean declarations (note that the declarations are bound as &lt;code&gt;@Bean&lt;/code&gt; using the method name for the &lt;code&gt;id&lt;/code&gt;):&lt;/p&gt; &lt;pre&gt;package com.sample; import com.ibm.mq.jms.*; import org.apache.activemq.artemis.jms.client.ActiveMQConnectionFactory; import org.apache.camel.component.jms.JmsComponent; import org.springframework.context.annotation.Bean; import org.springframework.context.annotation.Configuration; import org.springframework.jms.connection.UserCredentialsConnectionFactoryAdapter; @Configuration public class AppConfig { @Bean public JmsComponent activemq() throws Exception { // Create the connectionfactory which will be used to connect to Artemis ActiveMQConnectionFactory cf = new ActiveMQConnectionFactory(); cf.setBrokerURL("tcp://localhost:61616"); cf.setUser("admin"); cf.setPassword("admin"); // Create the Camel JMS component and wire it to our Artemis connectionfactory JmsComponent jms = new JmsComponent(); jms.setConnectionFactory(cf); return jms; } @Bean public JmsComponent wmq(){ JmsComponent jmsComponent = new JmsComponent(); jmsComponent.setConnectionFactory(mqQueueConnectionFactory()); return jmsComponent; } @Bean public MQQueueConnectionFactory mqQueueConnectionFactory() { // Create the connectionfactory which will be used to connect to IBM MQ MQQueueConnectionFactory mqQueueConnectionFactory = new MQQueueConnectionFactory(); mqQueueConnectionFactory.setHostName("localhost"); try { mqQueueConnectionFactory.setTransportType(1); mqQueueConnectionFactory.setChannel("DEV.APP.SVRCONN"); mqQueueConnectionFactory.setPort(1414); mqQueueConnectionFactory.setQueueManager("QM1"); } catch (Exception e) { e.printStackTrace(); } return mqQueueConnectionFactory; } @Bean public UserCredentialsConnectionFactoryAdapter userCredentialsConnectionFactoryAdapter( MQQueueConnectionFactory mqQueueConnectionFactory) { UserCredentialsConnectionFactoryAdapter userCredentialsConnectionFactoryAdapter = new UserCredentialsConnectionFactoryAdapter(); userCredentialsConnectionFactoryAdapter.setUsername("username"); userCredentialsConnectionFactoryAdapter.setPassword("password"); userCredentialsConnectionFactoryAdapter.setTargetConnectionFactory(mqQueueConnectionFactory); return userCredentialsConnectionFactoryAdapter; } } &lt;/pre&gt; &lt;p&gt;The Red Hat AMQ connection factory is now available under the &lt;code&gt;activemq&lt;/code&gt; &lt;code&gt;id&lt;/code&gt;. The IBM MQ connection factory is available under the &lt;code&gt;wmq&lt;/code&gt; &lt;code&gt;id&lt;/code&gt;.&lt;/p&gt; &lt;h2&gt;Add the route definition&lt;/h2&gt; &lt;p&gt;We&amp;#8217;re almost done. Our final step is to add the &lt;code&gt;RouteBuilder&lt;/code&gt; class, which contains the route definition:&lt;/p&gt; &lt;pre&gt;package com.sample; import org.apache.camel.builder.RouteBuilder; import org.springframework.stereotype.Component; @Component public class CamelArtemisRouteBuilder extends RouteBuilder { public void configure() throws Exception { from("timer:mytimer?period=5000").routeId("generate-route") .transform(constant("HELLO from Camel!")) .to("activemq:queue:QueueIN"); from("activemq:queue:QueueIN").routeId("receive-route") .log("Received a message - ${body} - sending to outbound queue") .to("wmq:queue:DEV.QUEUE.1?exchangePattern=InOnly"); } } &lt;/pre&gt; &lt;p&gt;In the above route, messages are produced from a timer component that fires new messages every five seconds. Messages are sent through the Red Hat AMQ queue named &lt;code&gt;QueueIN&lt;/code&gt;. After logging the message body, they are sent to the sink destination, which is &lt;code&gt;DEV.QUEUE.1&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;We&amp;#8217;ve completed the integration setup. Next, we&amp;#8217;ll run the application and verify that it&amp;#8217;s working.&lt;/p&gt; &lt;h2&gt;Start the brokers and run the application&lt;/h2&gt; &lt;p&gt;Before running the application, we need to start the two broker instances. Make sure your Red Hat AMQ server is up and running. If it is not already running, enter the following command:&lt;/p&gt; &lt;pre&gt;./artemis run &lt;/pre&gt; &lt;p&gt;Next, start IBM MQ. For this purpose, you can use a container image of IBM MQ with the developer license:&lt;/p&gt; &lt;pre&gt;$ podman run --env LICENSE=accept --env MQ_QMGR_NAME=QM1 --publish 1414:1414 --publish 9443:9443 --detach ibmcom/mq &lt;/pre&gt; &lt;p&gt;Finally, use the standard Spring Boot Maven plug-in to start the Red Hat Fuse application:&lt;/p&gt; &lt;pre&gt;$ mvn spring-boot:run &lt;/pre&gt; &lt;h2&gt;Verify the application&lt;/h2&gt; &lt;p&gt;As the application starts, you will see from the Spring Boot console that messages are logged on the console:&lt;/p&gt; &lt;pre&gt;12:10:12.552 [Camel (camel-1) thread #1 - JmsConsumer[INCOMING]] INFO receive-route - Received a message - HELLO from Camel! - sending to outbound queue 13:20:37.935 [Camel (camel-1) thread #1 - JmsConsumer[INCOMING]] INFO receive-route - Received a message - HELLO from Camel! - sending to outbound queue 13:20:42.954 [Camel (camel-1) thread #1 - JmsConsumer[INCOMING]] INFO receive-route - Received a message - HELLO from Camel! - sending to outbound queue 13:20:47.966 [Camel (camel-1) thread #1 - JmsConsumer[INCOMING]] INFO receive-route - Received a message - HELLO from Camel! - sending to outbound queue &lt;/pre&gt; &lt;p&gt;You can log into the running container process to check that the message has been received on the IBM MQ side:&lt;/p&gt; &lt;pre&gt;$ podman ps CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES 52f0f72d56ed docker.io/ibmcom/mq:latest 5 hours ago Up 5 hours ago 0.0.0.0:1414-&amp;#62;1414/tcp pensive_bose&lt;/pre&gt; &lt;p&gt;The output shows the message has been received:&lt;/p&gt; &lt;pre&gt;$ podman exec --tty --interactive 52f0f72d56ed bash bash-4.4$ /opt/mqm/samp/bin/amqsbcg DEV.QUEUE.1 QM1 MQGET of message number 1 ****Message descriptor**** StrucId : 'MD ' Version : 2 Report : 0 MsgType : 8 Expiry : -1 Feedback : 0 Encoding : 546 CodedCharSetId : 850 Format : 'MQEVENT ' Priority : 0 Persistence : 0 MsgId : X'414D512073617475726E2E71756575650005D30033563DB8' CorrelId : X'000000000000000000000000000000000000000000000000' BackoutCount : 0 ReplyToQ : ' ' ** Identity Context UserIdentifier : ' ' AccountingToken : X'0000000000000000000000000000000000000000000000000000000000000000' ApplIdentityData : ' ' ** Origin Context PutApplType : '7' PutDate : '19970417' PutTime : '15115208' ApplOriginData : ' ' GroupId : X'000000000000000000000000000000000000000000000000' MsgSeqNumber : '1' Offset : '0' MsgFlags : '0' OriginalLength : '104' **** Message **** length - 104 bytes &lt;/pre&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;This article discussed how to connect multiple JMS providers (in this case, Red Hat AMQ and IBM MQ) by registering their JMS &lt;code&gt;ConnectionFactory&lt;/code&gt; components as Spring beans. After registering the &lt;code&gt;ConnectionFactory&lt;/code&gt; beans, we injected them into a Camel JMS component configuration. We then defined the Camel JMS component and used it as part of a Camel route to move messages from both ends of the application.&lt;/p&gt; &lt;p&gt;To get started with Red Hat Fuse, &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/jbossnetwork/restricted/listSoftware.html?product=jboss.fuse&amp;#38;downloadType=distributions"&gt;visit the Red Hat Fuse download page&lt;/a&gt;. To learn more about using Red Hat Fuse for message broker integration, see &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/solutions/1173833"&gt;Integrate IBM WebSphere MQ with JBoss Fuse&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;About the author&lt;/h2&gt; &lt;p&gt;Francesco Marchioni is a senior technical account manager for Red Hat Middleware products based in Rome, Italy. Read more about open source contributions to the JBoss developer community at &lt;a target="_blank" rel="nofollow" href="http://www.mastertheboss.com"&gt;mastertheboss.com&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F08%2Fmessage-broker-integration-made-simple-with-red-hat-fuse%2F&amp;#38;linkname=Message%20broker%20integration%20made%20simple%20with%20Red%20Hat%20Fuse" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F08%2Fmessage-broker-integration-made-simple-with-red-hat-fuse%2F&amp;#38;linkname=Message%20broker%20integration%20made%20simple%20with%20Red%20Hat%20Fuse" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F08%2Fmessage-broker-integration-made-simple-with-red-hat-fuse%2F&amp;#38;linkname=Message%20broker%20integration%20made%20simple%20with%20Red%20Hat%20Fuse" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F08%2Fmessage-broker-integration-made-simple-with-red-hat-fuse%2F&amp;#38;linkname=Message%20broker%20integration%20made%20simple%20with%20Red%20Hat%20Fuse" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F08%2Fmessage-broker-integration-made-simple-with-red-hat-fuse%2F&amp;#38;linkname=Message%20broker%20integration%20made%20simple%20with%20Red%20Hat%20Fuse" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F08%2Fmessage-broker-integration-made-simple-with-red-hat-fuse%2F&amp;#38;linkname=Message%20broker%20integration%20made%20simple%20with%20Red%20Hat%20Fuse" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F08%2Fmessage-broker-integration-made-simple-with-red-hat-fuse%2F&amp;#38;linkname=Message%20broker%20integration%20made%20simple%20with%20Red%20Hat%20Fuse" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F08%2Fmessage-broker-integration-made-simple-with-red-hat-fuse%2F&amp;#038;title=Message%20broker%20integration%20made%20simple%20with%20Red%20Hat%20Fuse" data-a2a-url="https://developers.redhat.com/blog/2021/01/08/message-broker-integration-made-simple-with-red-hat-fuse/" data-a2a-title="Message broker integration made simple with Red Hat Fuse"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/08/message-broker-integration-made-simple-with-red-hat-fuse/"&gt;Message broker integration made simple with Red Hat Fuse&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/q9tJPZcfkZ8" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;This article presents a sample integration between Red Hat AMQ 7 and IBM MQ, using Red Hat Fuse 7 for the integration. Traditionally, developers have used resource adapters for message bridging with external systems. A resource adapter is a system library that provides connectivity to an enterprise information system (EIS). Similar to how a Java [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/08/message-broker-integration-made-simple-with-red-hat-fuse/"&gt;Message broker integration made simple with Red Hat Fuse&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/01/08/message-broker-integration-made-simple-with-red-hat-fuse/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">807297</post-id><dc:creator>Francesco Marchioni</dc:creator><dc:date>2021-01-08T08:00:00Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/01/08/message-broker-integration-made-simple-with-red-hat-fuse/</feedburner:origLink></entry><entry><title>Debuginfo is not just for debugging programs</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/UHgw-X9Dhdc/" /><category term="Linux" /><category term="Performance" /><category term="ABI check" /><category term="debuginfo" /><category term="Fedora" /><category term="performance monitoring" /><category term="RHEL" /><author><name>William Cohen</name></author><id>https://developers.redhat.com/blog/?p=783277</id><updated>2021-01-07T08:00:45Z</updated><published>2021-01-07T08:00:45Z</published><content type="html">&lt;p&gt;For a long time at Red Hat, all executables in RPMs were built with debuginfo enabled. While this practice makes it easier for people in support to investigate issues reported using tools such as GDB and crash, there are other important non-debugging uses for the resulting debuginfo.&lt;/p&gt; &lt;p&gt;Debuginfo was named for its initial use. Over time, other applications (such as application binary interface [ABI] compliance checking, data struct layout analysis, and performance monitoring) that use the same information needed for debugging have been developed. It is best to think of the debuginfo as mapping information between the executable that compilers generate and the source code that developers write. It helps humans get crucial information to better understand the executable code actually running their systems, and provides a means of double-checking the compiler&amp;#8217;s and the developers&amp;#8217; work.&lt;/p&gt; &lt;h2&gt;Application binary interface (ABI) checking&lt;/h2&gt; &lt;p&gt;Currently, on Linux, very few applications are monolithic stand-alone binaries. Most binaries make extensive use of shared libraries to leverage the work of other projects and reduce the size of executables. However, for this practice to work, the application binary interfaces (ABIs) provided by the libraries need to be stable. It would be horrible if a Linux distribution updated a shared library used by an application and suddenly the application stopped working as a result. Tools such as &lt;a target="_blank" rel="nofollow" href="https://sourceware.org/libabigail/"&gt;libabigail&lt;/a&gt; compare different versions of a shared library to detect any changes in the ABI.&lt;/p&gt; &lt;p&gt;These ABI checking tools use the debuginfo to determine which functions are available, the functions&amp;#8217; return types, the arguments being passed into the functions, and the data layout of those various types. The debuginfo is a machine-readable mechanism to verify that the ABI has not changed. Without the debuginfo, these checks would not be feasible.&lt;/p&gt; &lt;p&gt;For distributions such as &lt;a href="https://developers.redhat.com/topics/linux"&gt;Red Hat Enterprise Linux&lt;/a&gt; and &lt;a target="_blank" rel="nofollow" href="https://getfedora.org/"&gt;Fedora&lt;/a&gt;, these &lt;a href="https://developers.redhat.com/blog/2017/02/28/abi-change-analysis-of-fedora-packages/"&gt;ABI checks&lt;/a&gt; are essential. ABI checks are done comparing the newer candidate build of packages to previous builds to ensure ABI compatibility. This ensures that other software that relies on those packages will continue to function.&lt;/p&gt; &lt;h2&gt;Data structure layout analysis&lt;/h2&gt; &lt;p&gt;The compiler might insert padding in data structures to ensure that the data structures do not violate the alignment constraints of the target computer architecture. This padding wastes memory. When developers create data structures, they might not be aware of the alignment constraints. Also, there might be different alignment constraints used for certain compiler options and other target processors.&lt;/p&gt; &lt;p&gt;Tools such as pahole in the dwarves package reads the debuginfo describing the data structures and determines where padding has been added. Even on machines with gigabytes of RAM, there can be a great desire to &lt;a href="https://developers.redhat.com/blog/2016/06/01/how-to-avoid-wasting-megabytes-of-memory-a-few-bytes-at-a-time/"&gt;more efficiently organize the data structures to avoid wasting space&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Performance monitoring&lt;/h2&gt; &lt;p&gt;One might want to provide feedback on a program&amp;#8217;s operation in production. This information can provide a baseline of how the program normally operates. It can also provide insights into which areas of the program consume too much time and could be made more efficient. Periodic sampling of the program counter by &lt;a target="_blank" rel="nofollow" href="https://fedoramagazine.org/performance-profiling-perf/"&gt;perf&lt;/a&gt; is a common way of estimating the time spent in various areas of program. However, just having raw samples of program addresses and bytes from the program stack is not useful for developers. Developers want stack backtraces so they can produce &lt;a target="_blank" rel="nofollow" href="http://www.brendangregg.com/flamegraphs.html"&gt;flame graphs&lt;/a&gt; and be able to determine which areas of the source code they need to revise to improve performance of future versions of the software.&lt;/p&gt; &lt;h2&gt;Keep the debuginfo information handy&lt;/h2&gt; &lt;p&gt;These non-debugging uses of the debuginfo can help improve code quality by catching unexpected changes in ABI, unexpected wasted space in data structures, and unexpected inefficient sections of code. The debuginfo does take up space, but there are methods to strip that information from binaries and place it elsewhere so the default binaries are not any larger than binaries compiled without the debuginfo. Thus, it is best to default to compiling code with debuginfo enabled.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F07%2Fdebuginfo-is-not-just-for-debugging-programs%2F&amp;#38;linkname=Debuginfo%20is%20not%20just%20for%20debugging%20programs" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F07%2Fdebuginfo-is-not-just-for-debugging-programs%2F&amp;#38;linkname=Debuginfo%20is%20not%20just%20for%20debugging%20programs" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F07%2Fdebuginfo-is-not-just-for-debugging-programs%2F&amp;#38;linkname=Debuginfo%20is%20not%20just%20for%20debugging%20programs" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F07%2Fdebuginfo-is-not-just-for-debugging-programs%2F&amp;#38;linkname=Debuginfo%20is%20not%20just%20for%20debugging%20programs" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F07%2Fdebuginfo-is-not-just-for-debugging-programs%2F&amp;#38;linkname=Debuginfo%20is%20not%20just%20for%20debugging%20programs" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F07%2Fdebuginfo-is-not-just-for-debugging-programs%2F&amp;#38;linkname=Debuginfo%20is%20not%20just%20for%20debugging%20programs" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F07%2Fdebuginfo-is-not-just-for-debugging-programs%2F&amp;#38;linkname=Debuginfo%20is%20not%20just%20for%20debugging%20programs" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2021%2F01%2F07%2Fdebuginfo-is-not-just-for-debugging-programs%2F&amp;#038;title=Debuginfo%20is%20not%20just%20for%20debugging%20programs" data-a2a-url="https://developers.redhat.com/blog/2021/01/07/debuginfo-is-not-just-for-debugging-programs/" data-a2a-title="Debuginfo is not just for debugging programs"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/07/debuginfo-is-not-just-for-debugging-programs/"&gt;Debuginfo is not just for debugging programs&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/UHgw-X9Dhdc" height="1" width="1" alt=""/&gt;</content><summary type="html">&lt;p&gt;For a long time at Red Hat, all executables in RPMs were built with debuginfo enabled. While this practice makes it easier for people in support to investigate issues reported using tools such as GDB and crash, there are other important non-debugging uses for the resulting debuginfo. Debuginfo was named for its initial use. Over [&amp;#8230;]&lt;/p&gt; &lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2021/01/07/debuginfo-is-not-just-for-debugging-programs/"&gt;Debuginfo is not just for debugging programs&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;</summary><wfw:commentRss xmlns:wfw="http://wellformedweb.org/CommentAPI/">https://developers.redhat.com/blog/2021/01/07/debuginfo-is-not-just-for-debugging-programs/feed/</wfw:commentRss><slash:comments xmlns:slash="http://purl.org/rss/1.0/modules/slash/">0</slash:comments><post-id xmlns="com-wordpress:feed-additions:1">783277</post-id><dc:creator>William Cohen</dc:creator><dc:date>2021-01-07T08:00:45Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2021/01/07/debuginfo-is-not-just-for-debugging-programs/</feedburner:origLink></entry></feed>
