<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>Debugging Python C extensions with GDB</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/F6gwcAQMO0U/debugging-python-c-extensions-gdb" /><author><name>vstinner</name></author><id>d0bbb046-f057-43ce-9365-610b2db82a2d</id><updated>2021-09-08T03:00:00Z</updated><published>2021-09-08T03:00:00Z</published><summary type="html">&lt;p&gt;Many popular &lt;a href="https://developers.redhat.com/topics/python"&gt;Python&lt;/a&gt; modules are written in the &lt;a href="https://developers.redhat.com/topics/c"&gt;C&lt;/a&gt; language, and bugs in C extensions can cause nasty crashes that Python's error-catching mechanism won't catch. Fortunately, numerous powerful debuggers—notably, the &lt;a href="https://www.gnu.org/software/gdb/"&gt;GNU Project Debugger&lt;/a&gt; (GDB)—were designed for the C language. In Python 3.9, developers can use these to debug Python programs, and particularly the C extensions included in Python programs.&lt;/p&gt; &lt;p&gt;This article shows how to use the improved Python debug build in Python 3.9. I'll first discuss how we adapted Python to allow developers to use traditional C debuggers, then show you how to use the debug build and GDB to debug C extensions in a Python program.&lt;/p&gt; &lt;h2&gt;Getting started with Python 3.9&lt;/h2&gt; &lt;p&gt;Python 3.9 is now provided in the &lt;a href="https://developers.redhat.com/products/rhel"&gt;Red Hat Enterprise Linux&lt;/a&gt; 8.4 AppStream. The command to install the new version is:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;$ sudo yum install python3.9 &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Python 3.9 brings many new features:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;PEP 584: Union operators added to dict.&lt;/li&gt; &lt;li&gt;PEP 585:Type hinting generics in standard collections.&lt;/li&gt; &lt;li&gt;PEP 614: Relaxed grammar restrictions on decorators.&lt;/li&gt; &lt;li&gt;PEP 616: String methods to remove prefixes and suffixes.&lt;/li&gt; &lt;li&gt;PEP 593: Flexible function and variable annotations.&lt;/li&gt; &lt;li&gt;A new &lt;code&gt;os.pidfd_open()&lt;/code&gt; call that allows process management without races and signals.&lt;/li&gt; &lt;li&gt;PEP 615: Relocation of the IANA Time Zone Database to the standard library in the zoneinfo module.&lt;/li&gt; &lt;li&gt;An implementation of a topological sort of a graph in the new graphlib module.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;See &lt;a href="https://docs.python.org/3.9/whatsnew/3.9.html"&gt;What’s New In Python 3.9&lt;/a&gt; for the full list of changes.&lt;/p&gt; &lt;h2&gt;Using C debuggers in Python&lt;/h2&gt; &lt;p&gt;When a Python executable is highly optimized, such as the one shipped in RHEL, a typical C debugger doesn't work well. The debugger can't read many helpful pieces of information, such as function arguments, type information, and local variables.&lt;/p&gt; &lt;p&gt;Python does have a built-in fault-handler module that prints the Python traceback when a crash occurs. But when a Python object is corrupted (by a buffer overflow or for any other reason), the executable can continue for a long time before crashing. In this case, knowing the crash location is useless. Usually, the crash occurs during a garbage collection, when Python visits all Python objects. It's therefore hard to guess how the object was corrupted.&lt;/p&gt; &lt;p&gt;Unfortunately, for various reasons, some bugs can be reproduced only on production systems, not on developers' workstations. This adds to the importance of a good debugger.&lt;/p&gt; &lt;p&gt;Python can be built in debug mode, which adds many runtime checks. It helps to detect bugs such as corrupted Python objects. Prior to Python 3.9, a major usability issue was the need to rebuild C extensions in debug mode so they could run with a debug build of Python.&lt;/p&gt; &lt;h2&gt;How we improved the Python debug build&lt;/h2&gt; &lt;p&gt;I have been working for three years on the Python debugging experience to make it easier to use a C-language debugger such as GDB on Python. This section discusses the changes to Python that were required.&lt;/p&gt; &lt;h3&gt;ABI compatibility&lt;/h3&gt; &lt;p&gt;The first practical issue was that C extensions needed to be rebuilt in debug mode to be able to use a Python debug build.&lt;/p&gt; &lt;p&gt;I made the Python debug build compatible at an application binary interface (ABI) level with the Python release build in &lt;a href="https://bugs.python.org/issue36465"&gt;Python issue 36465&lt;/a&gt;. The main &lt;code&gt;PyObject&lt;/code&gt; C structure is now the same in release and debug builds.&lt;/p&gt; &lt;p&gt;The debug build no longer defines the &lt;code&gt;Py_TRACE_REFS&lt;/code&gt; macro, which caused the ABI incompatibility. If you want the macro, you need to explicitly request it through the &lt;code&gt;./configure --with-trace-refs&lt;/code&gt; build option. See the &lt;a href="https://github.com/python/cpython/commit/f4e4703e746067d6630410408d414b11003334d6"&gt;commit&lt;/a&gt; for more details.&lt;/p&gt; &lt;h3&gt;C extensions are no longer linked to libpython&lt;/h3&gt; &lt;p&gt;Another issue was that C extensions were linked to libpython. When a C extension was built in release mode and imported into a Python executable that was built in debug mode, the extension pulled in a version of libpython built in release mode, which was incompatible.&lt;/p&gt; &lt;p&gt;Python functions such as &lt;code&gt;PyLong_FromLong()&lt;/code&gt; are already loaded in the running Python process. C extensions inherit these symbols when their dynamic libraries are loaded. Therefore, linking C extensions to libpython explicitly is not strictly required.&lt;/p&gt; &lt;p&gt;I modified how C extensions are built in Python 3.8 so the extensions are no longer linked to libpython: See &lt;a href="https://bugs.python.org/issue21536"&gt;Python issue 21536&lt;/a&gt;. Some RHEL packages contained C extensions that linked to libpython manually; these had to be modified further.&lt;/p&gt; &lt;h3&gt;Compiler optimizations disabled in the debug build&lt;/h3&gt; &lt;p&gt;Last but not least, the Python package was modified to build Python in debug mode with &lt;code&gt;gcc -O0&lt;/code&gt; rather than &lt;code&gt;gcc -Og&lt;/code&gt;. The &lt;code&gt;-Og&lt;/code&gt; option is meant to allow some optimizations that don't interfere with debug information. In practice, GDB is fully usable only on an executable built with &lt;code&gt;-O0&lt;/code&gt;, which disables all compiler optimizations.&lt;/p&gt; &lt;h2&gt;Debugging with GBD in Python 3.9&lt;/h2&gt; &lt;p&gt;The Python 3.9 debug build shipped with RHEL 8.4 combines all of these enhancements and is now usable with debuggers. A Python 3.9 executable built in debug mode can import C extensions built in release mode. In short, the &lt;code&gt;python3.9d&lt;/code&gt; executable can be used as a seamless drop-in replacement for the usual &lt;code&gt;python3.9&lt;/code&gt; to help you run a debug session.&lt;/p&gt; &lt;p&gt;A special debug build of Python can work with a C debugger pretty much like a C program. This section shows how to use GDB to debug a Python program, plus some special debugger commands Python provides.&lt;/p&gt; &lt;h3&gt;Before: Trying GDB on a Python release build&lt;/h3&gt; &lt;p&gt;Before showing how debugging works better with the new Python 3.9 debug build, let's start with the release build, which is not usable with GDB.&lt;/p&gt; &lt;p&gt;First, install GDB and the Python 3.9 debug symbols:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;$ sudo yum install gdb $ sudo yum debuginfo-install python39 &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Create a simple Python program named &lt;code&gt;slow.py&lt;/code&gt; to play with GDB:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;import time def slow_function(): print("Slow function...") x = 3 time.sleep(60 * 10) slow_function() &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Debug &lt;code&gt;slow.py&lt;/code&gt; in GDB and interrupt it with &lt;kbd&gt;Ctrl&lt;/kbd&gt;+&lt;kbd&gt;C&lt;/kbd&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;$ gdb -args python3.9 slow.py (gdb) run Slow function... ^C Program received signal SIGINT, Interrupt. 0x00007ffff7b790e7 in select () from /lib64/libc.so.6 (gdb) where #0 select () from /lib64/libc.so.6 #1 pysleep (secs=&lt;optimized out&gt;) at .../Modules/timemodule.c:2036 #2 time_sleep (self=&lt;optimized out&gt;, obj=&lt;optimized out&gt;, self=&lt;optimized out&gt;, obj=&lt;optimized out&gt;) at .../Modules/timemodule.c:365 (...) #7 _PyEval_EvalFrameDefault (tstate=&lt;optimized out&gt;, f=&lt;optimized out&gt;, throwflag=&lt;optimized out&gt;) at .../Python/ceval.c:3487 3487 res = call_function(tstate, &amp;sp, oparg, NULL); (...) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;&lt;em&gt;Note: The previous GDB output was reformatted and truncated to make it easier to read.&lt;/em&gt;&lt;/p&gt; &lt;p&gt;If you try to explore the problem, you find that GDB fails to read the function arguments in &lt;code&gt;pysleep()&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;(gdb) frame 1 #1 0x00007ffff757769a in pysleep (secs=&lt;optimized out&gt;) at .../Modules/timemodule.c:2036 2036 err = select(0, (fd_set *)0, (fd_set *)0, (fd_set *)0, &amp;timeout); (gdb) p secs $1 = &lt;optimized out&gt; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;GDB also fails to read &lt;code&gt;_PyEval_EvalFrameDefault()&lt;/code&gt; local variables:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;(gdb) frame 7 #7 _PyEval_EvalFrameDefault (tstate=&lt;optimized out&gt;, f=&lt;optimized out&gt;, throwflag=&lt;optimized out&gt;) at .../Python/ceval.c:3487 3487 res = call_function(tstate, &amp;sp, oparg, NULL); (gdb) p opcode $11 = &lt;optimized out&gt; (gdb) p oparg $10 = &lt;optimized out&gt; &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;In the previous output, GDB displays &lt;code&gt;&lt;optimized out&gt;&lt;/code&gt;, rather than expected values. Usually, this means that CPU registers are used for these values. Since CPU registers are used for multiple purposes, GDB cannot guess whether the register currently contains the specified function argument or variable or something else.&lt;/p&gt; &lt;p&gt;In addition, the &lt;code&gt;python3.9&lt;/code&gt; executable is built in release mode with link time optimization (LTO), profile guided optimization (PGO), and &lt;code&gt;gcc -O2&lt;/code&gt; optimizations. Because of these optimizations, when debugged functions get inlined by the compiler, GDB's &lt;code&gt;where&lt;/code&gt; command can display invalid call stacks.&lt;/p&gt; &lt;h3&gt;After: Using GDB on the new debug build&lt;/h3&gt; &lt;p&gt;Now install the new Python 3.9 debug build:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;$ sudo yum module enable --enablerepo=rhel-CRB python39-devel $ sudo yum install --enablerepo=rhel-CRB python39-debug $ sudo yum debuginfo-install python39-debug &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;These commands enable the &lt;code&gt;python39-devel&lt;/code&gt; module, install the &lt;code&gt;python39-debug&lt;/code&gt; package from this module, and then install debug symbols. The &lt;a href="https://developers.redhat.com/blog/2018/11/15/introducing-codeready-linux-builder"&gt;Red Hat CodeReady Linux Builder&lt;/a&gt; repository is enabled in these commands to get the &lt;code&gt;python39-devel&lt;/code&gt; module.&lt;/p&gt; &lt;p&gt;Now, run GDB again to debug the same &lt;code&gt;slow.py&lt;/code&gt; program, but using &lt;code&gt;python3.9d&lt;/code&gt;. Again, interrupt the program with &lt;kbd&gt;Ctrl&lt;/kbd&gt;+&lt;kbd&gt;C&lt;/kbd&gt;:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;$ gdb -args python3.9d slow.py (gdb) run Slow function... ^C Program received signal SIGINT, Interrupt. select () from /lib64/libc.so.6 (gdb) where #0 select () from /lib64/libc.so.6 #1 pysleep (secs=600000000000) at .../Modules/timemodule.c:2036 #2 time_sleep (self=&lt;module at remote 0x7ffff7eb73b0&gt;, obj=600) at .../Modules/timemodule.c:365 (...) #7 _PyEval_EvalFrameDefault (tstate=0x55555575a7e0, f=Frame 0x7ffff7ecb850, for file slow.py, line 5, in slow_function (x=3), throwflag=0) at .../Python/ceval.c:3487 (...) &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Reading the &lt;code&gt;pysleep()&lt;/code&gt; function arguments now gives the expected values:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;(gdb) frame 1 #1 0x00007ffff754c156 in pysleep (secs=600000000000) at .../Modules/timemodule.c:2036 2036 err = select(0, (fd_set *)0, (fd_set *)0, (fd_set *)0, &amp;timeout); (gdb) p secs $1 = 600000000000 &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Reading &lt;code&gt;_PyEval_EvalFrameDefault()&lt;/code&gt; local variables now also gives the expected values:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;(gdb) frame 7 #7 _PyEval_EvalFrameDefault (...) 3487 res = call_function(tstate, &amp;sp, oparg, NULL); (gdb) p opcode $2 = 161 (gdb) p oparg $3 = 1 &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;As you can see, the &lt;code&gt;&lt;optimized out&gt;&lt;/code&gt; messages are gone. GDB works as expected thanks to the new executable built without compiler optimizations.&lt;/p&gt; &lt;h2&gt;Python commands in GDB&lt;/h2&gt; &lt;p&gt;Python comes with a &lt;code&gt;libpython3.9(...)-gdb.py&lt;/code&gt; gdb extension (implemented in Python) that adds GDB commands prefixed by &lt;code&gt;py-&lt;/code&gt;. Expanding this prefix with the tab key shows the available commands:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;(gdb) py-&lt;tab&gt;&lt;tab&gt; py-bt py-bt-full py-down py-list py-locals py-print py-up &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;py-bt&lt;/code&gt; command displays the Python call stack:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;(gdb) py-bt Traceback (most recent call first): File "slow.py", line 5, in slow_function time.sleep(60 * 10) File "slow.py", line 6, in &lt;module&gt; slow_function() &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;py-locals&lt;/code&gt; command lists Python local variables:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;(gdb) py-locals x = 3 &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The &lt;code&gt;py-print&lt;/code&gt; command gets the value of a Python variable:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;(gdb) py-print x local 'x' = 3 &lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Additional debug checks&lt;/h2&gt; &lt;p&gt;Before the program even runs its first statement, a debug build of Python can detect potential problems. When Python is built in debug mode, many debug checks are executed at runtime to detect bugs in C extensions. For example:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Debug hooks are installed on memory allocators to detect buffer overflows and other memory errors.&lt;/li&gt; &lt;li&gt;Assertions are made on various function arguments.&lt;/li&gt; &lt;li&gt;The garbage collector (&lt;code&gt;gc.collect()&lt;/code&gt; function) runs some checks on objects' consistency.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;See the &lt;a href="https://docs.python.org/dev/using/configure.html#python-debug-build"&gt;Python debug build&lt;/a&gt; web page for more details.&lt;/p&gt; &lt;h2&gt;Red Hat contributions to the Python debug build&lt;/h2&gt; &lt;p&gt;Red Hat contributed the following changes to Python upstream to enhance the Python debug build:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Adding assertions in the garbage collection module to make debugging easier with corrupted Python objects: See &lt;a href="https://bugs.python.org/issue9263"&gt;Python issue 9263&lt;/a&gt;. These enhancements were written by Dave Malcolm, maintained as downstream patches in Red Hat Enterprise Linux and Fedora, and pushed upstream in Python 3.8 in 2018. The change adds a new &lt;code&gt;_PyObject_ASSERT()&lt;/code&gt; function that dumps the Python object that caused the assertion failure.&lt;/li&gt; &lt;li&gt;Detecting freed memory to avoid crashes when debugging Python: I added &lt;code&gt;_PyObject_IsFreed()&lt;/code&gt; and &lt;code&gt;_PyMem_IsFreed()&lt;/code&gt; functions. The &lt;code&gt;visit_decref()&lt;/code&gt; function used by the Python garbage collector now detects freed memory and dumps the parent object on an attempt to access that memory: see &lt;a href="https://bugs.python.org/issue9263"&gt;Python issue 9263&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Maintenance of &lt;code&gt;python-gdb.py&lt;/code&gt; and associated &lt;code&gt;test_gdb&lt;/code&gt; regression tests: See &lt;a href="https://bugs.python.org/issue34989"&gt;Python issue 34989&lt;/a&gt;.&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;Python now works quite well with powerful open source debuggers such as GDB. We suggest you try out a Python debug build and GDB when you encounter a problem, especially a segmentation fault caused by a C extension to Python.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/09/08/debugging-python-c-extensions-gdb" title="Debugging Python C extensions with GDB"&gt;Debugging Python C extensions with GDB&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/F6gwcAQMO0U" height="1" width="1" alt=""/&gt;</summary><dc:creator>vstinner</dc:creator><dc:date>2021-09-08T03:00:00Z</dc:date><feedburner:origLink>https://developers.redhat.com/articles/2021/09/08/debugging-python-c-extensions-gdb</feedburner:origLink></entry><entry><title type="html">Shopping recommendations in PMML – Kogito at Work</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/gzNKkD0C9pA/shopping-recommendations-in-pmml-kogito-at-work.html" /><author><name>Gabriele Cardosi</name></author><id>http://feeds.athico.com/~r/droolsatom/~3/R6etf8YFoEs/shopping-recommendations-in-pmml-kogito-at-work.html</id><updated>2021-09-07T14:28:42Z</updated><content type="html">In a previous post () we built the main infrastructure for making personalized shopping recommendations depending on the customer shopping history. The was meant to demonstrate a standalone implementation of the engine. In this post, we will show how to invoke the engine on a remote Kogito instance. Kogito is designed from the ground up to run at scale on cloud infrastructure, which means it is dedicated to developing cloud-native applications. A Kogito service may be deployed as a standalone microservice or inside a container, like Kubernetes. Besides that, its native compilation makes it extremely fast. The overall architecture and design of the Kogito environment are out of the scope of the current post: the reader may find full documentation . KOGITO SETUP A detailed explanation of how to create and run a Kogito service is out of scope from the current post. Again, the reader may refer to . Simply put, the following three steps are required: 1. create a Maven project with Kogito dependencies 2. add the model file (cluster_buyer_predictor.pmml in our case) in the “resources folder 3. start the Kogito service (we will use Quarkus environment in this post) We will call the project "kogito-pmml-recommender", and sources are available . After issuing the command mvn clean compile quarkus:dev to service will be up and running, listening on port 8080. The endpoint for our model will be "KMeans" (the name of the model as defined inside cluster_buyer_predictor.pmml) More details about usage of inside Kogito may be found . REST INVOCATION It is possible to use the REST API to actually invoke the running engine, sending a POST request. The JSON content of such a post should contain the input data for the Trusty-PMML engine. As we may recall from the previous post, such data is a 30-sized array of doubles with only "0.0" or "1.0". This is an excerpt of that json: { "0": 0.0, "1": 1.0, "2": 0.0, ... "28": 0.0, "29": 1.0 } Request details are: POST http://localhost:8080/KMeans Content-Type: application/json and curl equivalent is: curl -X POST -H 'Accept: application/json' -H 'Content-Type: application/json' --data @commands/ClusterBuyerPredictor.json 'http://localhost:8080/KMeans (the above curl invocation requires a "ClusterBuyerPredictor.json" file with the content listed before). The already contains the . JAVA-CLIENT INVOCATION Kogito services are exposed as standard REST endpoints, so the java client application simply needs to use an HTTP Client. The project is a modified version of the we saw in the previous post, with the only difference being that it features the HTTP client to retrieve predictions with a remote invocation to the Kogito service. As a matter of fact, there are only a couple of required modifications: 1. fix dependencies inside , i.e. remove compilation-related ones 2. modify the class to use the http client to make a remote invocation. SUM UP In this post, we have tackled a real-world recommendation scenario using the PMML and Trusty-PMML engine inside a Kogito microservice. First, we have created a Kogito service project, basically containing only the cluster_buyer_predictor.pmml. Then, we have provided a brief explanation on how to make a simple HTTP request to it. Last, we have shown a bare-bone java project that, featuring a standard java HTTP client, is able to provide reliable recommendations. But this is just to scratch the potentialities that the couple Trusty PMML + Kogito may offer. This explains how to use Kogito inside Kubernets, while this shows how to deploy a Quarkus microservice as AWS lambda. Stay tuned! The post appeared first on .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/gzNKkD0C9pA" height="1" width="1" alt=""/&gt;</content><dc:creator>Gabriele Cardosi</dc:creator><feedburner:origLink>http://feeds.athico.com/~r/droolsatom/~3/R6etf8YFoEs/shopping-recommendations-in-pmml-kogito-at-work.html</feedburner:origLink></entry><entry><title>Build a Kubernetes Operator in six steps</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/1QJ_EThzyfI/build-kubernetes-operator-six-steps" /><author><name>Deepak Sharma</name></author><id>77edefc1-7afc-4f6d-86a8-ac9d38ee6c44</id><updated>2021-09-07T03:00:00Z</updated><published>2021-09-07T03:00:00Z</published><summary type="html">&lt;p&gt;&lt;a href="https://developers.redhat.com/topics/kubernetes/operators"&gt;Operators&lt;/a&gt; greatly increase the power of &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; as an environment and orchestration tool for running scalable applications This article shows you how to create your own Kubernetes Operator. Although production applications often run in the cloud, you don't need a cloud service for the tutorial; you'll download everything you need onto a local system.&lt;/p&gt; &lt;p&gt;This article is an update to one I wrote last year, &lt;a href="https://developers.redhat.com/blog/2020/08/21/hello-world-tutorial-with-kubernetes-operators"&gt;'Hello, World' tutorial with Kubernetes Operators&lt;/a&gt;. Architecture upgrades in the Kubernetes Operator SDK (in version 0.20) put that article out of date. This tutorial takes you on the journey of writing your first Kubernetes Operator using Kubernetes Operator SDK 1.11+.&lt;/p&gt; &lt;h2&gt;The role and behavior of Kubernetes Operators&lt;/h2&gt; &lt;p&gt;A Kubernetes Operator manages your application's logistics. It contains code called a &lt;em&gt;controller&lt;/em&gt; that runs periodically and checks the current state of your service's namespaced resources against the desired state. If the controller finds any differences, it restores your service to the desired state in a process called &lt;em&gt;reconciliation&lt;/em&gt;. For instance, if a resource crashed, the controller restarts it.&lt;/p&gt; &lt;p&gt;You can imagine an unofficial agreement between you and the Kubernetes Operator:&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;You&lt;/strong&gt;: "Hey Opo, I am creating the following resources. Now it's your responsibility to keep them running."&lt;/p&gt; &lt;p class="Indent1"&gt;&lt;strong&gt;Operator&lt;/strong&gt;: "Roger that! Will check back regularly."&lt;/p&gt; &lt;p&gt;You can build an operator with Helm Charts, Ansible playbooks, or Golang. In this article, we use Golang. We'll focus on a namespace-scoped operator (as opposed to a cluster-scoped operator) because it's more flexible, and because we want to control only our own application. See the &lt;a href="https://developers.redhat.com/articles/2021/06/11/kubernetes-operators-101-part-1-overview-and-key-features"&gt;Kubernetes Operators 101&lt;/a&gt; series for more background on operators.&lt;/p&gt; &lt;p&gt;Now we'll create an operator. Let's go ...&lt;/p&gt; &lt;h2&gt;Setup and prerequisites&lt;/h2&gt; &lt;p&gt;We'll start by getting these resources on your system:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;The &lt;a href="https://golang.org/dl/"&gt;Go&lt;/a&gt; language (Golang)&lt;/li&gt; &lt;li&gt;The &lt;a href="https://minikube.sigs.k8s.io/docs/start/"&gt;Minikube&lt;/a&gt; environment for running Kubernetes locally&lt;/li&gt; &lt;li&gt;The &lt;a href="https://v1-11-x.sdk.operatorframework.io/docs/installation/"&gt;Kubernetes Operator SDK 1.11+&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;For prerequisites, I recommend the following&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Some programming language experience. This example uses Golang, so some knowledge of that language would be helpful but is not required.&lt;/li&gt; &lt;li&gt;Patience (very important).&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;Let's set up the software requirements.&lt;/p&gt; &lt;h3&gt;Installing Golang&lt;/h3&gt; &lt;p&gt;Get Golang from the &lt;a href="https://golang.org/dl/"&gt;Golang download site&lt;/a&gt;, then configure the following environment variable:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$GOPATH=/your/preferred/path/&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Next, verify the installation:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;# Verify $ go version go version go1.16.3 linux/amd64 &lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Setting up a cluster on Minikube&lt;/h3&gt; &lt;p&gt;After downloading &lt;a href="https://minikube.sigs.k8s.io/docs/start/"&gt;Minikube&lt;/a&gt;, make sure it is properly installed and running:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ minikube status minikube type: Control Plane host: Running kubelet: Running apiserver: Running kubeconfig: Configured&lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Setting up the Operator SDK&lt;/h3&gt; &lt;p&gt;&lt;a href="https://sdk.operatorframework.io/docs/installation/"&gt;Install the Operator SDK&lt;/a&gt;, then verify that it is installed:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;# Verify $ operator-sdk version operator-sdk version: "v1.11.0", commit: "28dcd12a776d8a8ff597e1d8527b08792e7312fd", kubernetes version: "1.20.2", go version: "go1.16.7", GOOS: "linux", GOARCH: "amd64" &lt;/code&gt;&lt;/pre&gt; &lt;h2 id="build_the_operator-h2"&gt;Build the Kubernetes Operator&lt;/h2&gt; &lt;p&gt;Now we'll build our Kubernetes Operator in just six steps. I provide a link to the code for you to download at each step.&lt;/p&gt; &lt;h3&gt;Step 1: Generate boilerplate code&lt;/h3&gt; &lt;p&gt;To create your local cluster, run the &lt;code&gt;minikube start&lt;/code&gt; command:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;$ mkdir -p $GOPATH/src/operators &amp;&amp; cd $GOPATH/src/operators $ minikube start init&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Then run &lt;code&gt;operator-sdk init&lt;/code&gt; to generate the boilerplate code for our example application:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;$ operator-sdk init&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The &lt;a href="https://github.com/deepak1725/hello-operator2/commit/d37dd4ea3035a26889d3028d58e7f2da1220a5cb" target="_blank"&gt;code for this step&lt;/a&gt; is available in my Hello Operator GitHub repository.&lt;/p&gt; &lt;h3&gt;Step 2: Create APIs and a custom resource&lt;/h3&gt; &lt;p&gt;In Kubernetes, the functions exposed for each service you want to provide are grouped together in a &lt;em&gt;resource&lt;/em&gt;. Thus, when we create the APIs for our application, we also create their resource through a &lt;a href="https://access.redhat.com/documentation/en-us/openshift_container_platform/3.7/html/cluster_administration/admin-guide-custom-resources"&gt;CustomResourceDefinition&lt;/a&gt; (CRD).&lt;/p&gt; &lt;p&gt;The following command creates an API and labels it &lt;code&gt;Traveller&lt;/code&gt; through the &lt;code&gt;--kind&lt;/code&gt; option. In the YAML configuration files created by the command, you can find a field labeled &lt;code&gt;kind&lt;/code&gt; with the value &lt;code&gt;Traveller&lt;/code&gt;. This field indicates that &lt;code&gt;Traveller&lt;/code&gt; is used throughout the development process to refer to our APIs:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;$ operator-sdk create api --version=v1alpha1 --kind=Traveller Create Resource [y/n] y Create Controller [y/n] y ... ...&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;We have asked the command also to create a controller to handle all operations corresponding to our &lt;code&gt;kind&lt;/code&gt;. The file defining the controller is named &lt;code&gt;traveller_controller.go&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;--version&lt;/code&gt; option can take any string, and you can set it to track your development on a project. Here, we've started with a modest value, indicating that our application is in alpha.&lt;/p&gt; &lt;p&gt;The &lt;a href="https://github.com/deepak1725/hello-operator2/commit/5d18c604bf82be02f4bcfa49f12c33541b704d92" target="_blank"&gt;code for this step&lt;/a&gt; is available in the Hello Operator GitHub repository.&lt;/p&gt; &lt;h3&gt;Step 3: Download the dependencies&lt;/h3&gt; &lt;p&gt;Our application uses the &lt;code&gt;tidy&lt;/code&gt; module to remove dependencies we don't need, and the &lt;code&gt;vendor&lt;/code&gt; module &lt;a href="https://golang.org/ref/mod#vendoring"&gt;to consolidate packages&lt;/a&gt;. Install these modules as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ go mod tidy $ go mod vendor&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The &lt;a href="https://github.com/deepak1725/hello-operator2/commit/98e4ebc8532696b1f65e5471fd49b1b54c7f1031" target="_blank"&gt;code for this step&lt;/a&gt; is available in the Hello Operator GitHub repository.&lt;/p&gt; &lt;h3&gt;Step 4: Create a deployment&lt;/h3&gt; &lt;p&gt;Now we will create, under our Kubernetes Operator umbrella, the standard resources that make up a containerized application. Because a Kubernetes Operator runs iteratively to reconcile the state of your application, it's very important to write the controller to be idempotent: In other words, the controller can run the code multiple times without creating multiple instances of a resource.&lt;/p&gt; &lt;p&gt;The following repo includes a controller for a deployment resource in the file &lt;code&gt;controllers/deployment.go&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;The &lt;a href="https://github.com/deepak1725/hello-operator2/commit/c87544405b8359da2007317112bb64e434330f5f" target="_blank"&gt;code for this step&lt;/a&gt; is available in the Hello Operator GitHub repository.&lt;/p&gt; &lt;h3&gt;Step 5: Create a service&lt;/h3&gt; &lt;p&gt;Because we want the pods created by our deployment to be accessible outside our system, we attach a service to the deployment we just created. The code is in the file &lt;code&gt;controllers/service.go&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;The &lt;a href="https://github.com/deepak1725/hello-operator2/commit/b17c24f7abd75328aa1549b0afb6c6bcb1ca8f61" target="_blank"&gt;code for this step&lt;/a&gt; is available in the Hello Operator GitHub repository.&lt;/p&gt; &lt;h3&gt;Step 6: Add a reference in the controller&lt;/h3&gt; &lt;p&gt;This step lets our controller know the existence of the deployment and service. It does this through edits to the reconciliation loop function of the &lt;code&gt;traveller_controller.go&lt;/code&gt; file.&lt;/p&gt; &lt;p&gt;Find the &lt;a href="https://github.com/deepak1725/hello-operator2/commit/324a56116aa561bf44b34402287edbfa87131cc6" target="_blank"&gt;code for this step&lt;/a&gt; in the Hello Operator GitHub repository.&lt;/p&gt; &lt;p&gt;Now, perhaps it's time for a hydration break. Then we'll try out our service.&lt;/p&gt; &lt;h2&gt;Deploy the service&lt;/h2&gt; &lt;p&gt;There are multiple ways to deploy our CRD:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Run the server locally.&lt;/li&gt; &lt;li&gt;Run the server in a cluster.&lt;/li&gt; &lt;li&gt;Deploy the service via an &lt;a href="https://developers.redhat.com/blog/2021/02/08/deploying-kubernetes-operators-with-operator-lifecycle-manager-bundles"&gt;Operator Lifecycle Manager (OLM) bundle&lt;/a&gt;.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;For the sake of brevity, we will run the service locally.&lt;/p&gt; &lt;h3&gt;Installing the CRD&lt;/h3&gt; &lt;p&gt;All we have to do to deploy our hard work locally is to run a build:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ make install&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This command registers our custom kind schema (&lt;code&gt;Traveller&lt;/code&gt; in this case) within our Kubernetes cluster. Now any new request specifying this kind will be forwarded to our &lt;code&gt;Traveller&lt;/code&gt; controller internally.&lt;/p&gt; &lt;p&gt;You will find the &lt;a href="https://github.com/deepak1725/hello-operator2/commit/31dc35d73b2f2a89b7e1868a4c04bb4012fc66f4" target="_blank"&gt;code for this step&lt;/a&gt; in the Hello Operator GitHub repository.&lt;/p&gt; &lt;h3&gt;Deploying a CRD instance&lt;/h3&gt; &lt;p&gt;We still have to enable our resource in Kubernetes. Queue up a request to create our resource through the following command:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ kustomize build config/samples | kubectl apply -f -&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;At this stage, our Kubernetes cluster is aware of our &lt;code&gt;Traveller&lt;/code&gt; CRD. Spin up the controller:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ make run&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;This command will execute the reconciliation function in &lt;code&gt;traveller_controller.go&lt;/code&gt;, which in turn creates our deployment and service resources.&lt;/p&gt; &lt;h2&gt;Run the Kubernetes Operator&lt;/h2&gt; &lt;p&gt;Now we will dive into our local cluster and check its behavior.&lt;/p&gt; &lt;h3&gt;Checking the state&lt;/h3&gt; &lt;p&gt;Make sure that the resources are running:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;$ kubectl get all NAME READY STATUS RESTARTS AGE pod/hello-pod-6bbd776b6d-cxp46 1/1 Running 0 6m4s NAME TYPE CLUSTER-IP EXTERNAL-IP PORT(S) AGE service/backend-service NodePort 10.xx.xxx.xxx &lt;none&gt; 80:30685/TCP 6m4s service/kubernetes ClusterIP 10.xx.0.1 &lt;none&gt; 443/TCP 168m NAME READY UP-TO-DATE AVAILABLE AGE deployment.apps/hello-pod 1/1 1 1 6m4s NAME DESIRED CURRENT READY AGE replicaset.apps/hello-pod-6bbd776b6d 1 1 1 6m4s &lt;/code&gt;&lt;/pre&gt; &lt;h3&gt;Exposing the service&lt;/h3&gt; &lt;p&gt;Open our newly created service in a browser as follows:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ minikube service backend-service |-----------|-----------------|-------------|---------------------------| | NAMESPACE |      NAME       | TARGET PORT |            URL            | |-----------|-----------------|-------------|---------------------------| | default   | backend-service |          80 | http://192.168.49.2:30685 | |-----------|-----------------|-------------|---------------------------| ? Opening service default/backend-service in default browser... ➜ ~ Opening in existing browser session.&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;The browser screen looks like Figure 1. Congratulations—you have just deployed your first Kubernetes Operator.&lt;/p&gt; &lt;figure role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/hello_screen.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/hello_screen.png?itok=6PCXCplB" width="600" height="158" alt="When fully deployed, the service shows a Hello World screen." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1: The screen displayed by running a service. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;Operators extend Kubernetes APIs and create custom objects in the cluster. This feature of Kubernetes opens a number of avenues for developers to customize the cluster in a manner best suited for our application and environment. This article only touched on the power of Kubernetes Operators in a minimal way. They are capable of doing far more than what we accomplished here. I encourage you to take this article as a starting point for building awesome Kubernetes Operators.&lt;/p&gt; &lt;p&gt;I hope you enjoyed the journey.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/09/07/build-kubernetes-operator-six-steps" title="Build a Kubernetes Operator in six steps"&gt;Build a Kubernetes Operator in six steps&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/1QJ_EThzyfI" height="1" width="1" alt=""/&gt;</summary><dc:creator>Deepak Sharma</dc:creator><dc:date>2021-09-07T03:00:00Z</dc:date><feedburner:origLink>https://developers.redhat.com/articles/2021/09/07/build-kubernetes-operator-six-steps</feedburner:origLink></entry><entry><title type="html">Quarkus 2.2.2.Final released - Maintenance release</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/p3qJ_uGDvMs/" /><author><name>Guillaume Smet</name></author><id>https://quarkus.io/blog/quarkus-2-2-2-final-released/</id><updated>2021-09-07T00:00:00Z</updated><content type="html">Today, we released Quarkus 2.2.2.Final, a maintenance release for our 2.2 release train containing bugfixes and documentation improvements. It is a safe upgrade for anyone already using 2.2. If you are not using 2.2 already, please refer to the 2.2 migration guide. Full changelog You can get the full changelog...&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/p3qJ_uGDvMs" height="1" width="1" alt=""/&gt;</content><dc:creator>Guillaume Smet</dc:creator><feedburner:origLink>https://quarkus.io/blog/quarkus-2-2-2-final-released/</feedburner:origLink></entry><entry><title>Improving CI/CD in Red Hat OpenShift</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/_jGHs2l6LJg/improving-cicd-red-hat-openshift" /><author><name>Brigid Gliwa</name></author><id>82c3df91-7d61-4564-847b-a599f5f2a9ad</id><updated>2021-09-06T03:00:00Z</updated><published>2021-09-06T03:00:00Z</published><summary type="html">&lt;p&gt;Red Hat recently conducted a &lt;a href="https://cloud.redhat.com/blog/introduction-to-customer-empathy-workshops"&gt;Customer Empathy Workshop series&lt;/a&gt; that included two virtual workshops focused on continuous integration and continuous delivery (&lt;a href="https://developers.redhat.com/topics/ci-cd"&gt;CI/CD&lt;/a&gt;) tooling within &lt;a href="https://developers.redhat.com/openshift"&gt;Red Hat OpenShift&lt;/a&gt;. The Red Hat User Experience Design team partnered with Product Management and Engineering to engage 22 OpenShift customers from seven different companies.&lt;/p&gt; &lt;p&gt;During each workshop, we used digital whiteboards and video conferencing to virtually engage customers in hands-on activities. We used the first three steps of the classic design thinking—empathize, define, and ideate—to identify and understand problems as well as suggest solutions. Let’s take a look at what we learned.&lt;/p&gt; &lt;h2&gt;Problems and pain points with CI/CD&lt;/h2&gt; &lt;p&gt;We began the workshops by asking participants to introduce themselves in order to help break the ice and get to know each other. Each customer shared their role and responsibilities, the CI/CD tools they use, and what they were looking forward to in the workshop. After everyone got the chance to share, we dove into the first step of design thinking: Empathize. Although we couldn’t use sticky notes and Sharpies as we do in person, participants were able to use digital whiteboarding to write down their problems and pain points when they use CI/CD tooling within OpenShift. We reviewed the participants’ pain points to find similarities and identify common themes.&lt;/p&gt; &lt;p&gt;Figure 1 lists some of those themes, followed by a list that includes paraphrased responses from customers.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/Bucket%20stacks.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/Bucket%20stacks.png?itok=neW92pmj" width="600" height="596" alt="Nine themes were raised by customers in the design workshop." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1: Themes from design workshop. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;ul&gt;&lt;li&gt;&lt;strong&gt;Tekton limitations&lt;/strong&gt;: "Passing data through a Tekton Pipeline is cumbersome and chatty. Tekton also lacks the capability for human confirmation in pipelines."&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Argo CD&lt;/strong&gt;: "We need better integration of Argo CD, Helm, and Tekton."&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Multitenancy&lt;/strong&gt;: "Multitenancy and Kubernetes RBAC should be enforced in tools."&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Pipeline as code&lt;/strong&gt;: "Our developers would like simple pipeline definitions, such as GitHub Actions or Travis. It is difficult to share pipelines or parts of the pipeline."&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Metrics and gates:&lt;/strong&gt; "We are unable to track test results across consecutive runs. OpenShift lacks the ability to set up gates for the pipeline."&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Best practices&lt;/strong&gt;: "What is Red Hat's ideal CI/CD architecture? How could we get feedback from OpenShift in our CI/CD tooling?"&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Triggers&lt;/strong&gt;: "Tekton EventListeners are not protected with authentication or OAuth. EventListeners also can't override default parameters of pipelines."&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Delivering secrets&lt;/strong&gt;: "There is no secret handling in Argo CD or OpenShift GitOps and integrating with an external vault is not easy. Secrets do not work well in resource-constrained clusters."&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Multicluster management&lt;/strong&gt;: "We need Git repo management for Argo CD and synching of multiple clusters, along with configuration as code."&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;How might we improve CI/CD?&lt;/h2&gt; &lt;p&gt;The next step in the design thinking process is to define the problem. In this step, we grouped our issues into different themes and selected a few to focus on for the remainder of the workshop. We used these key themes to define problem statements in the format of "How might we" statements. Reframing the problem into a "How might we" statement helped to shift our perspective from challenges to opportunities. Figure 2 shows the problem statements we created and groups some participant observations within each statement.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/Pain%20point%20graphic_0.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/Pain%20point%20graphic_0.png?itok=gU4pKeCD" width="600" height="550" alt="For five areas identified as "pain points," several projects were found that could improve them." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 2: Pain points and projects that can address them. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;The statements are as follows:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;How might we make it easier to onboard and use Tekton Pipelines effectively?&lt;/li&gt; &lt;li&gt;How might we make it easier to learn how to leverage Argo CD effectively?&lt;/li&gt; &lt;li&gt;How might we share parts of pipelines more easily?&lt;/li&gt; &lt;li&gt;How might we offer a flexible way to customize pipeline metrics and react to them?&lt;/li&gt; &lt;li&gt;How might we get more information about what Red Hat thinks is the right way to use the tools?&lt;/li&gt; &lt;/ul&gt;&lt;h2&gt;Ideas for improving CI/CD&lt;/h2&gt; &lt;p&gt;The final step of the design thinking process in these workshops was to ideate new solutions to the problem statements we created. We used the "Yes, and" technique to facilitate brainstorming. The phrase "Yes, and" encourages active listening, positive thinking, and building on each other’s ideas. It reminds people not to criticize other people's ideas, but to use the ideas as inspiration for more suggestions. This process generated many possible solutions to the problems we were exploring, as summarized in Figure 3.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/Solutions.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/Solutions.png?itok=U66RHv9u" width="600" height="287" alt="Ideating finds positive steps an organization can take to solve a problem." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 3: Suggestions resulting from ideating. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;Let's look at our findings from each of the problem statements.&lt;/p&gt; &lt;h3&gt;How might we make it easier to onboard and use Tekton Pipelines effectively?&lt;/h3&gt; &lt;p&gt;Participants generated the following ideas for making Tekton Pipelines onboarding easier:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Provide additional information from elsewhere (secrets, registry, etc) during the pipeline creation process.&lt;/li&gt; &lt;li&gt;Provide an out-of-the-box way of protecting Triggers and EventListeners.&lt;/li&gt; &lt;li&gt;Provide additional metrics on a per-pipeline level (success ratio, run duration, etc.).&lt;/li&gt; &lt;li&gt;Create a pipeline template that generates pipelines based on each folder.&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;How might we make it easier to learn how to leverage Argo CD effectively?&lt;/h3&gt; &lt;p&gt;Ideas for learning how to leverage Argo CD were:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Integrate better with external vaults (e.g., HashiCorp).&lt;/li&gt; &lt;li&gt;Document complex use cases.&lt;/li&gt; &lt;li&gt;Write guided docs to achieve use cases (after setup).&lt;/li&gt; &lt;li&gt;Implement secrets via Argo CD or Vault.&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;How might we share parts of pipelines more easily?&lt;/h3&gt; &lt;p&gt;For sharing parts of pipelines, participants had the following suggestions:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Use a simpler syntax (e.g., GitHub actions).&lt;/li&gt; &lt;li&gt;Make sure that every time you have a new branch, the pipeline stays the same and certain tasks are skipped based on the branch.&lt;/li&gt; &lt;li&gt;Save users from having to think about the technical details of where the pipeline is running, and how many resources it is using.&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;How might we offer a flexible way to customize pipeline metrics and react to them?&lt;/h3&gt; &lt;p&gt;Ideas for providing more flexible pipeline-metric customization were:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Allow custom metrics to be defined at certain author-defined thresholds that will fail the pipeline.&lt;/li&gt; &lt;li&gt;Make results of performance scans processable: if they are above a certain value they should block or break the pipeline.&lt;/li&gt; &lt;li&gt;Provide a yes-or-no button: Should I proceed with the next step?&lt;/li&gt; &lt;/ul&gt;&lt;h3&gt;How might we get more information about what Red Hat thinks is the right way to do things and use the tools?&lt;/h3&gt; &lt;p&gt;Participants suggested the following:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Define a reference architecture.&lt;/li&gt; &lt;li&gt;Publish ideas from Red Hat about how to use the tools—we don’t want to search the internet.&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;Finally, we voted on the solutions participants most wanted to see implemented. This information will help the OpenShift team prioritize new features and enhancements for CI/CD tooling in the console.&lt;/p&gt; &lt;h2&gt;What’s next&lt;/h2&gt; &lt;p&gt;The User Experience Design team will continue to explore the customer ideas that came from these workshops. We will complete the design thinking process by prototyping designs and testing them with users. The information that we gathered from these two workshops helped us to identify five main focus areas that will inform decisions and enhancements to the OpenShift CI/CD tooling.&lt;/p&gt; &lt;p&gt;Community feedback helps us continually improve the OpenShift Developer Experience. We want to hear from you, too. Attend one of our office hours on the OpenShift Twitch channel, or join the OpenShift Developer Experience Google Group to share your Web Console tips, get help with what doesn’t work so well for you, and shape the future of the OpenShift Developer Experience.&lt;/p&gt; &lt;p&gt;Ready to get started? &lt;a href="https://developers.redhat.com/developer-sandbox"&gt;Try OpenShift today&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Are you interested in being a user research participant? &lt;a href="https://redhatdg.co1.qualtrics.com/jfe/form/SV_7aLuDILtNL7FmPX?source=OpenShift-blog"&gt;Sign up today&lt;/a&gt;.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/09/06/improving-cicd-red-hat-openshift" title="Improving CI/CD in Red Hat OpenShift"&gt;Improving CI/CD in Red Hat OpenShift&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/_jGHs2l6LJg" height="1" width="1" alt=""/&gt;</summary><dc:creator>Brigid Gliwa</dc:creator><dc:date>2021-09-06T03:00:00Z</dc:date><feedburner:origLink>https://developers.redhat.com/articles/2021/09/06/improving-cicd-red-hat-openshift</feedburner:origLink></entry><entry><title type="html">Byteman 4.0.17 has been released</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/rWbhPy3hdCQ/byteman-4017-has-been-released.html" /><author><name>Andrew Dinn</name></author><id>http://bytemanblog.blogspot.com/2021/09/byteman-4017-has-been-released.html</id><updated>2021-09-03T14:47:00Z</updated><content type="html">Byteman 4.0.17 is now available from the and from the . It is the latest update release for use on all JDK9+ runtimes up to and including JDK17.   Byteman 4.0.17 is a maintenance release which provides a few small enhancements and fixes a minor bug. More details are provided in the .  &lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/rWbhPy3hdCQ" height="1" width="1" alt=""/&gt;</content><dc:creator>Andrew Dinn</dc:creator><feedburner:origLink>http://bytemanblog.blogspot.com/2021/09/byteman-4017-has-been-released.html</feedburner:origLink></entry><entry><title type="html">Bringing Drools rules into the cloud with Kogito: a step by step path</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/GDkJ8DmV0lM/bringing-drools-rules-into-the-cloud-with-kogito-a-step-by-step-path.html" /><author><name>Mario Fusco</name></author><id>https://blog.kie.org/2021/09/bringing-drools-rules-into-the-cloud-with-kogito-a-step-by-step-path.html</id><updated>2021-09-02T07:20:36Z</updated><content type="html">The goal of this article is to demonstrate how to expose a Drools stateless rules evaluation in a Quarkus REST endpoint and then how to migrate it to Kogito in order to fully leverage Quarkus features and finally how to embrace the Kogito’s programming model based on rule units. OVERVIEW In Drools a stateless rules evaluation is a one-off execution of a rule set against a provided set of facts. Under this point of view this kind of rules evaluation can be seen as a pure function invocation, where the return value is only determined by its input values, without observable side effects, in which the arguments passed to the function are actually the facts to be inserted into the session and the result is the outcome of your rules set applied on those facts. From a consumer perspective of this service the fact that the invoked function uses a rule engine to perform its job could be only an internal implementation detail. In this situation it is natural to expose such a function through a REST endpoint, thus turning it into a microservice. At this point it can be eventually deployed into a Function as a Service environment, possibly after having compiled it into a native image, to avoid paying the cost of relatively high JVM startup time. This document is focused on this stateless scenario because at the moment it is the only use case also supported in Kogito. THE SAMPLE PROJECT Let’s try to put this idea in practice by taking an existing Drools project and migrating it in steps to Kogito and Quarkus. The domain model of the sample project that we will is use to demonstrate this migration is made only by two classes, a loan application public class LoanApplication {    private String id;    private Applicant applicant;    private int amount;    private int deposit;    private boolean approved = false;    public LoanApplication(String id, Applicant applicant, int amount, int deposit) {        this.id = id;        this.applicant = applicant;        this.amount = amount;        this.deposit = deposit;    } } and the applicant who requested it public class Applicant {    private int age;    public Applicant(String name, int age) {        this.name = name;        this.age = age;    } } The rules set is made of business decisions to approve or reject an application plus one last rule collecting all the approved applications into a list. The rules set is made of business decisions to approve or reject an application plus one last rule collecting all the approved applications into a list. global Integer maxAmount; global java.util.List approvedApplications; rule LargeDepositApprove when    $l: LoanApplication( applicant.age &gt;= 20, deposit &gt;= 1000, amount &lt;= maxAmount ) then    modify($l) { setApproved(true) }; // loan is approved end rule LargeDepositReject when    $l: LoanApplication( applicant.age &gt;= 20, deposit &gt;= 1000, amount &gt; maxAmount ) then    modify($l) { setApproved(false) }; // loan is rejected end // ... more loans approval/rejections business rules ... rule CollectApprovedApplication when    $l: LoanApplication( approved ) then    approvedApplications.add($l); // collect all approved loan applications end STEP 1: EXPOSING RULES EVALUATION WITH A REST ENDPOINT THROUGH QUARKUS The first goal that we want to achieve is providing a REST endpoint for this service using Quarkus. The easiest way to do this is creating a new module depending on the one containing the rules plus a few basic Quarkus libraries providing the REST support. &lt;dependencies&gt;  &lt;dependency&gt;    &lt;groupId&gt;io.quarkus&lt;/groupId&gt;    &lt;artifactId&gt;quarkus-resteasy&lt;/artifactId&gt;  &lt;/dependency&gt;  &lt;dependency&gt;    &lt;groupId&gt;io.quarkus&lt;/groupId&gt;    &lt;artifactId&gt;quarkus-resteasy-jackson&lt;/artifactId&gt;  &lt;/dependency&gt;  &lt;dependency&gt;    &lt;groupId&gt;org.example&lt;/groupId&gt;    &lt;artifactId&gt;drools-project&lt;/artifactId&gt;    &lt;version&gt;1.0-SNAPSHOT&lt;/version&gt;  &lt;/dependency&gt; &lt;dependencies&gt; With this setup it’s easy to create a REST endpoint as it follows. @Path("/find-approved") public class FindApprovedLoansEndpoint {    private static final KieContainer kContainer = KieServices.Factory.get().newKieClasspathContainer();    @POST()    @Produces(MediaType.APPLICATION_JSON)    @Consumes(MediaType.APPLICATION_JSON)    public List&lt;LoanApplication&gt; executeQuery(LoanAppDto loanAppDto) {        KieSession session = kContainer.newKieSession();        List&lt;LoanApplication&gt; approvedApplications = new ArrayList&lt;&gt;();        session.setGlobal("approvedApplications", approvedApplications);        session.setGlobal("maxAmount", loanAppDto.getMaxAmount());        loanAppDto.getLoanApplications().forEach(session::insert);        session.fireAllRules();        session.dispose();        return approvedApplications;    } } Here a KieContainer containing the rules taken from the other module in the classpath is created and put into a static field. In this way it will be possible to reuse the same KieContainer for all subsequent invocations of this endpoint without having to recompile the rules. When the endpoint is invoked it creates a new KieSession from the container, populates it with the objects coming from a DTO resulting from the unmarshalling of the JSON request. public class LoanAppDto {    private int maxAmount;    private List&lt;LoanApplication&gt; loanApplications;    public int getMaxAmount() {        return maxAmount;    }    public void setMaxAmount(int maxAmount) {        this.maxAmount = maxAmount;    }    public List&lt;LoanApplication&gt; getLoanApplications() {        return loanApplications;    }    public void setLoanApplications(List&lt;LoanApplication&gt; loanApplications) {        this.loanApplications = loanApplications;    } } When we call fireAllRules() the session is fired and all our business logic is evaluated against the provided input data. Then the last rule collects all the approved applications into a global list and this list is returned as the result of the computation. After having started Quarkus you can already put this at work invoking the REST endpoint with a JSON request containing the loan applications to be checked and the value for the maxAmount to be used in the rules, like in the the following example curl -X POST -H 'Accept: application/json' -H 'Content-Type: application/json' -d '{"maxAmount":5000,"loanApplications":[ {"id":"ABC10001","amount":2000,"deposit":1000,"applicant":{"age":45,"name":"John"}}, {"id":"ABC10002","amount":5000,"deposit":100,"applicant":{"age":25,"name":"Paul"}}, {"id":"ABC10015","amount":1000,"deposit":100,"applicant":{"age":12,"name":"George"}} ]}' http://localhost:8080/find-approved and you will be returned with a list of the approved applications. [{"id":"ABC10001","applicant":{"name":"John","age":45},"amount":2000,"deposit":1000,"approved":true}] This straightforward approach has the major drawback of not allowing to use some of the most interesting features of Quarkus like the hot reload and the possibility of creating a native image of the project. Those features, as we will see in the next step, are indeed provided by the Kogito extension to Quarkus that in essence makes Quarkus aware of the existence of the drl files,  implementing their hot reload in a similar way to what Quarkus provides out-of-the-box for the java sources. The integration demonstrated up to this point between Drools and Quakus has to be considered no more than an introduction to the next migration step. Since Kogito supports the use of Drools API, and given the advantages it provides in terms of fully functional out-of-the-box Quarkus integration, we strongly suggest to not stop the development of your REST service at this point.  STEP 2: FROM DROOLS TO KOGITO WITHOUT CHANGING (ALMOST) ANYTHING USING THE DROOLS LEGACY API As anticipated, Kogito can provide those missing features, so let’s try to migrate our project to Kogito with the minimal amount of effort. To do this we can use the Quarkus extension for Kogito in conjunction with the kogito-legacy-api allowing us to use the same API of Drools 7. This approach also makes it possible to consolidate the former two modules into a single one. &lt;dependencies&gt;  &lt;dependency&gt;   &lt;groupId&gt;org.kie.kogito&lt;/groupId&gt;   &lt;artifactId&gt;kogito-quarkus-rules&lt;/artifactId&gt;  &lt;/dependency&gt;  &lt;dependency&gt;   &lt;groupId&gt;org.kie.kogito&lt;/groupId&gt;   &lt;artifactId&gt;kogito-legacy-api&lt;/artifactId&gt;  &lt;/dependency&gt; &lt;/dependencies&gt; In this way no changes at all are required to  the DRL file containing the rules while the former REST endpoint implementation can be rewritten as follows. @Path("/find-approved") public class FindApprovedLoansEndpoint {    @Inject    KieRuntimeBuilder kieRuntimeBuilder;    @POST()    @Produces(MediaType.APPLICATION_JSON)    @Consumes(MediaType.APPLICATION_JSON)    public List&lt;LoanApplication&gt; executeQuery(LoanAppDto loanAppDto) {        KieSession session = kieRuntimeBuilder.newKieSession();        List&lt;LoanApplication&gt; approvedApplications = new ArrayList&lt;&gt;();        session.setGlobal("approvedApplications", approvedApplications);        session.setGlobal("maxAmount", loanAppDto.getMaxAmount());        loanAppDto.getLoanApplications().forEach(session::insert);        session.fireAllRules();        session.dispose();        return approvedApplications;    } } Here the only difference with the former implementation is that the KieSession instead of being created from the KieContainer is created from an automatically injected KieRuntimeBuilder.  The KieRuntimeBuilder is the interface provided by the kogito-legacy-api module that replace the KieContainer and from which it is now possible to create the KieBases and KieSessions exactly as you did with the KieContainer itself. An implementation of the KieRuntimeBuilder interface is automatically generated at compile time by Kogito and injected into the class implementing the REST endpoint. With this change it is possible both to launch quarkus in dev mode thus leveraging its hot reload to make on-the-fly changes also to the rules files that are immediately applied to the running application and to create a native image of your rule based application.   STEP 3: EMBRACING RULE UNITS AND AUTOMATIC REST ENDPOINT GENERATION A rule unit is a new concept introduced in Kogito encapsulating both a set of rules and the facts against which those rules will be matched. It comes with a second abstraction called data source, defining the sources through which the facts are inserted, acting in practice as typed entry-points. There are two types of data sources: * DataStream: an append-only data source * subscribers only receive new (and possibly past) messages * cannot update/remove * stream may also be hot/cold in “reactive streams” terminology * DataStore: data source for modifiable data * subscribers may act upon the data store, by acting upon the fact handle In essence a rule unit is made of 2 strictly related parts: the definition of the fact to be evaluated and the set of rules evaluating them. The first part is implemented with a POJO, that for our loan applications could be something like the following: package org.kie.kogito.queries; import org.kie.kogito.rules.DataSource; import org.kie.kogito.rules.DataStore; import org.kie.kogito.rules.RuleUnitData; public class LoanUnit implements RuleUnitData {    private int maxAmount;    private DataStore&lt;LoanApplication&gt; loanApplications;    public LoanUnit() {        this(DataSource.createStore(), 0);    }    public LoanUnit(DataStore&lt;LoanApplication&gt; loanApplications, int maxAmount) {        this.loanApplications = loanApplications;        this.maxAmount = maxAmount;    }    public DataStore&lt;LoanApplication&gt; getLoanApplications() { return loanApplications; }    public void setLoanApplications(DataStore&lt;LoanApplication&gt; loanApplications) {        this.loanApplications = loanApplications;    }    public int getMaxAmount() { return maxAmount; }    public void setMaxAmount(int maxAmount) { this.maxAmount = maxAmount; } } Here instead of using the LoanAppDto that we introduced to marshall/unmarshall the JSON requests we are binding directly the class representing the rule unit. The two relevant differences are that it implements the org.kie.kogito.rules.RuleUnitData interface and uses a DataStore instead of a plain List to contain the loan applications to be approved. The first is just a marker interface to notify the engine that this class is part of a rule unit definition. The use of a DataStore is necessary to let the rule engine to react to changes of processed fact, this allows the rule engine to react accordingly to the changes by firing new rules and triggering other rules. In the example, the consequences of the rules modify the approved property of the loan applications. Conversely the maxAmount value can be considered a configuration parameter of the rule unit and left as it is: it will automatically be processed during the rules evaluation with the same semantic of a global, and automatically set from the value passed by the JSON request as in the first example, so you will still be allowed to use it in your rules. The second part of the rule unit is the drl file containing the rules belonging to this unit. package org.kie.kogito.queries; unit LoanUnit; // no need to using globals, all variables and facts are stored in the rule unit  rule LargeDepositApprove when    $l: /loanApplications[ applicant.age &gt;= 20, deposit &gt;= 1000, amount &lt;= maxAmount ] // oopath style then    modify($l) { setApproved(true) }; end rule LargeDepositReject when    $l: /loanApplications[ applicant.age &gt;= 20, deposit &gt;= 1000, amount &gt; maxAmount ] then    modify($l) { setApproved(false) }; end // ... more loans approval/rejections business rules ... // approved loan applications are now retrieved through a query query FindApproved    $l: /loanApplications[ approved ] end This rules file must declare the same package and a unit with the same name of the java class implementing the RuleUnitData interface in order to state that they belong to the same rule unit. This file has also been rewritten using the new OOPath notation: as anticipated, here the data source acts as a typed entry-point and the oopath expression has its name as root while the constraints are in square brackets, like in the following example. $l: /loanApplications[ applicant.age &gt;= 20, deposit &gt;= 1000, amount &lt;= maxAmount ] Alternatively you can still use the old DRL syntax, specifying the name of the data source as an entry-point, with the drawback that in this case you need to specify again the type of the matched object, even if the engine can infer it from the type of the datasource, as it follows.  $l: LoanApplication( applicant.age &gt;= 20, deposit &gt;= 1000, amount &lt;= maxAmount ) from entry-point loanApplications Finally note that the last rule collecting all the approved loan applications into a global List has been replaced by a query simply retrieving them. One of the advantages in using a rule unit is that it clearly defines the context of computation, in other terms the facts to be passed in input to the rule evaluation. Similarly the query defines what is the output expected by this evaluation.      This clear definition of the computation boundaries allows Kogito to also automatically generate a class executing the query and returning its results public class LoanUnitQueryFindApproved implements org.kie.kogito.rules.RuleUnitQuery&lt;List&lt;org.kie.kogito.queries.LoanApplication&gt;&gt; {    private final RuleUnitInstance&lt;org.kie.kogito.queries.LoanUnit&gt; instance;    public LoanUnitQueryFindApproved(RuleUnitInstance&lt;org.kie.kogito.queries.LoanUnit&gt; instance) {        this.instance = instance;    }    @Override    public List&lt;org.kie.kogito.queries.LoanApplication&gt; execute() {        return instance.executeQuery("FindApproved").stream().map(this::toResult).collect(toList());    }    private org.kie.kogito.queries.LoanApplication toResult(Map&lt;String, Object&gt; tuple) {        return (org.kie.kogito.queries.LoanApplication) tuple.get("$l");    } } together with a REST endpoint taking the rule unit as input, passing it to the former query executor and returning its as output. @Path("/find-approved") public class LoanUnitQueryFindApprovedEndpoint {    @javax.inject.Inject    RuleUnit&lt;org.kie.kogito.queries.LoanUnit&gt; ruleUnit;    public LoanUnitQueryFindApprovedEndpoint() {    }    public LoanUnitQueryFindApprovedEndpoint(RuleUnit&lt;org.kie.kogito.queries.LoanUnit&gt; ruleUnit) {        this.ruleUnit = ruleUnit;    }    @POST()    @Produces(MediaType.APPLICATION_JSON)    @Consumes(MediaType.APPLICATION_JSON)    public List&lt;org.kie.kogito.queries.LoanApplication&gt; executeQuery(org.kie.kogito.queries.LoanUnit unit) {        RuleUnitInstance&lt;org.kie.kogito.queries.LoanUnit&gt; instance = ruleUnit.createInstance(unit);        return instance.executeQuery(LoanUnitQueryFindApproved.class);    } } You can have as many query as you want and for each of them it will be generated a different REST endpoint with the same name of the query transformed from camel case (like FindApproved) to dash separated (like find-approved). The post appeared first on .&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/GDkJ8DmV0lM" height="1" width="1" alt=""/&gt;</content><dc:creator>Mario Fusco</dc:creator><feedburner:origLink>https://blog.kie.org/2021/09/bringing-drools-rules-into-the-cloud-with-kogito-a-step-by-step-path.html</feedburner:origLink></entry><entry><title>Faster web deployment with Python serverless functions</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Wob7oaCf6hA/faster-web-deployment-python-serverless-functions" /><author><name>Don Schenck</name></author><id>07578a68-80d3-4ada-9dc6-9d404b0f335b</id><updated>2021-09-02T07:00:00Z</updated><published>2021-09-02T07:00:00Z</published><summary type="html">&lt;p&gt;Functions as a Service (FaaS) and &lt;a href="https://developers.redhat.com/topics/serverless-architecture"&gt;serverless architecture&lt;/a&gt; promise quick, lightweight deployments for web applications and other standalone functions. But until recently, creating FaaS in &lt;a href="https://developers.redhat.com/products/openshift/"&gt;Red Hat OpenShift&lt;/a&gt; has been a "sort of" process consisting of multiple steps. You weren't really creating a function so much as an application that could scale back to zero pods after a few minutes, then scale up again when called.&lt;/p&gt; &lt;p&gt;&lt;a href="https://developers.redhat.com/blog/2021/01/04/create-your-first-serverless-function-with-red-hat-openshift-serverless-functions"&gt;Red Hat OpenShift Serverless Functions&lt;/a&gt; is a newer feature that changes all of that. As a developer, you can use it to deploy functions in a snap. You can scaffold functions that handle HTTP requests or &lt;a href="https://cloudevents.io/"&gt;CloudEvents&lt;/a&gt; with one command.&lt;/p&gt; &lt;p&gt;This article gets you started with creating and deploying serverless functions with OpenShift Serverless Functions. We'll use &lt;a href="https://developers.redhat.com/topics/python"&gt;Python&lt;/a&gt; to develop our serverless function, but it's just one of many languages you could choose from.&lt;/p&gt; &lt;h2&gt;Creating and deploying serverless functions with Knative&lt;/h2&gt; &lt;p&gt;OpenShift Serverless Functions uses the open source &lt;a href="https://developers.redhat.com/topics/serverless-architecture"&gt;Knative&lt;/a&gt; framework, which offers powerful management tools through its &lt;code&gt;kn&lt;/code&gt; command-line interface (CLI). Prior to OpenShift Serverless Functions, creating a function in OpenShift required writing an application from scratch, using Knative to manage the application, and creating the deployment, service, and route to support the application. While creating a serverless function that way was not terribly complicated, OpenShift Serverless Functions makes life much easier.&lt;/p&gt; &lt;p&gt;With OpenShift Serverless Functions, developers no longer have to worry about creating the deployment, service, and route. It's all one thing: The function. You can't get more &lt;em&gt;serverless&lt;/em&gt; than that.&lt;/p&gt; &lt;p&gt;Deploying a function with OpenShift Serverless Functions requires three Knative commands:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;kn func create kn func build kn func deploy &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;There's more to the process, but those three commands get to the heart of it. We'll explore more about deployment shortly. First, we need to set up our environment to support OpenShift Serverless Functions.&lt;/p&gt; &lt;h2&gt;Step 1: Set up your serverless development environment&lt;/h2&gt; &lt;p&gt;I was able to complete all of my examples for this article using &lt;a href="https://developers.redhat.com/products/codeready-containers/overview"&gt;Red Hat CodeReady Containers&lt;/a&gt;. CodeReady Containers requires at least 9GB of RAM. I also had to set the number of CPUs to five in order to get both HTTP-driven and event-driven functions to run at the same time. Note that I issued this command &lt;em&gt;before&lt;/em&gt; starting CodeReady Containers:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;crc config set cpus 5&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;When I used a more enterprise-like, cloud-based OpenShift cluster—as you might find in a typical OpenShift installation—CPU and memory usage was not a concern.&lt;/p&gt; &lt;h3&gt;The OpenShift Serverless Operator&lt;/h3&gt; &lt;p&gt;Before you can start deploying functions to an OpenShift cluster, you must install the OpenShift Serverless Operator. From the OpenShift console, locate the operator's card, click on it, and then use the default values to install it. When the installation is finished, the dashboard will let you know. When you see the "Installed operator — ready for use" message shown in Figure 1, click the &lt;strong&gt;View Operator&lt;/strong&gt; button.&lt;/p&gt; &lt;figure role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/ofs_installed.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/ofs_installed.png?itok=wQQGBTVK" width="607" height="227" alt="After you successfully install the Red Hat OpenShift Serverless Operator, the OpenShift dashboard shows the message "Installed operator — ready for use."" typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 1: The OpenShift dashboard showing the Red Hat OpenShift Serverless Operator is ready for use. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;You will see your OpenShift Serverless Operator in all its glory, as shown in Figure 2.&lt;/p&gt; &lt;figure role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/ofs_openshift.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/ofs_openshift.png?itok=3XPyIrR4" width="977" height="474" alt="The Red Hat OpenShift Serverless Operator offers three APIs: Knative Serving, Knative Eventing, and Knative Kafka." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 2: The OpenShift dashboard showing the APIs offered by the Red Hat OpenShift Serverless Operator. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;The Knative Serving API&lt;/h3&gt; &lt;p&gt;With the operator in place, your next step is to prepare the Knative Serving API. Change the project you're working in to &lt;strong&gt;knative-serving&lt;/strong&gt;, as shown in Figure 3. That's where the API must be located.&lt;/p&gt; &lt;figure role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/ofs_serving.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/ofs_serving.png?itok=bOjbeCBo" width="360" height="596" alt="Change the current project to Knative Serving in OpenShift Serverless Functions." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 3: Choosing the knative-serving project in OpenShift Serverless Functions. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Once that's done, click on the &lt;strong&gt;Knative Serving&lt;/strong&gt; link under the Provided APIs, click &lt;strong&gt;Create Knative Serving&lt;/strong&gt;, and use the default values to create the API.&lt;/p&gt; &lt;p&gt;When all of the statuses read True, as shown in Figure 4, you are ready to start using OpenShift Serverless Functions for HTTP-based functions.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/ofs_true.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/ofs_true.png?itok=omHA_hE6" width="708" height="280" alt="Knative Serving is ready when all statuses are True." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 4: Status of Knative Serving. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;h3&gt;The Knative Eventing API&lt;/h3&gt; &lt;p&gt;You need to perform the steps in this section if you want to use CloudEvents to fire your functions. In this case, we'll use Knative Eventing with CloudEvents. The steps are similar if you want to use Knative Serving instead.&lt;/p&gt; &lt;p&gt;Change the working project to &lt;strong&gt;knative-eventing&lt;/strong&gt; and make sure the OpenShift Serverless Function Operator page is displayed.&lt;/p&gt; &lt;p&gt;Click on the &lt;strong&gt;Knative Eventing&lt;/strong&gt; link under the Provided APIs, then click &lt;strong&gt;Create Knative Eventing&lt;/strong&gt;. Use the default values to create the API.&lt;/p&gt; &lt;p&gt;When all of the statuses at the bottom of the page read &lt;strong&gt;True&lt;/strong&gt;, you are ready to start using OpenShift Serverless Functions for CloudEvent-based functions.&lt;/p&gt; &lt;p&gt;That's it: We're finished with all of the installation tasks. Our cluster will now support both HTTP-based and CloudEvent-based serverless functions.&lt;/p&gt; &lt;h2&gt;Step 2: Create an HTTP serverless function in Python&lt;/h2&gt; &lt;p&gt;You can create an HTTP serverless function using Knative's &lt;code&gt;kn&lt;/code&gt; CLI, and the function will be fully functional. You do have to edit the code, of course, to do what you want.&lt;/p&gt; &lt;p&gt;The steps required to create a basic function are shown in Figure 5. In a terminal window, create a directory whose name will become the name of the function. Then, move into that directory and create the function using the &lt;code&gt;kn func create&lt;/code&gt; command. The default runtime is &lt;a href="https://developers.redhat.com/topics/nodejs"&gt;Node.js&lt;/a&gt;, which we will not be using. Instead, we'll use the following command to create a serverless function written in Python:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ kn func create -l python&lt;/code&gt;&lt;/pre&gt; &lt;figure role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/ofs_basic.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/ofs_basic.png?itok=U01f42x2" width="646" height="299" alt="The steps to create a basic application culminate in a "kn func create" command." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 5: The steps to create a serverless function using Python. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: Why did I choose Python? It's popular, I have a Python &lt;a href="https://developers.redhat.com/topics/microservices"&gt;microservice&lt;/a&gt; that I'm going to convert to a function (in my next article), and Red Hat Developer already has a &lt;a href="https://developers.redhat.com/articles/2021/07/01/nodejs-serverless-functions-red-hat-openshift-part-1-logging"&gt; series of articles about creating OpenShift Serverless Functions with Node.js&lt;/a&gt;. So, Python it is.&lt;/p&gt; &lt;h3&gt;About the kn func create command&lt;/h3&gt; &lt;p&gt;The &lt;code&gt;kn func create&lt;/code&gt; command uses the name of the current directory to create the source code for a function. Any supporting files, such as dependencies, will also be created. You simply start with this template and edit the function to suit your needs.&lt;/p&gt; &lt;p&gt;If no language is specified, Node.js will be the default. Several languages are supported, and the list seems to be growing at a decent pace. For now, you can specify any of the following:&lt;/p&gt; &lt;ul&gt;&lt;li&gt;Go&lt;/li&gt; &lt;li&gt;Node.js&lt;/li&gt; &lt;li&gt;Python&lt;/li&gt; &lt;li&gt;Quarkus&lt;/li&gt; &lt;li&gt;Rust&lt;/li&gt; &lt;li&gt;Spring Boot&lt;/li&gt; &lt;li&gt;TypeScript&lt;/li&gt; &lt;/ul&gt;&lt;p&gt;Enter this command to see the list of currently supported languages:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ kn func create --help&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Figure 6 shows where the list of languages appears in the output.&lt;/p&gt; &lt;figure role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/ofs_languages.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/ofs_languages.png?itok=jo27UbOi" width="1087" height="709" alt="Output of the "kn func create --help" command shows which languages it supports." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 6: Languages supported by the "kn func create" command. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;Creating the Knative function&lt;/h3&gt; &lt;p&gt;So what just happened in our &lt;code&gt;kn&lt;/code&gt; command? Figure 7 shows a listing in the directory after we run &lt;code&gt;kn func create -l python&lt;/code&gt;.&lt;/p&gt; &lt;figure role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/ofs_create.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/ofs_create.png?itok=w8RukE92" width="612" height="240" alt="The "kn func create" command adds files for a basic application." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 7: The content of project directory after running the "kn func create" command. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;Let's look inside the &lt;code&gt;func.py&lt;/code&gt; file to see what was created and how it will be used:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-python"&gt;from parliament import Context def main(context: Context): """ Function template The context parameter contains the Flask request object and any CloudEvent received with the request. """ return { "message": "Howdy!" }, 200&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;As shown, this skeleton Python function returns "Howdy!" Remove the comments and you can see that it only takes three lines of code to make a working function. As a default function, the skeleton function is not very useful. My next article will update it to read from a database, so stay tuned.&lt;/p&gt; &lt;p&gt;Note that we've also created the &lt;code&gt;func.yaml&lt;/code&gt; file. If you view the contents, you will notice that it is incomplete. For example, the &lt;code&gt;image&lt;/code&gt; field is empty. If you wish, you can edit this file to create the image name and tag. The default will be the function name and the &lt;code&gt;:latest&lt;/code&gt; tag:&lt;/p&gt; &lt;pre&gt; &lt;code&gt;name: python-faas-example namespace: "" runtime: python image: "" imageDigest: "" builder: quay.io/boson/faas-python-builder:v0.8.3 builderMap: default: quay.io/boson/faas-python-builder:v0.8.3 volumes: [] envs: [] annotations: {} options: {}&lt;/code&gt;&lt;/pre&gt; &lt;h2&gt;Step 3: Build the Python serverless function&lt;/h2&gt; &lt;p&gt;We can build our default HTTP-based function by running the &lt;code&gt;kn func build&lt;/code&gt; command. But because the image name was not specified in the &lt;code&gt;func.yaml&lt;/code&gt; file, this command will prompt us for an image registry. It will use the registry name, the function name, and the tag &lt;code&gt;:latest&lt;/code&gt; to create the image name—if you haven't already supplied one by editing the YAML file. For my own functions, I use my registry: &lt;code&gt;docker.io/donschenck&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;Figure 8 shows the &lt;code&gt;kn func build&lt;/code&gt; command and the resulting &lt;code&gt;func.yaml&lt;/code&gt; file. Notice that the fully-qualified image name has been generated by the command. I'm using PowerShell in Windows, but a Bash shell terminal in macOS or Linux works just as well. The operating system you choose doesn't affect the results: You can build functions anywhere.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/ofs_build.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/ofs_build.png?itok=UiWYu5dl" width="721" height="353" alt="The "kn func build" command creates a minimal YAML configuration file." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 8: YAML configuration created by the "kn func build" command. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;If you view your local image registry, shown in Figure 9, you will see that the image now exists. (I have no idea why "41 years ago" appears.)&lt;/p&gt; &lt;figure role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/ofs_images.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/ofs_images.png?itok=L-OTemY7" width="1255" height="102" alt="A "docker images" command shows the image you created." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 9: A "docker images" command showing the existence of an image. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;h3&gt;Testing the function&lt;/h3&gt; &lt;p&gt;You can use the &lt;code&gt;kn func run&lt;/code&gt; command to run the function locally and test it. In this case, the function will run on port 8080.&lt;/p&gt; &lt;h2&gt;Step 4: Deploy the Python serverless function&lt;/h2&gt; &lt;p&gt;With the function built into an image on your local machine, it's time to deploy it to a cluster. Before you can do that, you need to sign into two systems: The image registry you're using (mine is &lt;code&gt;docker.io/donschenck&lt;/code&gt;) and the cluster where you wish to deploy the function. You also need to make sure you're in the correct project. Figure 10 shows an example of what to do.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/ofs_logins.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/ofs_logins.png?itok=yy7mz71E" width="1179" height="506" alt="To prepare for deployment to OpenShift, you must log in to the image registry and your OpenShift cluster, and create a new project." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 10: Summary of logins and creation of a project in OpenShift. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;When you run &lt;code&gt;kn func deploy&lt;/code&gt;, the command builds the image, pushes the image to the image registry you specified, and then deploys that image from the registry into the OpenShift project to which your current context is set.&lt;/p&gt; &lt;p&gt;In this case, the &lt;code&gt;docker.io/donschenck/python-faas-example:latest&lt;/code&gt; image is deployed to the &lt;code&gt;faas-example&lt;/code&gt; project in my cluster, as shown in Figure 11.&lt;/p&gt; &lt;figure role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/ofs_deploy.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/ofs_deploy.png?itok=wVpOkk3z" width="1179" height="84" alt="The "kn func deploy" command can get an application into your cluster." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 11: Output from the "kn func deploy" command in a cluster. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p class="Indent1"&gt;&lt;strong&gt;Note&lt;/strong&gt;: You can edit the &lt;code&gt;func.yaml&lt;/code&gt; file and change the image tag if you wish. I changed my tag from &lt;code&gt;:latest&lt;/code&gt; to &lt;code&gt;:v1&lt;/code&gt; and it works just fine.&lt;/p&gt; &lt;p&gt;Figure 12 shows the developer topology view in the OpenShift dashboard, displaying the deployed function.&lt;/p&gt; &lt;figure role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/ofs_dashboard.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/ofs_dashboard.png?itok=WfB0MVxa" width="504" height="404" alt="The OpenShift dashboard shows that your function is deployed and has running instances." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 12: The OpenShift dashboard showing the deployed function. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;You can prove that the function in the cluster is working simply by clicking on the &lt;strong&gt;Open URL&lt;/strong&gt; icon.&lt;/p&gt; &lt;h3&gt;Watch the HTTP function scale to zero&lt;/h3&gt; &lt;p&gt;Wait a bit and you'll see the dark blue circle in the function turn white (see Figure 13). This means the function is still available, but it has scaled down to zero pods.&lt;/p&gt; &lt;figure role="group"&gt;&lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/ofs_scaled.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/ofs_scaled.png?itok=IjKvh6A5" width="509" height="400" alt="When the blue circle around a function disappears in the OpenShift dashboard, the function has scaled down to zero pods." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 13: The function after it has scaled down to zero pods. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;figcaption class="rhd-c-caption"&gt;&lt;/figcaption&gt;&lt;/figure&gt;&lt;p&gt;If you access the function now—by clicking on the &lt;strong&gt;Open URL&lt;/strong&gt; icon, or refreshing the browser where you previously opened it—you'll see a slight delay before getting the result. This delay happens only when the function is scaling from zero to one. Refresh yet again and you'll see a speedy response. The function is now up and running.&lt;/p&gt; &lt;h3&gt;Update the function&lt;/h3&gt; &lt;p&gt;Updating the function requires the following steps, which are shown in Figure 14:&lt;/p&gt; &lt;ol&gt;&lt;li&gt;Edit the &lt;code&gt;func.py&lt;/code&gt; source file.&lt;/li&gt; &lt;li&gt;Run the &lt;code&gt;kn func deploy&lt;/code&gt; command.&lt;/li&gt; &lt;/ol&gt;&lt;p&gt;That's all you need to do. The &lt;code&gt;kn func deploy&lt;/code&gt; command &lt;em&gt;automagically&lt;/em&gt; rebuilds the image before pushing it to your image registry and deploying it to your cluster.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/ofs_updated.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/ofs_updated.png?itok=9guPcOWj" width="1173" height="296" alt="Updating a function requires editing the source code and redeploying it with the "kn func deploy" command." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 14: Steps needed to update a function. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;h2&gt;Troubleshooting kn func deploy&lt;/h2&gt; &lt;p&gt;Before closing, let's look at some common error messages related to &lt;code&gt;kn func deploy&lt;/code&gt; and how to recover from them.&lt;/p&gt; &lt;h3&gt;incorrect username or password&lt;/h3&gt; &lt;p&gt;This message, shown in Figure 15, occurred to me once when I ran &lt;code&gt;kn func deploy&lt;/code&gt; while I was not logged into my docker.io registry.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/ofs_incorrect.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/ofs_incorrect.png?itok=mKtPZy5O" width="476" height="25" alt="An invalid password or username when logging in prevents deployment of the functon to the image registry." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 15: An "incorrect username or password" error message. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;The lesson is that you must be logged into the image register in order to successfully run the command, because it has to push the image to the repository. The &lt;code&gt;kn&lt;/code&gt; command was nice enough to prompt me for username and password, but I made a mistake entering them. Of course, my function was not deployed as a result. When I supplied the correct name and password, the command worked.&lt;/p&gt; &lt;h3&gt;knative deployer failed to get the Knative Service&lt;/h3&gt; &lt;p&gt;This happened to me when I ran &lt;code&gt;kn func deploy&lt;/code&gt; while I was not logged into my OpenShift cluster, as shown in Figure 16. The deployment failed.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content-full-width"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/ofs_failed.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_full_width_1440px_w/public/ofs_failed.png?itok=ngLoq_Tf" width="1016" height="64" alt="If you are not logged in to your project in your OpenShift cluster, the "kn func deploy" command cannot get access to the cluster." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 16: A "knative deployer failed to get the Knative Service" error message. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;Although the &lt;code&gt;kn&lt;/code&gt; command can gracefully log in to the image repository, as shown in the previous section, it cannot automatically connect to a cluster. Make sure to log in to the cluster and the correct project, then rerun the &lt;code&gt;kn&lt;/code&gt; command.&lt;/p&gt; &lt;h3&gt;timeout&lt;/h3&gt; &lt;p&gt;I got this error when I ran &lt;code&gt;kn func deploy&lt;/code&gt; while using Red Hat's quay.io as my image registry, as shown in Figure 17.&lt;/p&gt; &lt;div class="rhd-c-figure"&gt; &lt;article class="media media--type-image media--view-mode-article-content"&gt;&lt;div class="field field--name-image field--type-image field--label-hidden field__items"&gt; &lt;a href="https://developers.redhat.com/sites/default/files/ofs_timeout.png" data-featherlight="image"&gt;&lt;img src="https://developers.redhat.com/sites/default/files/styles/article_floated/public/ofs_timeout.png?itok=VjsK8Byi" width="600" height="12" alt="A timeout error may appear when you don't explicitly make images Public in Red Hat's quay.io registry." typeof="Image" /&gt;&lt;/a&gt; &lt;/div&gt; &lt;div class="field field--name-field-caption field--type-string field--label-hidden field__items"&gt; &lt;div class="rhd-c-caption field__item"&gt; Figure 17: A "timeout" error message. &lt;/div&gt; &lt;/div&gt; &lt;/article&gt;&lt;/div&gt; &lt;p&gt;By default, images added to quay.io registry are marked Private, so your OpenShift cluster cannot pull the image. Simply change the repository visibility in quay.io to Public. OpenShift will continue to attempt to pull the image, and once it is publicly available, the deployment will succeed.&lt;/p&gt; &lt;h2&gt;What else can I do with Python serverless functions?&lt;/h2&gt; &lt;p&gt;Look for the next article in this series, where we'll build a Python-based serverless function that responds to a CloudEvent instead of an HTTP request. Also visit the &lt;a href="https://developers.redhat.com/topics/serverless-architecture"&gt;OpenShift Serverless&lt;/a&gt; homepage to learn more about creating, scaling, and managing serverless functions on &lt;a href="https://developers.redhat.com/products/openshift/"&gt;Red Hat OpenShift&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Serverless functions in Java and Node.js&lt;/h2&gt; &lt;p&gt;Are you interested in writing serverless functions in &lt;a href="https://developers.redhat.com/topics/enterprise-java"&gt;Java&lt;/a&gt; or &lt;a href="https://developers.redhat.com/topics/nodejs"&gt;Node.js&lt;/a&gt;? Start with &lt;a href="https://developers.redhat.com/blog/2021/01/04/create-your-first-serverless-function-with-red-hat-openshift-serverless-functions"&gt;this overview of OpenShift serverless functions&lt;/a&gt;, then get a quick tutorial introduction to &lt;a href="https://developers.redhat.com/blog/2021/01/29/write-a-quarkus-function-in-two-steps-on-red-hat-openshift-serverless"&gt;writing a Quarkus function in two steps&lt;/a&gt; or &lt;a href="https://developers.redhat.com/articles/2021/07/01/nodejs-serverless-functions-red-hat-openshift-part-1-logging"&gt;developing Node.js serverless functions&lt;/a&gt; on Red Hat OpenShift.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/09/02/faster-web-deployment-python-serverless-functions" title="Faster web deployment with Python serverless functions"&gt;Faster web deployment with Python serverless functions&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Wob7oaCf6hA" height="1" width="1" alt=""/&gt;</summary><dc:creator>Don Schenck</dc:creator><dc:date>2021-09-02T07:00:00Z</dc:date><feedburner:origLink>https://developers.redhat.com/articles/2021/09/02/faster-web-deployment-python-serverless-functions</feedburner:origLink></entry><entry><title>The outbox pattern with Apache Kafka and Debezium</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/VFcQCM_rYaU/outbox-pattern-apache-kafka-and-debezium" /><author><name>Don Schenck</name></author><id>fde9b237-3f15-4ece-a630-b4f9c5c97aee</id><updated>2021-09-01T12:00:00Z</updated><published>2021-09-01T12:00:00Z</published><summary type="html">&lt;p&gt;&lt;a href="https://developers.redhat.com/topics/microservices"&gt;Microservices&lt;/a&gt; need access to shared data. Microservices also need to be loosely coupled. Just how are developers supposed to reconcile these diametrically opposed ideas?&lt;/p&gt; &lt;p&gt;Enter &lt;a href="https://kafka.apache.org/"&gt;Apache Kafka&lt;/a&gt;, &lt;a href="https://debezium.io/"&gt;Debezium&lt;/a&gt;, and &lt;a href="https://microservices.io/patterns/data/transactional-outbox.html"&gt;the outbox pattern&lt;/a&gt;. By combining messaging and change data capture technologies with good programming practices, you can meet both microservices demands with ease.&lt;/p&gt; &lt;p&gt;&lt;a href="https://www.youtube.com/watch?v=wEhr-mnPOeQ"&gt;This video explores the outbox pattern and demonstrates it in action&lt;/a&gt;, using &lt;a href="https://developers.redhat.com/products/red-hat-openshift-streams-for-apache-kafka/overview"&gt;Red Hat OpenShift Streams for Apache Kafka&lt;/a&gt; and &lt;a href="https://debezium.io/"&gt;Debezium&lt;/a&gt;. In just minutes, you’ll see how easy it is to replicate data to your microservices while keeping them loosely coupled. OpenShift Streams for Apache Kafka is a managed cloud solution with a free-to-try introductory option.&lt;/p&gt; &lt;p&gt;When you’re finished, you can use a free account on &lt;a href="https://developers.redhat.com/developer-sandbox"&gt;Developer Sandbox for Red Hat OpenShift&lt;/a&gt; and &lt;a href="https://developers.redhat.com/developer-sandbox/activities/connecting-to-your-managed-kafka-instance"&gt;Red Hat OpenShift Streams for Apache Kafka&lt;/a&gt; to start your own education and experimentation.&lt;/p&gt; &lt;p&gt;You can explore &lt;a href="https://developers.redhat.com/articles/2021/08/11/how-maximize-data-storage-microservices-and-kubernetes-part-1-introduction"&gt;other data solutions within Red Hat OpenShift&lt;/a&gt; as well. The choices are many, so begin your journey today.&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/09/01/outbox-pattern-apache-kafka-and-debezium" title="The outbox pattern with Apache Kafka and Debezium"&gt;The outbox pattern with Apache Kafka and Debezium&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/VFcQCM_rYaU" height="1" width="1" alt=""/&gt;</summary><dc:creator>Don Schenck</dc:creator><dc:date>2021-09-01T12:00:00Z</dc:date><feedburner:origLink>https://developers.redhat.com/articles/2021/09/01/outbox-pattern-apache-kafka-and-debezium</feedburner:origLink></entry><entry><title>Red Hat CodeReady Containers 1.31.2 makes the leap</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/50_u54cQr0w/red-hat-codeready-containers-1312-makes-leap" /><author><name>CodeReady Containers Team</name></author><id>a24b60ae-7ffc-470d-8a00-111abeca5c91</id><updated>2021-09-01T07:00:00Z</updated><published>2021-09-01T07:00:00Z</published><summary type="html">&lt;p&gt;&lt;a href="https://developers.redhat.com/blog/2019/09/05/red-hat-openshift-4-on-your-laptop-introducing-red-hat-codeready-containers"&gt;Red Hat CodeReady Containers&lt;/a&gt; supports local development and testing on a &lt;a href="https://developers.redhat.com/openshift"&gt;Red Hat OpenShift&lt;/a&gt; cluster. We recently released CodeReady Containers 1.31.2, which is the first version based on the major &lt;a href="https://cloud.redhat.com/blog/red-hat-openshift-4.8-is-now-generally-available"&gt;OpenShift 4.8&lt;/a&gt; release. The CodeReady Containers team doesn't publicly report our advances on a regular basis, so this article is a good opportunity to learn about the biggest changes to CodeReady Containers during the past several months.&lt;/p&gt; &lt;h2&gt;Upgrade to OpenShift 4.8&lt;/h2&gt; &lt;p&gt;With this release, we updated CodeReady Containers to use the 4.8 release of OpenShift. This release offers support for single-node clusters as a developer preview. We also enabled OpenShift’s Machine Config Operator, so users can now follow OpenShift documentation for registry and proxy configuration, or for any other changes that use the Machine Config Operator to modify the cluster. In previous releases, these changes required steps specific to CodeReady Containers. The following video shows how to enable the Machine Config Operator (MCO).&lt;/p&gt; &lt;div class="video-embed-field-provider-youtube video-embed-field-responsive-video"&gt; &lt;/div&gt; &lt;h2&gt;Installers&lt;/h2&gt; &lt;p&gt;On macOS and Windows 10, we are now shipping native installers (&lt;code&gt;.pkg&lt;/code&gt; and &lt;code&gt;.msi&lt;/code&gt; files, respectively). The native installers provide an easier installation procedure, with more integrated requirement checks. The following video shows how installation on macOS can be done in less than 30 seconds.&lt;/p&gt; &lt;div class="video-embed-field-provider-youtube video-embed-field-responsive-video"&gt; &lt;/div&gt; &lt;p&gt;The installers are signed so that they can be properly validated by the operating system before installation, which is particularly important in light of recent supply-chain attacks. Installers are the only supported way to install and use CodeReady Containers on macOS and Windows.&lt;/p&gt; &lt;h2&gt;System trays&lt;/h2&gt; &lt;p&gt;The new installers on macOS and Windows come with a system tray icon. This icon allows direct interactions with CodeReady Containers, such as to start and stop your cluster. You no longer need to fall back to a shell prompt to manage your OpenShift instance.&lt;/p&gt; &lt;h2&gt;New networking stack&lt;/h2&gt; &lt;p&gt;One of the biggest pain points for CodeReady Containers over the years has been networking, particularly in corporate environments. Configuring the host system DNS to redirect the &lt;code&gt;crc.testing&lt;/code&gt; domain to the CodeReady Containers virtual machine often required superuser privileges. Additionally, corporate VPNs or firewalls would sometimes get in the way and prevent this setup from working, resulting in cluster connectivity issues for end users.&lt;/p&gt; &lt;p&gt;A few releases ago, we started moving to a userland networking stack based on &lt;a href="https://github.com/containers/gvisor-tap-vsock"&gt;gvisor&lt;/a&gt;. All networking communication by the virtual machine now goes through a CodeReady Containers daemon running on the host. Together with improved usage of the &lt;code&gt;/etc/hosts&lt;/code&gt; file for DNS resolution, this change makes the networking setup less reliant on modifications to the host configuration. It also avoids some of the aforementioned issues with corporate networks. This new networking stack is now the default on Windows and macOS.&lt;/p&gt; &lt;h2&gt;Disk expansion&lt;/h2&gt; &lt;p&gt;CodeReady Containers instances use a 31GB disk image by default. This is not enough for some users who want to deploy heavy workloads.&lt;/p&gt; &lt;p&gt;It’s now possible, when running &lt;code&gt;crc start&lt;/code&gt;, to use the &lt;code&gt;--disk-size&lt;/code&gt; or &lt;code&gt;-d&lt;/code&gt; command-line option to dynamically resize the disk to the desired size. The disk size can only be expanded, not reduced. The following example uses a 40GB disk for the CodeReady Containers instance:&lt;/p&gt; &lt;pre&gt; &lt;code class="language-bash"&gt;$ crc start --disk-size 40&lt;/code&gt;&lt;/pre&gt; &lt;p&gt;On macOS and Windows, you can also use the system tray icon to easily change the disk size.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;This article has summarized the most notable changes the CodeReady Containers team made during the past few months, but there were also plenty more minor improvements and bug fixes. We strongly encourage you to &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_codeready_containers/1.31"&gt;try CodeReady Containers 1.31.2&lt;/a&gt; and report any problems you find.&lt;/p&gt; &lt;p&gt;We’ll keep polishing and improving CodeReady Containers in the months to come. Our roadmap includes Podman integration and improved integration with remote CodeReady Containers instances, so stay tuned!&lt;/p&gt; The post &lt;a href="https://developers.redhat.com/articles/2021/09/01/red-hat-codeready-containers-1312-makes-leap" title="Red Hat CodeReady Containers 1.31.2 makes the leap"&gt;Red Hat CodeReady Containers 1.31.2 makes the leap&lt;/a&gt; appeared first on &lt;a href="https://developers.redhat.com/blog" title="Red Hat Developer"&gt;Red Hat Developer&lt;/a&gt;. &lt;br /&gt;&lt;br /&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/50_u54cQr0w" height="1" width="1" alt=""/&gt;</summary><dc:creator>CodeReady Containers Team</dc:creator><dc:date>2021-09-01T07:00:00Z</dc:date><feedburner:origLink>https://developers.redhat.com/articles/2021/09/01/red-hat-codeready-containers-1312-makes-leap</feedburner:origLink></entry></feed>
