<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>Kubernetes integration and more in odo 2.0</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/6wRR3Cu86CU/" /><category term="codeready" scheme="searchisko:content:tags" /><category term="deploy Operator" scheme="searchisko:content:tags" /><category term="devfile" scheme="searchisko:content:tags" /><category term="devops" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="Java" scheme="searchisko:content:tags" /><category term="Kubernetes" scheme="searchisko:content:tags" /><category term="Node.js" scheme="searchisko:content:tags" /><category term="odo" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><category term="operator" scheme="searchisko:content:tags" /><category term="Python" scheme="searchisko:content:tags" /><author><name>Serena Chechile Nichols</name></author><id>searchisko:content:id:jbossorg_blog-kubernetes_integration_and_more_in_odo_2_0</id><updated>2020-10-06T07:00:04Z</updated><published>2020-10-06T07:00:04Z</published><content type="html">&lt;p&gt;Odo is a &lt;a href="https://developers.redhat.com/blog/2020/06/16/enterprise-kubernetes-development-with-odo-the-cli-tool-for-developers/"&gt;developer-focused command-line interface&lt;/a&gt; (CLI) for OpenShift and Kubernetes. This article introduces highlights of the odo 2.0 release, which now integrates with &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt;. Additional highlights include the new default deployment method in odo 2.0, which uses devfiles for rapid, iterative development. We&amp;#8217;ve also moved &lt;a href="https://developers.redhat.com/topics/kubernetes/operators"&gt;Operator deployment&lt;/a&gt; out of experimental mode, so you can easily deploy Operator-backed services from the &lt;code&gt;odo&lt;/code&gt; command line.&lt;/p&gt; &lt;p&gt;&lt;span id="more-792387"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Odo 2.0 now works with core Kubernetes!&lt;/h2&gt; &lt;p&gt;Odo 2.0 lets you write, build, and deploy applications entirely on Kubernetes. You can use any compliant Kubernetes cluster, whether it&amp;#8217;s a hosted cloud provider, a self-managed cluster, or hosted locally with a tool like Minikube.&lt;/p&gt; &lt;p&gt;Odo&amp;#8217;s integration with Kubernetes provides a consistent development experience. You can write applications from scratch, iterate the &lt;a href="https://developers.redhat.com/devnation/tech-talks/odo-iterative-container-based-development"&gt;development inner loop&lt;/a&gt;, and commit your code to Git, all within the same environment.&lt;/p&gt; &lt;p&gt;To initiate your Kubernetes installation, install the Kubernetes &lt;a target="_blank" rel="nofollow" href="https://github.com/operator-framework/operator-lifecycle-manager"&gt;Operator Lifecycle Manager&lt;/a&gt; and &lt;code&gt;etcd&lt;/code&gt;. See the &lt;a target="_blank" rel="nofollow" href="https://operatorhub.io/operator/etcd"&gt;etcd installation guide&lt;/a&gt; on the Kubernetes Operator Hub.&lt;/p&gt; &lt;h2&gt;Deploy with devfiles in odo 2.0&lt;/h2&gt; &lt;p&gt;This major release establishes devfiles as the default deployment method for odo. Odo still supports Source-to-Image (S2I) deployment for developers who prefer using the &lt;code&gt;--s2i&lt;/code&gt; flag from the command line.&lt;/p&gt; &lt;p&gt;A &lt;em&gt;devfile&lt;/em&gt; is a YAML file that is used to define the developer workspace in &lt;a href="https://developers.redhat.com/videos/youtube/S3auoOqwDS8"&gt;Eclipse Che&lt;/a&gt;. Devfiles have an open format, so we can also use them in &lt;code&gt;odo&lt;/code&gt;. Odo&amp;#8217;s support for devfiles lets developers easily switch between tools, with no additional configuration. Using devfiles also streamlines the process of adding new language support to &lt;code&gt;odo&lt;/code&gt;and Eclipse Che. Now, you only need to create a devfile from a template and update.&lt;/p&gt; &lt;p&gt;See the &lt;a target="_blank" rel="nofollow" href="https://odo.dev/docs/deploying-a-devfile-using-odo/"&gt;odo tutorial&lt;/a&gt; for a guide to deploying your first devfile in &lt;code&gt;odo&lt;/code&gt;.&lt;/p&gt; &lt;h3&gt;A common definition for your developer tools&lt;/h3&gt; &lt;p&gt;With the odo 2.0 release, we have aligned on devfiles as the common definition format for developer workspaces and application lifecycles across Red Hat&amp;#8217;s developer tooling portfolio. &lt;a href="https://developers.redhat.com/products/codeready-workspaces/overview"&gt;Red Hat CodeReady Workspaces&lt;/a&gt; (the productized version of Eclispe Che) currently uses devfiles, and all of the OpenShift IDE extensions leverage &lt;code&gt;odo&lt;/code&gt;, bringing iterative development and deployment flows directly to developers. You can try out &lt;code&gt;odo&lt;/code&gt; directly or access it using IDE extensions for &lt;a href="https://developers.redhat.com/products/vscode-extensions/overview"&gt;VS Code&lt;/a&gt;, &lt;a target="_blank" rel="nofollow" href="https://www.eclipse.org/che/"&gt;Eclipse Che&lt;/a&gt;, and the &lt;a target="_blank" rel="nofollow" href="https://www.eclipse.org/ide/"&gt;Eclipse desktop IDE&lt;/a&gt;.&lt;/p&gt; &lt;h3&gt;Improved language support&lt;/h3&gt; &lt;p&gt;Adding devfiles as the default deployment method improves language support in odo 2.0. To see the list of currently supported devfile components, open your &lt;code&gt;odo&lt;/code&gt; CLI and run:&lt;/p&gt; &lt;pre&gt;$ odo catalog list components &lt;/pre&gt; &lt;p&gt;Table 1 shows the currently available &lt;code&gt;odo&lt;/code&gt; components, including devfile components.&lt;/p&gt; &lt;table align="center"&gt; &lt;caption&gt;Table 1: Odo devfile components&lt;/caption&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;b&gt;Name&lt;/b&gt;&lt;/td&gt; &lt;td&gt;&lt;b&gt;Description&lt;/b&gt;&lt;/td&gt; &lt;td&gt;&lt;b&gt;Registry&lt;/b&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;java-maven&lt;/td&gt; &lt;td&gt;Upstream Maven and OpenJDK 11&lt;/td&gt; &lt;td&gt;DefaultDevfileRegistry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;java-openliberty&lt;/td&gt; &lt;td&gt;Open Liberty microservice in Java&lt;/td&gt; &lt;td&gt;DefaultDevfileRegistry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;java-quarkus&lt;/td&gt; &lt;td&gt;Upstream Quarkus with Java+GraalVM&lt;/td&gt; &lt;td&gt;DefaultDevfileRegistry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;java-springboot&lt;/td&gt; &lt;td&gt;Spring Boot using Java&lt;/td&gt; &lt;td&gt;DefaultDevfileRegistry&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;nodejs&lt;/td&gt; &lt;td&gt;Stack with NodeJS 12&lt;/td&gt; &lt;td&gt;DefaultDevfileRegistry&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;Odo&amp;#8217;s new deployment model is available for &lt;a href="https://developers.redhat.com/topics/enterprise-java"&gt;Java&lt;/a&gt; using &lt;a href="https://developers.redhat.com/products/quarkus/getting-started"&gt;Quarkus&lt;/a&gt;, &lt;a href="https://developers.redhat.com/blog/category/node-js/"&gt;Node.js&lt;/a&gt;, and early access for &lt;a href="https://developers.redhat.com/blog/category/python/"&gt;Python&lt;/a&gt;.&lt;/p&gt; &lt;h3&gt;Sample starters for new projects&lt;/h3&gt; &lt;p&gt;As another advantage of using devfiles, you can now leverage sample starters to scaffold new projects. Simply use the &lt;code&gt;odo create&lt;/code&gt; command to provide the name of your devfile component. Odo will pull a cloned local copy of a starter from the associated Git repository. Here&amp;#8217;s an example:&lt;/p&gt; &lt;pre&gt;$ odo create nodejs --starter Validation  ✓  Checking devfile existence [22411ns]  ✓  Checking devfile compatibility [22492ns]  ✓  Creating a devfile component from registry: DefaultDevfileRegistry [24341ns]  ✓  Validating devfile component [74471ns] Starter Project  ✓  Downloading starter project nodejs-starter from https://github.com/odo-devfiles/nodejs-ex.git [479ms] Please use `odo push` command to create the component with source deployed &lt;/pre&gt; &lt;h2&gt;Debugging with odo&lt;/h2&gt; &lt;p&gt;With this release, the &lt;code&gt;odo debug&lt;/code&gt; command has graduated from tech preview. See the odo tutorial for more about &lt;a target="_blank" rel="nofollow" href="https://odo.dev/docs/debugging-using-devfile/"&gt;debugging application components with the odo CLI or VS Code&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Using Operators for installation&lt;/h2&gt; &lt;p&gt;Developers can now deploy Operator-backed services with &lt;code&gt;odo&lt;/code&gt;. Operators provide custom resource definitions (CRDs), which you can use to create service instances—also known as custom resources (CRs), or operands. You can then use these instances in your projects and link them to your components.&lt;/p&gt; &lt;p&gt;Here&amp;#8217;s an example, using the &lt;code&gt;etcd&lt;/code&gt; Operator to deploy an Etcd cluster:&lt;/p&gt; &lt;pre&gt;$ odo catalog list services   Operators available in the cluster   NAME                          CRDs  etcdoperator.v0.9.4           EtcdCluster, EtcdBackup, EtcdRestore $ odo service create etcdoperator.v0.9.4/EtcdCluster &lt;/pre&gt; &lt;p&gt;See the odo tutorial for more about &lt;a target="_blank" rel="nofollow" href="https://odo.dev/docs/operator-hub/#deploying-operator-backed-service-to-a-cluster-via-yaml"&gt;deploying Operator-backed services with odo&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F10%2F06%2Fkubernetes-integration-and-more-in-odo-2-0%2F&amp;#38;linkname=Kubernetes%20integration%20and%20more%20in%20odo%202.0" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F10%2F06%2Fkubernetes-integration-and-more-in-odo-2-0%2F&amp;#38;linkname=Kubernetes%20integration%20and%20more%20in%20odo%202.0" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F10%2F06%2Fkubernetes-integration-and-more-in-odo-2-0%2F&amp;#38;linkname=Kubernetes%20integration%20and%20more%20in%20odo%202.0" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F10%2F06%2Fkubernetes-integration-and-more-in-odo-2-0%2F&amp;#38;linkname=Kubernetes%20integration%20and%20more%20in%20odo%202.0" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F10%2F06%2Fkubernetes-integration-and-more-in-odo-2-0%2F&amp;#38;linkname=Kubernetes%20integration%20and%20more%20in%20odo%202.0" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F10%2F06%2Fkubernetes-integration-and-more-in-odo-2-0%2F&amp;#38;linkname=Kubernetes%20integration%20and%20more%20in%20odo%202.0" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F10%2F06%2Fkubernetes-integration-and-more-in-odo-2-0%2F&amp;#38;linkname=Kubernetes%20integration%20and%20more%20in%20odo%202.0" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F10%2F06%2Fkubernetes-integration-and-more-in-odo-2-0%2F&amp;#038;title=Kubernetes%20integration%20and%20more%20in%20odo%202.0" data-a2a-url="https://developers.redhat.com/blog/2020/10/06/kubernetes-integration-and-more-in-odo-2-0/" data-a2a-title="Kubernetes integration and more in odo 2.0"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/10/06/kubernetes-integration-and-more-in-odo-2-0/"&gt;Kubernetes integration and more in odo 2.0&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/6wRR3Cu86CU" height="1" width="1" alt=""/&gt;</content><summary>Odo is a developer-focused command-line interface (CLI) for OpenShift and Kubernetes. This article introduces highlights of the odo 2.0 release, which now integrates with Kubernetes. Additional highlights include the new default deployment method in odo 2.0, which uses devfiles for rapid, iterative development. We’ve also moved Operator deployment out of experimental mode, so you can easily deploy...</summary><dc:creator>Serena Chechile Nichols</dc:creator><dc:date>2020-10-06T07:00:04Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/10/06/kubernetes-integration-and-more-in-odo-2-0/</feedburner:origLink></entry><entry><title>CodeReady Containers - Getting Started with OpenShift Container Platform 4.5 and Decision Manager Tooling</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/0DSID4pnaa8/codeready-containers-getting-started-with-ocp-45-and-decision-manager-tooling.html" /><category term="AppDev" scheme="searchisko:content:tags" /><category term="Automate" scheme="searchisko:content:tags" /><category term="cloud" scheme="searchisko:content:tags" /><category term="CodeReadyContainers" scheme="searchisko:content:tags" /><category term="Containers" scheme="searchisko:content:tags" /><category term="Decision Manager" scheme="searchisko:content:tags" /><category term="feed_group_name_global" scheme="searchisko:content:tags" /><category term="feed_name_ericschabell" scheme="searchisko:content:tags" /><category term="JBoss" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><author><name>Eric D. Schabell</name></author><id>searchisko:content:id:jbossorg_blog-codeready_containers_getting_started_with_openshift_container_platform_4_5_and_decision_manager_tooling</id><updated>2020-10-06T09:28:11Z</updated><published>2020-10-05T05:00:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;table cellpadding="0" cellspacing="0" class="tr-caption-container" style="float: left; margin-right: 1em;"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style="text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-4Rs3JaM6ne4/X3ddBFq5MdI/AAAAAAAAxk4/Y1gM9X2hSK0rMIx-bTvlcOmIU6Yd47TUACNcBGAsYHQ/s2048/jon-tyson-PXB7yEM5LVs-unsplash.jpg" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="2048" data-original-width="1536" height="200" src="https://1.bp.blogspot.com/-4Rs3JaM6ne4/X3ddBFq5MdI/AAAAAAAAxk4/Y1gM9X2hSK0rMIx-bTvlcOmIU6Yd47TUACNcBGAsYHQ/w150-h200/jon-tyson-PXB7yEM5LVs-unsplash.jpg" width="150" /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt; For some time now we've been working on updating your experience using CodeReady Containers, a container platform installation for your local machine, by providing interesting developer tooling and project examples.&amp;nbsp;&lt;/div&gt;&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;The first example here is the latest version of the Red Hat Decision Manager installed on OpenShift Container Platform (either your own installation or using our &lt;a href="https://www.schabell.org/2020/09/how-to-setup-openshift-container-platform-45.html" target="_blank"&gt;CodeReady Containers installation&lt;/a&gt;).&lt;/div&gt;&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;Get started today with rules and business logic in just a few simple steps, as follows.&amp;nbsp;&lt;/div&gt;&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;There is no better way to learn about container technologies, container platforms, and container-based application development than getting hands-on with great open technologies.&amp;nbsp;&lt;/div&gt;&lt;span&gt;&lt;a name='more'&gt;&lt;/a&gt;&lt;/span&gt;&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;This demo is to install Red Hat Decision Manager in the Cloud based on leveraging a Red Hat OpenShift Container Platform. It delivers a fully functioning Decision Manager containerized on OpenShift Container Platform.&lt;/div&gt;&lt;div&gt;&lt;div data-sourcepos="3:1-4:70" dir="auto"&gt;&lt;br /&gt;&lt;/div&gt;&lt;h3 data-sourcepos="7:1-9:131"&gt;Install on OpenShift Container Platform&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-lOy42L6FlZA/X3dbMEui4AI/AAAAAAAAxkg/EnNt4FQ7rtoUZtqckhYg85GHokiZFm4BQCNcBGAsYHQ/s1543/rhdm-build-rhdmauthor.png" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"&gt;&lt;img alt="code ready containers" border="0" data-original-height="827" data-original-width="1543" height="172" src="https://1.bp.blogspot.com/-lOy42L6FlZA/X3dbMEui4AI/AAAAAAAAxkg/EnNt4FQ7rtoUZtqckhYg85GHokiZFm4BQCNcBGAsYHQ/w320-h172/rhdm-build-rhdmauthor.png" width="320" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;/h3&gt;&lt;div data-sourcepos="9:1-10:83" dir="auto"&gt;There are two options to install and run this project on the OpenShift Container Platform; use your own existing installation or to install on &lt;a href="https://www.schabell.org/2020/09/how-to-setup-openshift-container-platform-45.html" target="_blank"&gt;CodeReady Containers which provides you with a local OpenShift cluster&lt;/a&gt;.&lt;/div&gt;&lt;ol data-sourcepos="12:1-13:0" dir="auto"&gt;&lt;li data-sourcepos="12:1-13:0"&gt;Ensure you have an OpenShift container based installation, such as one of the following:&lt;/li&gt;&lt;/ol&gt;&lt;ul data-sourcepos="14:3-17:0" style="text-align: left;"&gt;&lt;li&gt;your own OpenShift installation, if using this you just need to pass the IP address to the init.{sh|bat} script.&lt;/li&gt;&lt;li data-sourcepos="16:3-17:0"&gt;&lt;div data-sourcepos="16:5-16:95"&gt;&lt;a href="https://gitlab.com/redhatdemocentral/ocp-install-demo"&gt;Code Ready Containers Easy Install&lt;/a&gt;&lt;/div&gt;&lt;/li&gt;&lt;/ul&gt;&lt;ol data-sourcepos="18:1-23:0" start="2" style="text-align: left;"&gt;&lt;li data-sourcepos="18:1-19:0"&gt;&lt;div data-sourcepos="18:4-18:146"&gt;&lt;a href="https://gitlab.com/redhatdemocentral/rhcs-rhdm-install-demo/-/archive/master/rhcs-rhdm-install-demo-master.zip"&gt;Download and unzip this demo.&lt;/a&gt;&lt;/div&gt;&lt;/li&gt;&lt;li data-sourcepos="18:1-19:0"&gt;&lt;div data-sourcepos="18:4-18:146"&gt;Run 'init.sh' or 'init.bat' file. 'init.bat' must be run with Administrative privileges:&lt;/div&gt;&lt;/li&gt;&lt;/ol&gt;&lt;pre class="code highlight js-syntax-highlight plaintext dark" lang="plaintext"&gt;&lt;code&gt;&lt;span class="line" id="LC1" lang="plaintext"&gt; # If using your own installation just point to Openshift Container Platform IP Address&lt;/span&gt;&lt;br /&gt;&lt;span class="line" id="LC2" lang="plaintext"&gt; # as follows:&lt;/span&gt;&lt;br /&gt;&lt;span class="line" id="LC3" lang="plaintext"&gt; #&lt;/span&gt;&lt;br /&gt;&lt;span class="line" id="LC4" lang="plaintext"&gt; $ ./init.sh 192.168.99.100 # example for OCP.&lt;br /&gt;&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;pre class="code highlight js-syntax-highlight plaintext dark" lang="plaintext"&gt;&lt;code&gt;&lt;span class="line" id="LC1" lang="plaintext"&gt; # If using CodeReady Containers or the CodeReady Containers Easy Install project, just add the cluster &lt;/span&gt;&lt;br /&gt;&lt;span class="line" id="LC2" lang="plaintext"&gt; # address to HOST_IP variable found at the top of the init.{sh|bat} files, for example:&lt;/span&gt;&lt;br /&gt;&lt;span class="line" id="LC3" lang="plaintext"&gt; #&lt;/span&gt;&lt;br /&gt;&lt;span class="line" id="LC4" lang="plaintext"&gt; # HOST_IP=api.crc.testing &lt;/span&gt;&lt;br /&gt;&lt;span class="line" id="LC5" lang="plaintext"&gt; # &lt;/span&gt;&lt;br /&gt;&lt;span class="line" id="LC6" lang="plaintext"&gt; # Now just run the script without any IP address arguments and it picks up that hostname as follows:&lt;/span&gt;&lt;br /&gt;&lt;span class="line" id="LC7" lang="plaintext"&gt; #&lt;/span&gt;&lt;br /&gt;&lt;span class="line" id="LC8" lang="plaintext"&gt; $ ./init.sh&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;div data-sourcepos="42:1-42:140" dir="auto"&gt;&lt;br /&gt;&lt;/div&gt;&lt;div data-sourcepos="42:1-42:140" dir="auto"&gt;&lt;a href="https://www.blogger.com/blog/post/edit/3868547292717970492/2667182560341544792#" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"&gt;&lt;img alt="Red Hat Decision Manager" border="0" data-original-height="988" data-original-width="1600" height="197" src="https://1.bp.blogspot.com/-jn-qDgri7Ag/XhLqljebByI/AAAAAAAAw1A/ewJyAbDlq5YD4VjMg4I0AqLAzGk89D0FwCEwYBhgL/s320/rhdm-ocp.png" title="" width="320" /&gt;&lt;/a&gt;Now log in to Red Hat Decision Manager to start developing containerized process automation projects (the address will be generated by OCP):&lt;/div&gt;&lt;ul data-sourcepos="44:3-45:0" dir="auto"&gt;&lt;li data-sourcepos="44:3-45:0"&gt;CodeReady Container example: http:rhcs-rhdm-install-demo-appdev-in-cloud.apps-crc.testing/decision-central ( u:erics / p:redhatdm1! )&lt;/li&gt;&lt;/ul&gt;&lt;div data-sourcepos="46:1-46:195" dir="auto"&gt;Not sure how to get started with Red Hat Decision Manager? Try one of these&amp;nbsp;&lt;a href="https://www.blogger.com/blog/post/edit/3868547292717970492/2667182560341544792#" rel="nofollow noreferrer noopener"&gt;online workshops&lt;/a&gt;&amp;nbsp;to build a first project from scratch.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="feedflare"&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=vMaeJDMSLpQ:UJBoSR2HJYU:yIl2AUoC8zA"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=yIl2AUoC8zA" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=vMaeJDMSLpQ:UJBoSR2HJYU:63t7Ie-LG7Y"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=63t7Ie-LG7Y" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=vMaeJDMSLpQ:UJBoSR2HJYU:4cEx4HpKnUU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=vMaeJDMSLpQ:UJBoSR2HJYU:4cEx4HpKnUU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=vMaeJDMSLpQ:UJBoSR2HJYU:F7zBnMyn0Lo"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=vMaeJDMSLpQ:UJBoSR2HJYU:F7zBnMyn0Lo" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=vMaeJDMSLpQ:UJBoSR2HJYU:V_sGLiPBpWU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=vMaeJDMSLpQ:UJBoSR2HJYU:V_sGLiPBpWU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=vMaeJDMSLpQ:UJBoSR2HJYU:qj6IDK7rITs"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=qj6IDK7rITs" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=vMaeJDMSLpQ:UJBoSR2HJYU:gIN9vFwOqvQ"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=vMaeJDMSLpQ:UJBoSR2HJYU:gIN9vFwOqvQ" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/schabell/jboss/~4/vMaeJDMSLpQ" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/0DSID4pnaa8" height="1" width="1" alt=""/&gt;</content><summary>For some time now we've been working on updating your experience using CodeReady Containers, a container platform installation for your local machine, by providing interesting developer tooling and project examples.  The first example here is the latest version of the Red Hat Decision Manager installed on OpenShift Container Platform (either your own installation or using our CodeReady Containers ...</summary><dc:creator>Eric D. Schabell</dc:creator><dc:date>2020-10-05T05:00:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/vMaeJDMSLpQ/codeready-containers-getting-started-with-ocp-45-and-decision-manager-tooling.html</feedburner:origLink></entry><entry><title>Customizing and tuning the Kuryr SDN for Red Hat OpenShift 3.11 on Red Hat OpenStack 13</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/FeaA957blM8/" /><category term="Containers" scheme="searchisko:content:tags" /><category term="double encapsulation" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="floating IP" scheme="searchisko:content:tags" /><category term="Kubernetes" scheme="searchisko:content:tags" /><category term="Kuryr" scheme="searchisko:content:tags" /><category term="linux" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><category term="OpenStack" scheme="searchisko:content:tags" /><category term="performance" scheme="searchisko:content:tags" /><author><name>mohammad ahmad</name></author><id>searchisko:content:id:jbossorg_blog-customizing_and_tuning_the_kuryr_sdn_for_red_hat_openshift_3_11_on_red_hat_openstack_13</id><updated>2020-10-02T07:23:04Z</updated><published>2020-10-02T07:23:04Z</published><content type="html">&lt;p&gt;In &lt;a href="https://developers.redhat.com/blog/2019/11/01/how-to-customize-the-red-hat-openshift-3-11-sdn/"&gt;a previous article&lt;/a&gt;, I showed you how to customize &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt; software-defined networking (SDN) for your organization&amp;#8217;s requirements and restrictions. In this article, we&amp;#8217;ll look at using the &lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/3.11/install_config/configuring_kuryrsdn.html"&gt;Kuryr SDN&lt;/a&gt; instead. Using Kuryr with &lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/3.11/welcome/index.html"&gt;OpenShift 3.11&lt;/a&gt; on &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/documentation/en-us/red_hat_openstack_platform/13"&gt;Red Hat OpenStack 13&lt;/a&gt; changes the customization requirements because Kuryr works directly with OpenStack Neutron and Octavia.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: This article builds on the discussion and examples from my previous one. I recommend reading the previous one first.&lt;/p&gt; &lt;h2&gt;Background&lt;/h2&gt; &lt;p&gt;Traditional OpenShift installations leverage &lt;code&gt;openshift-sdn&lt;/code&gt;, which is specific to OpenShift. Using &lt;code&gt;openshift-sdn&lt;/code&gt; means that your containers run on a network within a network. This setup, known as &lt;em&gt;double encapsulation&lt;/em&gt;, introduces an additional layer of complexity, which becomes apparent when troubleshooting network issues. Double encapsulation also affects network performance due to the overhead of running a network within a network.&lt;/p&gt; &lt;p&gt;&lt;span id="more-766097"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;If you are running OpenShift on OpenStack, then you have the option to use the Kuryr SDN, which allows you to directly access OpenStack&amp;#8217;s Neutron services and avoid double encapsulation. Using the &lt;code&gt;kuryr-cni&lt;/code&gt; means that all of your OpenShift components—networks, subnets, load balancers, ports, and so on—are, in fact, OpenStack resources. This setup reduces the complexity of the networking layer. It also &lt;a target="_blank" rel="nofollow" href="https://www.openshift.com/blog/accelerate-your-openshift-network-performance-on-openstack-with-kuryr"&gt;improves network performance&lt;/a&gt;. As another benefit, you can assign floating IPs to any of the OpenShift services, which allows traffic directly into the service without having to go through the OpenShift router.&lt;/p&gt; &lt;p&gt;In some cases, you might need to customize Kuryr&amp;#8217;s network-range defaults, such as if the defaults overlap with your organization’s network. Let&amp;#8217;s look at the requirements for customizing the Kuryr network.&lt;/p&gt; &lt;h2&gt;Customizing the Kuryr network&lt;/h2&gt; &lt;p&gt;We&amp;#8217;ll use the same base address range from the customization example in my &lt;a href="https://developers.redhat.com/blog/2019/11/01/how-to-customize-the-red-hat-openshift-3-11-sdn/"&gt;previous article&lt;/a&gt;: 192.168.0.0/16. In this case, we&amp;#8217;ll divide the range between the service network (192.168.128.0/18), pod network (192.168.0.0/17), and docker-bridge network. For this specific example, we intend to configure Kuryr with namespace isolation, similar to &lt;code&gt;ovs-multitenant&lt;/code&gt; when using &lt;code&gt;openshift-sdn&lt;/code&gt;.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;b&gt;Note&lt;/b&gt;: &lt;a target="_blank" rel="nofollow" href="https://github.com/openshift/openshift-ansible"&gt;OpenShift-Ansible&lt;/a&gt;, which was featured in my last article, has significantly more parameter requirements to deliver the same network IP range customizations that we can achieve with the Kuryr Container Network Interface (CNI).&lt;/p&gt; &lt;h3&gt;Kuryr service network&lt;/h3&gt; &lt;p&gt;Because Kuryr uses Octavia load balancers (which is an Amphora VM in OpenStack), every OpenShift service is an instance of an Octavia load balancer. Therefore, &lt;code&gt;openshift_portal_net&lt;/code&gt; is the address range that OpenShift uses to assign IP addresses to OpenShift (Kubernetes) services. Each IP address will be associated with an Octavia load balancer as a VIP (Virtual IP, or floating port in OpenStack) in case of failover. Additionally, because Octavia load balancers are Amphora VMs, they also require a port/IP, which should not collide with the &lt;code&gt;openshift_portal_net&lt;/code&gt; range.&lt;/p&gt; &lt;p&gt;Using the following ranges ensures a clear distinction between the Amphora VM IP range and the OpenShift service IP range:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;code&gt;openshift_openstack_kuryr_service_subnet_cidr&lt;/code&gt;: The range to be used by both OpenShift service IPs and the Octavia load balancer Amphora VM IPs. In this case, the range is 192.168.128.0/18, which is between 192.168.128.0 and 192.168.191.254.&lt;/li&gt; &lt;li&gt;&lt;code&gt;openshift_portal_net&lt;/code&gt;: The range dedicated to OpenShift service IPs. In this case, the range is 192.168.128.0/19, which is between 192.168.128.0 and 192.168.159.254.&lt;/li&gt; &lt;li&gt;&lt;code&gt;openshift_openstack_kuryr_service_pool_start&lt;/code&gt;: The start of the range to be used by the Octavia load balancer Amphora VM IPs. In this case, it is the second half of the range identified in the first parameter (&lt;code&gt;openshift_openstack_kuryr_service_subnet_cidr&lt;/code&gt;). The start of that range is 192.168.160.0.&lt;/li&gt; &lt;li&gt;&lt;code&gt;openshift_openstack_kuryr_service_pool_end&lt;/code&gt;: The end of the range used by the Octavia load balancer Amphora VM IPs. In this case, it is 192.168.191.254.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Figure 1 shows Amphora VM&amp;#8217;s IP allocation when implemented with an OpenShift service.&lt;/p&gt; &lt;div id="attachment_766107" style="width: 649px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Amphora-VM-IP-in-service.png"&gt;&lt;img aria-describedby="caption-attachment-766107" class="wp-image-766107" src="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Amphora-VM-IP-in-service.png" alt="Amphora VM's IP allocation groupings between itself and OpenShift" width="639" height="373" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/08/Amphora-VM-IP-in-service.png 960w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Amphora-VM-IP-in-service-300x175.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/08/Amphora-VM-IP-in-service-768x448.png 768w" sizes="(max-width: 639px) 100vw, 639px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-766107" class="wp-caption-text"&gt;Figure 1: Clearly defining each range avoids IP collisions.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Kuryr pod network&lt;/h3&gt; &lt;p&gt;There are no changes to the pod network, which is straightforward. In our case, it&amp;#8217;s:&lt;/p&gt; &lt;pre&gt;openshift_openstack_kuryr_pod_subnet_cidr: 192.168.0.0/17&lt;/pre&gt; &lt;h2&gt;Customizing the Kuryr inventory parameters&lt;/h2&gt; &lt;p&gt;Next, we&amp;#8217;ll look at all of the inventory parameters required to successfully configure a customized OpenShift IP range.&lt;/p&gt; &lt;h3&gt;Enabling namespace isolation&lt;/h3&gt; &lt;p&gt;These parameters are needed to enable namespace isolation in Kuryr:&lt;/p&gt; &lt;pre&gt;openshift_use_kuryr: True openshift_use_openshift_sdn: False use_trunk_ports: True os_sdn_network_plugin_name: cni openshift_node_proxy_mode: userspace kuryr_openstack_pool_driver: nested &lt;/pre&gt; &lt;p&gt;You must ensure that &lt;code&gt;os_sdn_network_plugin_name&lt;/code&gt; is unset.&lt;/p&gt; &lt;h3&gt;IP range&lt;/h3&gt; &lt;p&gt;Failing to set the IP range clearly causes performance problems with the &lt;code&gt;kuryr-controller&lt;/code&gt;, and IP conflicts:&lt;/p&gt; &lt;pre&gt;#SERVICE: openshift_portal_net: 192.168.128.0/19 openshift_openstack_kuryr_service_subnet_cidr: 192.168.128.0/18 openshift_openstack_kuryr_service_pool_start: 192.168.160.1 openshift_openstack_kuryr_service_pool_end: 192.168.191.253 #POD openshift_openstack_kuryr_pod_subnet_cidr: 192.168.0.0/17 &lt;/pre&gt; &lt;p&gt;The OpenShift service IP range is from 192.168.128.0 to 192.168.159.254; the Amphora VM IP range is from 192.168.160.1 to 19.168.191.254; and the pod IP range is from 192.168.0.1 to 192.168.127.254.&lt;/p&gt; &lt;p&gt;Note that the following types of errors will cause the OpenShift service IP range to conflict with Amphora VM&amp;#8217;s IP range:&lt;/p&gt; &lt;pre&gt;ERROR kuryr_kubernetes.controller.drivers.lbaasv2 [-] Error when creating loadbalancer: {"debuginfo": null, "faultcode": "Client", "faultstring": "IP address 192.168.123.123 already allocated in subnet &lt;/pre&gt; &lt;h3&gt;Pre-creating subports&lt;/h3&gt; &lt;p&gt;This value is generally relevant when you have a flat network, where pre-creating subports contributes to the overall deployment speed for applications that require network resources. In most cases, you can set this value to false:&lt;/p&gt; &lt;pre&gt;openshift_kuryr_precreate_subports: false &lt;/pre&gt; &lt;h3&gt;Cluster sizing&lt;/h3&gt; &lt;p&gt;This parameter changes the way that you size a cluster, so it is important. The number of pods per namespace is determined by &lt;code&gt;prefixlen&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;openshift_openstack_kuryr_pod_subnet_prefixlen &lt;/pre&gt; &lt;p&gt;Where:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;/24 = 256 pods per namespace&lt;/li&gt; &lt;li&gt;/25 = 128 pods per namespace&lt;/li&gt; &lt;li&gt;/26 = 64 pods per namespace&lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;Pool batch&lt;/h3&gt; &lt;p&gt;The &lt;code&gt;kuryr_openstack_pool_batch&lt;/code&gt; value needs to be set based on &lt;code&gt;openshift_openstack_kuryr_pod_subnet_prefixlen&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;kuryr_openstack_pool_max: kuryr_openstack_pool_min: &lt;/pre&gt; &lt;p&gt;Here are some suggestions for the following values of &lt;code&gt;openshift_openstack_kuryr_pod_subnet_prefixlen&lt;/code&gt;:&lt;/p&gt; &lt;p&gt;24: batch: 5, max: 10, min: 1&lt;br /&gt; 25: batch: 4, max: 7, min: 1&lt;br /&gt; 26: batch: 3, max: 5, min: 1&lt;/p&gt; &lt;p&gt;Also note that each OpenShift node will have its own pool, so if you have three worker nodes, each node will have a dedicated pool for that namespace. This requirement limits how many worker nodes you can use based on the size of &lt;code&gt;openshift_openstack_kuryr_pod_subnet_prefixlen&lt;/code&gt;.&lt;/p&gt; &lt;h3&gt;kuryr_openstack_ca: &amp;#8220;MYORG_CA_Bundle.txt&amp;#8221;&lt;/h3&gt; &lt;p&gt;If you do not set this value, Kuryr will fail.&lt;/p&gt; &lt;h3&gt;Images&lt;/h3&gt; &lt;p&gt;Providing specific values for the images rules out the risk of default images being incorrect:&lt;/p&gt; &lt;pre&gt;openshift_openstack_kuryr_controller_image openshift_openstack_kuryr_cni_image &lt;/pre&gt; &lt;h3&gt;kuryr_openstack_public_net_id&lt;/h3&gt; &lt;p&gt;You can get this value from &lt;code&gt;openstack network list&lt;/code&gt;.&lt;/p&gt; &lt;h3&gt;Global namespaces&lt;/h3&gt; &lt;p&gt;By default, these are the only namespaces that are considered &lt;i&gt;global&lt;/i&gt;, meaning that Kuryr allows other namespaces to reach these namespaces despite namespace isolation:&lt;/p&gt; &lt;pre&gt;kuryr_openstack_global_namespaces: default,openshift-monitoring &lt;/pre&gt; &lt;h3&gt;Namespace isolation&lt;/h3&gt; &lt;p&gt;The &lt;code&gt;openshift_kuryr_subnet_driver: namespace&lt;/code&gt; and &lt;code&gt;openshift_kuryr_sg_driver: namespace&lt;/code&gt; are required for namespace isolation.&lt;/p&gt; &lt;h3&gt;DNS lookup&lt;/h3&gt; &lt;p&gt;The values here allow DNS lookup:&lt;/p&gt; &lt;pre&gt;openshift_master_open_ports: - service: dns tcp   port: 53/tcp - service: dns udp   port: 53/udp openshift_node_open_ports: - service: dns tcp   port: 53/tcp - service: dns udp   port: 53/udp &lt;/pre&gt; &lt;h3&gt;openshift_openstack_node_secgroup_rules&lt;/h3&gt; &lt;pre&gt;# NOTE(shadower): the 53 rules are needed for Kuryr - direction: ingress protocol: tcp port_range_min: 53 port_range_max: 53 - direction: ingress protocol: udp port_range_min: 53 port_range_max: 53 - direction: ingress protocol: tcp port_range_min: 10250 port_range_max: 10250 remote_ip_prefix: "{{ openshift_openstack_kuryr_pod_subnet_cidr }}" - direction: ingress protocol: tcp port_range_min: 10250 port_range_max: 10250 remote_ip_prefix: "{{ openshift_openstack_subnet_cidr }}" - direction: ingress protocol: udp port_range_min: 4789 port_range_max: 4789 remote_ip_prefix: "{{ openshift_openstack_kuryr_pod_subnet_cidr }}" - direction: ingress protocol: udp port_range_min: 4789 port_range_max: 4789 remote_ip_prefix: "{{ openshift_openstack_subnet_cidr }}" - direction: ingress protocol: tcp port_range_min: 9100 port_range_max: 9100 remote_ip_prefix: "{{ openshift_openstack_kuryr_pod_subnet_cidr }}" - direction: ingress protocol: tcp port_range_min: 9100 port_range_max: 9100 remote_ip_prefix: "{{ openshift_openstack_subnet_cidr }}" - direction: ingress protocol: tcp port_range_min: 8444 port_range_max: 8444 remote_ip_prefix: "{{ openshift_openstack_kuryr_pod_subnet_cidr }}" - direction: ingress protocol: tcp port_range_min: 8444 port_range_max: 8444 remote_ip_prefix: "{{ openshift_openstack_subnet_cidr }}" &lt;/pre&gt; &lt;p&gt;Most importantly, never use &lt;code&gt;remote_group_id&lt;/code&gt;. Instead, only use &lt;code&gt;remote_ip_prefix&lt;/code&gt;.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;Using Kuryr with OpenShift 3.11 on OpenStack 13 provides the benefits of using OpenStack&amp;#8217;s Neutron networking directly for OpenShift pods and services, instead of the OpenShift SDN. Avoiding double encapsulation improves performance and reduces troubleshooting complexity, and you also get the benefits of directly associating floating IPs to OpenShift services, which is useful in several applications.&lt;/p&gt; &lt;p&gt;There are, however, parameters that must be configured correctly in order to get an optimally running OpenShift cluster with Kuryr. This article identified all of the important parameters and the recommended values that are required to configure a cluster that suits your needs.&lt;/p&gt; &lt;h2&gt;Acknowledgments&lt;/h2&gt; &lt;p&gt;I would like to acknowledge &lt;a target="_blank" rel="nofollow" href="https://ltomasbo.wordpress.com/"&gt;Luis Tomas Bolivar&lt;/a&gt; as my co-author and &lt;a href="https://developers.redhat.com/blog/author/pnguyen/"&gt;Phuong Nguyen&lt;/a&gt; as our peer reviewer.&lt;/p&gt; &lt;h2&gt;References&lt;/h2&gt; &lt;p&gt;For additional information:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;See &amp;#8220;&lt;a href="https://developers.redhat.com/blog/2019/11/01/how-to-customize-the-red-hat-openshift-3-11-sdn/"&gt;How to customize the Red Hat OpenShift 3.11 SDN&lt;/a&gt;&amp;#8221; ( Mohammad Ahmad, 2019) for the original discussion and example that are the basis for this article.&lt;/li&gt; &lt;li&gt;See &amp;#8220;&lt;a target="_blank" rel="nofollow" href="https://www.openshift.com/blog/accelerate-your-openshift-network-performance-on-openstack-with-kuryr"&gt;Accelerate your OpenShift Network Performance on OpenStack with Kuryr&lt;/a&gt;&amp;#8221; (Rodriguez, Malleni, and Bolivar, 2019) for an architectural overview and performance comparison of the Kuryr SDN versus OpenShift SDN.&lt;/li&gt; &lt;li&gt;See the &lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/3.11/install_config/configuring_kuryrsdn.html"&gt;Kuryr SDN and OpenShift Container Platform (OCP 3.11) documentation&lt;/a&gt; for detailed information about configuring the Kuryr SDN.&lt;/li&gt; &lt;li&gt;See &lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/3.11/install_config/configuring_openstack.html"&gt;Configuring for OpenStack&lt;/a&gt; (OCP 3.11) for more about configuring OCP to access the OpenStack infrastructure.&lt;/li&gt; &lt;li&gt;See &lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/3.11/admin_guide/kuryr.html"&gt;Kuryr SDN Administration&lt;/a&gt; (OCP 3.11) for more about configuring the Kuryr SDN.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F10%2F02%2Fcustomizing-and-tuning-the-kuryr-sdn-for-red-hat-openshift-3-11-on-red-hat-openstack-13%2F&amp;#38;linkname=Customizing%20and%20tuning%20the%20Kuryr%20SDN%20for%20Red%20Hat%20OpenShift%203.11%20on%20Red%20Hat%20OpenStack%2013" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F10%2F02%2Fcustomizing-and-tuning-the-kuryr-sdn-for-red-hat-openshift-3-11-on-red-hat-openstack-13%2F&amp;#38;linkname=Customizing%20and%20tuning%20the%20Kuryr%20SDN%20for%20Red%20Hat%20OpenShift%203.11%20on%20Red%20Hat%20OpenStack%2013" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F10%2F02%2Fcustomizing-and-tuning-the-kuryr-sdn-for-red-hat-openshift-3-11-on-red-hat-openstack-13%2F&amp;#38;linkname=Customizing%20and%20tuning%20the%20Kuryr%20SDN%20for%20Red%20Hat%20OpenShift%203.11%20on%20Red%20Hat%20OpenStack%2013" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F10%2F02%2Fcustomizing-and-tuning-the-kuryr-sdn-for-red-hat-openshift-3-11-on-red-hat-openstack-13%2F&amp;#38;linkname=Customizing%20and%20tuning%20the%20Kuryr%20SDN%20for%20Red%20Hat%20OpenShift%203.11%20on%20Red%20Hat%20OpenStack%2013" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F10%2F02%2Fcustomizing-and-tuning-the-kuryr-sdn-for-red-hat-openshift-3-11-on-red-hat-openstack-13%2F&amp;#38;linkname=Customizing%20and%20tuning%20the%20Kuryr%20SDN%20for%20Red%20Hat%20OpenShift%203.11%20on%20Red%20Hat%20OpenStack%2013" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F10%2F02%2Fcustomizing-and-tuning-the-kuryr-sdn-for-red-hat-openshift-3-11-on-red-hat-openstack-13%2F&amp;#38;linkname=Customizing%20and%20tuning%20the%20Kuryr%20SDN%20for%20Red%20Hat%20OpenShift%203.11%20on%20Red%20Hat%20OpenStack%2013" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F10%2F02%2Fcustomizing-and-tuning-the-kuryr-sdn-for-red-hat-openshift-3-11-on-red-hat-openstack-13%2F&amp;#38;linkname=Customizing%20and%20tuning%20the%20Kuryr%20SDN%20for%20Red%20Hat%20OpenShift%203.11%20on%20Red%20Hat%20OpenStack%2013" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F10%2F02%2Fcustomizing-and-tuning-the-kuryr-sdn-for-red-hat-openshift-3-11-on-red-hat-openstack-13%2F&amp;#038;title=Customizing%20and%20tuning%20the%20Kuryr%20SDN%20for%20Red%20Hat%20OpenShift%203.11%20on%20Red%20Hat%20OpenStack%2013" data-a2a-url="https://developers.redhat.com/blog/2020/10/02/customizing-and-tuning-the-kuryr-sdn-for-red-hat-openshift-3-11-on-red-hat-openstack-13/" data-a2a-title="Customizing and tuning the Kuryr SDN for Red Hat OpenShift 3.11 on Red Hat OpenStack 13"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/10/02/customizing-and-tuning-the-kuryr-sdn-for-red-hat-openshift-3-11-on-red-hat-openstack-13/"&gt;Customizing and tuning the Kuryr SDN for Red Hat OpenShift 3.11 on Red Hat OpenStack 13&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/FeaA957blM8" height="1" width="1" alt=""/&gt;</content><summary>In a previous article, I showed you how to customize Red Hat OpenShift software-defined networking (SDN) for your organization’s requirements and restrictions. In this article, we’ll look at using the Kuryr SDN instead. Using Kuryr with OpenShift 3.11 on Red Hat OpenStack 13 changes the customization requirements because Kuryr works directly with OpenStack Neutron and Octavia. Note: This article b...</summary><dc:creator>mohammad ahmad</dc:creator><dc:date>2020-10-02T07:23:04Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/10/02/customizing-and-tuning-the-kuryr-sdn-for-red-hat-openshift-3-11-on-red-hat-openstack-13/</feedburner:origLink></entry><entry><title>Command-line cluster management with Red Hat OpenShift’s new web terminal (tech preview)</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/swGMQMl_psE/" /><category term="devops" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="Kubernetes" scheme="searchisko:content:tags" /><category term="linux" scheme="searchisko:content:tags" /><category term="odo" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><category term="OpenShift cluster" scheme="searchisko:content:tags" /><category term="OpenShift Operator" scheme="searchisko:content:tags" /><category term="operator" scheme="searchisko:content:tags" /><category term="Web Terminal Operator" scheme="searchisko:content:tags" /><author><name>Joshua Wood</name></author><id>searchisko:content:id:jbossorg_blog-command_line_cluster_management_with_red_hat_openshift_s_new_web_terminal_tech_preview</id><updated>2020-10-01T07:00:29Z</updated><published>2020-10-01T07:00:29Z</published><content type="html">&lt;p&gt;&lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt;&amp;#8216;s web console simplifies many development and deployment chores to just a few clicks, but sometimes you need a command-line interface (CLI) to get things done on a cluster. Whether you&amp;#8217;re learning by cut-and-paste in a tutorial or troubleshooting a deep bug in production (also often done by cut-and-paste), you’ll likely need to enter at least a line or two at a command prompt.&lt;/p&gt; &lt;p&gt;Starting with version 4.5.3, OpenShift users can try out a tech preview of the new Web Terminal Operator. The new OpenShift web terminal brings indispensable command-line tools right to the web console, and its Linux environment runs in a pod deployed on your OpenShift cluster. The web terminal eliminates the need to install software and configure connections and authentication for your local terminal. It also makes it easier to use OpenShift on devices like tablets and mobile phones, which might lack a native terminal.&lt;/p&gt; &lt;p&gt;&lt;span id="more-787327"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;This article introduces the new OpenShift web terminal, including how to install and activate the Web Terminal Operator.&lt;/p&gt; &lt;h2&gt;An easier way to manage OpenShift clusters&lt;/h2&gt; &lt;p&gt;The new OpenShift web terminal includes key programs for working with clusters, including:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The &lt;code&gt;oc&lt;/code&gt; tool for comprehensive OpenShift management.&lt;/li&gt; &lt;li&gt;&lt;code&gt;odo&lt;/code&gt;, OpenShift&amp;#8217;s streamlined workflow utility for application development.&lt;/li&gt; &lt;li&gt;&lt;code&gt;kubectl&lt;/code&gt;, the core Kubernetes API client.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;CLI client tools for the &lt;a href="https://developers.redhat.com/blog/2020/08/14/introduction-to-cloud-native-ci-cd-with-tekton-kubecon-europe-2020/"&gt;Tekton CI/CD framework&lt;/a&gt;, &lt;a href="https://developers.redhat.com/blog/2020/07/20/advanced-helm-support-in-the-openshift-4-5-web-console/"&gt;Helm application deployment charts&lt;/a&gt;, and &lt;a href="https://developers.redhat.com/topics/serverless-architecture"&gt;Knative serverless workloads&lt;/a&gt; are also installed and ready to run. These OpenShift and &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; tools are supported by the usual suspects of Unix-like, general-purpose text processing, and shell scripting.&lt;/p&gt; &lt;p&gt;Once you&amp;#8217;ve installed the Web Terminal Operator, you can access the web terminal from the command-prompt icon (&lt;strong&gt;&amp;#62;_&lt;/strong&gt;) on the OpenShift web console masthead, as shown in Figure 1.&lt;/p&gt; &lt;div id="attachment_787737" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-787737" class="wp-image-787737 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/wticon.png" alt="A screenshot showing the command-prompt icon in the web console." width="640" height="148" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/wticon.png 640w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/wticon-300x69.png 300w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-787737" class="wp-caption-text"&gt;Figure 1: The command prompt icon in the OpenShift web console.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Clicking the icon displays the web terminal frame at the bottom of the OpenShift web console, as shown in Figure 2. You can resize, reposition, or pop out the terminal into a new browser window or tab.&lt;/p&gt; &lt;div id="attachment_787747" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-787747" class="wp-image-787747 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/wtrunning-1024x502.png" alt="A screenshot of the web terminal open in the web console." width="640" height="314" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/wtrunning-1024x502.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/wtrunning-300x147.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/wtrunning-768x377.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-787747" class="wp-caption-text"&gt;Figure 2: The new command-line terminal opens at the bottom of the OpenShift web console.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;How to activate the OpenShift web terminal&lt;/h2&gt; &lt;p&gt;OpenShift versions 4.5.3 and later support the new Web Terminal Operator, which manages the terminal environment on the cluster. To activate the web terminal, visit the &lt;b&gt;OperatorHub&lt;/b&gt; in the left sidebar of the &lt;b&gt;Web Console Administrator Experience&lt;/b&gt; and search for &lt;b&gt;Web Terminal&lt;/b&gt;. Install the Web Terminal Operator.&lt;/p&gt; &lt;p&gt;Once you&amp;#8217;ve deployed the Operator, log into the web console as a user without the cluster-admin role. Click the command-prompt icon in the top-right corner of your screen to start a web terminal. You’re ready to build, deploy, and manage your cluster workloads with your favorite &lt;code&gt;oc&lt;/code&gt; or &lt;code&gt;odo&lt;/code&gt; one-liners, without ever leaving your browser.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note:&lt;/strong&gt; The web terminal&amp;#8217;s tech preview imposes a couple of limitations. First, cluster admins cannot use the web terminal, it is available only to less privileged roles. Second, the shell history feature works to recall previous commands with the up and down arrow keys and other bash mechanics, but this information is not preserved between terminal sessions.&lt;/p&gt; &lt;h2&gt;We appreciate your feedback&lt;/h2&gt; &lt;p&gt;Community feedback helps us continually improve the OpenShift developer experience. We really want to hear from you! Attend one of our office hours, or &lt;a target="_blank" rel="nofollow" href="https://forms.gle/zDd4tuWvjndCRVMD8"&gt;complete this survey&lt;/a&gt; to let us know your thoughts about the OpenShift web console and the new web terminal. You can also join the &lt;a target="_blank" rel="nofollow" href="https://groups.google.com/forum/#!forum/openshift-dev-users"&gt;OpenShift Developer Experience Google Group&lt;/a&gt; to share your tips, get help with what doesn’t work so well for you, and shape the future of the OpenShift Developer Experience.&lt;/p&gt; &lt;p&gt;Ready to get started? &lt;a target="_blank" rel="nofollow" href="http://www.openshift.com/try"&gt;Try OpenShift today&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F10%2F01%2Fcommand-line-cluster-management-with-red-hat-openshifts-new-web-terminal-tech-preview%2F&amp;#38;linkname=Command-line%20cluster%20management%20with%20Red%20Hat%20OpenShift%E2%80%99s%20new%20web%20terminal%20%28tech%20preview%29" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F10%2F01%2Fcommand-line-cluster-management-with-red-hat-openshifts-new-web-terminal-tech-preview%2F&amp;#38;linkname=Command-line%20cluster%20management%20with%20Red%20Hat%20OpenShift%E2%80%99s%20new%20web%20terminal%20%28tech%20preview%29" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F10%2F01%2Fcommand-line-cluster-management-with-red-hat-openshifts-new-web-terminal-tech-preview%2F&amp;#38;linkname=Command-line%20cluster%20management%20with%20Red%20Hat%20OpenShift%E2%80%99s%20new%20web%20terminal%20%28tech%20preview%29" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F10%2F01%2Fcommand-line-cluster-management-with-red-hat-openshifts-new-web-terminal-tech-preview%2F&amp;#38;linkname=Command-line%20cluster%20management%20with%20Red%20Hat%20OpenShift%E2%80%99s%20new%20web%20terminal%20%28tech%20preview%29" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F10%2F01%2Fcommand-line-cluster-management-with-red-hat-openshifts-new-web-terminal-tech-preview%2F&amp;#38;linkname=Command-line%20cluster%20management%20with%20Red%20Hat%20OpenShift%E2%80%99s%20new%20web%20terminal%20%28tech%20preview%29" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F10%2F01%2Fcommand-line-cluster-management-with-red-hat-openshifts-new-web-terminal-tech-preview%2F&amp;#38;linkname=Command-line%20cluster%20management%20with%20Red%20Hat%20OpenShift%E2%80%99s%20new%20web%20terminal%20%28tech%20preview%29" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F10%2F01%2Fcommand-line-cluster-management-with-red-hat-openshifts-new-web-terminal-tech-preview%2F&amp;#38;linkname=Command-line%20cluster%20management%20with%20Red%20Hat%20OpenShift%E2%80%99s%20new%20web%20terminal%20%28tech%20preview%29" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F10%2F01%2Fcommand-line-cluster-management-with-red-hat-openshifts-new-web-terminal-tech-preview%2F&amp;#038;title=Command-line%20cluster%20management%20with%20Red%20Hat%20OpenShift%E2%80%99s%20new%20web%20terminal%20%28tech%20preview%29" data-a2a-url="https://developers.redhat.com/blog/2020/10/01/command-line-cluster-management-with-red-hat-openshifts-new-web-terminal-tech-preview/" data-a2a-title="Command-line cluster management with Red Hat OpenShift’s new web terminal (tech preview)"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/10/01/command-line-cluster-management-with-red-hat-openshifts-new-web-terminal-tech-preview/"&gt;Command-line cluster management with Red Hat OpenShift&amp;#8217;s new web terminal (tech preview)&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/swGMQMl_psE" height="1" width="1" alt=""/&gt;</content><summary>Red Hat OpenShift‘s web console simplifies many development and deployment chores to just a few clicks, but sometimes you need a command-line interface (CLI) to get things done on a cluster. Whether you’re learning by cut-and-paste in a tutorial or troubleshooting a deep bug in production (also often done by cut-and-paste), you’ll likely need to enter at least a line or two at a command prompt. St...</summary><dc:creator>Joshua Wood</dc:creator><dc:date>2020-10-01T07:00:29Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/10/01/command-line-cluster-management-with-red-hat-openshifts-new-web-terminal-tech-preview/</feedburner:origLink></entry><entry><title>Building modern CI/CD workflows for serverless applications with Red Hat OpenShift Pipelines and Argo CD, Part 1</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/eafqH_hG3wo/" /><category term="ArgoCD" scheme="searchisko:content:tags" /><category term="ci/cd" scheme="searchisko:content:tags" /><category term="ci/cd pipeline" scheme="searchisko:content:tags" /><category term="devops" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="gitops" scheme="searchisko:content:tags" /><category term="Knative" scheme="searchisko:content:tags" /><category term="Modern App Dev" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><category term="serverless" scheme="searchisko:content:tags" /><category term="Tekton" scheme="searchisko:content:tags" /><author><name>David Sancho</name></author><id>searchisko:content:id:jbossorg_blog-building_modern_ci_cd_workflows_for_serverless_applications_with_red_hat_openshift_pipelines_and_argo_cd_part_1</id><updated>2020-10-01T07:00:27Z</updated><published>2020-10-01T07:00:27Z</published><content type="html">&lt;p&gt;A recent article, &lt;a href="https://developers.redhat.com/blog/2020/09/03/the-present-and-future-of-ci-cd-with-gitops-on-red-hat-openshift/"&gt;&lt;em&gt;The present and future of CI/CD with GitOps on Red Hat OpenShift&lt;/em&gt;&lt;/a&gt;, proposed &lt;a href="https://developers.redhat.com/blog/2020/08/14/introduction-to-cloud-native-ci-cd-with-tekton-kubecon-europe-2020/"&gt;Tekton&lt;/a&gt; as a framework for cloud-native CI/CD pipelines, and Argo CD as its perfect partner for GitOps. &lt;a href="https://developers.redhat.com/devnation/tech-talks/gitops/watch"&gt;GitOps&lt;/a&gt; practices support continuous delivery in hybrid, multi-cluster &lt;a href="https://developers.redhat.com/topics/kubernetes"&gt;Kubernetes&lt;/a&gt; environments.&lt;/p&gt; &lt;p&gt;In this two-part article, we&amp;#8217;ll build a CI/CD workflow that demonstrates the potential of combining Tekton and GitOps. You&amp;#8217;ll also be introduced to &lt;a href="https://developers.redhat.com/topics/serverless-architecture"&gt;Red Hat OpenShift Serverless&lt;/a&gt;, as we&amp;#8217;ll use &lt;a target="_blank" rel="nofollow" href="https://knative.dev/"&gt;Knative&lt;/a&gt; service resources in our CI/CD workflow. Let&amp;#8217;s start with an overview of the CI/CD workflow that we&amp;#8217;ll implement for the demonstration.&lt;/p&gt; &lt;h2&gt;The CI/CD workflow&lt;/h2&gt; &lt;p&gt;The diagram in Figure 1 illustrates the CI/CD workflow. A commit initiated in the application&amp;#8217;s source code repository triggers a full CI/CD process, which ends with a new version of the serverless application deployed in development, staging, and production environments as laid out in Figure 1.&lt;/p&gt; &lt;div id="attachment_780177" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/cicd-knative.png"&gt;&lt;img aria-describedby="caption-attachment-780177" class="wp-image-780177" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/cicd-knative.png" alt="A diagram of the sample CI/CI workflow." width="640" height="520" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/cicd-knative.png 829w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/cicd-knative-300x244.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/cicd-knative-768x623.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-780177" class="wp-caption-text"&gt;Figure 1: The sample CI/CD workflow for the demonstration.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Let&amp;#8217;s look more closely at each step in the workflow:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;A developer pushes a new change in the application&amp;#8217;s source code repository.&lt;/li&gt; &lt;li&gt;A webhook configured in the source code repository (GitHub, in this case) triggers the &lt;a target="_blank" rel="nofollow" href="https://github.com/tektoncd/pipeline"&gt;Tekton pipeline&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Once the pipeline has started, the first task fetches the source code from the repository.&lt;/li&gt; &lt;li&gt;A Maven task packages the application code as a JAR file and runs unit tests before building the container image.&lt;/li&gt; &lt;li&gt;A &lt;a target="_blank" rel="nofollow" href="https://buildah.io/"&gt;buildah&lt;/a&gt; task builds and pushes the container image to the registry. The image is then pushed to the OpenShift internal registry.&lt;/li&gt; &lt;li&gt;The pipeline fetches the repository that keeps the desired state of the example application&amp;#8217;s configuration and deployment descriptors. In GitOps methodology, we use a Git repository as the single source of truth for what is deployed and where it&amp;#8217;s deployed.&lt;/li&gt; &lt;li&gt;Initially, the Git repository might be empty, so this task is smart enough to initialize the repository with all of the Kubernetes manifests (in this case, the &lt;a target="_blank" rel="nofollow" href="https://knative.dev/"&gt;Knative&lt;/a&gt; service and &lt;code&gt;ConfigMaps&lt;/code&gt;) that are required to run the application for the first time. The subsequent repository commits will only update the existing descriptors with the new application version, an independent route for canary testing, and related configurations. Once all the manifest files have been created or modified, this task pushes the changes to the repository. This step is the glue between the continuous integration performed by the &lt;a target="_blank" rel="nofollow" href="https://github.com/tektoncd/pipeline"&gt;Tekton pipeline&lt;/a&gt; and the continuous deployment managed by &lt;a target="_blank" rel="nofollow" href="https://argoproj.github.io/argo-cd/"&gt;Argo CD&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Argo CD pulls from the configuration repository and synchronizes the existing Kubernetes manifests, which are specified using &lt;a target="_blank" rel="nofollow" href="https://kustomize.io/"&gt;Kustomize&lt;/a&gt; files. This action creates the final Kubernetes objects in the &lt;code&gt;development&lt;/code&gt;, &lt;code&gt;staging&lt;/code&gt;, and &lt;code&gt;production&lt;/code&gt; namespaces. The synchronization could be auto or manual based on the target namespace&amp;#8217;s requirements.&lt;/li&gt; &lt;li&gt;In this final part of the workflow, it might be necessary to pull images referenced in the deployment Kubernetes manifest from the OpenShift internal registry. The operations team might also push configuration changes, for instance, changing the URL of a target microservice or certain information that is unknown by the development team. This last step could also create an &lt;code&gt;OutOfSync&lt;/code&gt; state in &lt;a target="_blank" rel="nofollow" href="https://argoproj.github.io/argo-cd/"&gt;Argo CD&lt;/a&gt;, which would lead to a new synchronization process (see Step 9 in Figure 1).&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Next, we&amp;#8217;ll set up our cluster with the OpenShift Operators and services that we&amp;#8217;ll need.&lt;/p&gt; &lt;h2&gt;Configuring the OpenShift cluster&lt;/h2&gt; &lt;p&gt;We&amp;#8217;ll use a set of scripts to configure and install all of the components required for this demonstration. To get started with setting up the demonstration environment, clone the following source code repository:&lt;/p&gt; &lt;pre&gt;$ git clone https://github.com/dsanchor/rh-developers-cicd.git &lt;/pre&gt; &lt;p&gt;Next, ensure that you have all of the following tools installed in your system. You&amp;#8217;ll need these pre-installed when you run the scripts:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://helm.sh/docs/intro/install/"&gt;Helm&lt;/a&gt;: &lt;code&gt;helm &lt;em&gt;version&lt;/em&gt;&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://git-scm.com/book/en/v2/Getting-Started-Installing-Git"&gt;Git&lt;/a&gt;: &lt;code&gt;git &lt;em&gt;version&lt;/em&gt;&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/4.5/cli_reference/openshift_cli/getting-started-cli.html"&gt;oc&lt;/a&gt;: &lt;code&gt;oc &lt;em&gt;version&lt;/em&gt;&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://kubernetes-sigs.github.io/kustomize/installation/"&gt;kustomize&lt;/a&gt; v 3.1.0 or higher: &lt;code&gt;customize &lt;em&gt;version&lt;/em&gt;&lt;/code&gt;&lt;/li&gt; &lt;li&gt;envsubst (gettext): &lt;code&gt;envsubst --help&lt;/code&gt;&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/tektoncd/cli"&gt;tkn&lt;/a&gt; (optional Tekton CLI): &lt;code&gt;tkn &lt;em&gt;version&lt;/em&gt;&lt;/code&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Once you&amp;#8217;ve checked the above requirements, log in to your OpenShift cluster as a cluster-admin user:&lt;/p&gt; &lt;pre&gt;$ oc login -u &lt;em&gt;USERNAME&lt;/em&gt; -p &lt;em&gt;PASSWORD&lt;/em&gt; https://api.&lt;em&gt;YOUR_CLUSTER_DOMAIN&lt;/em&gt;:6443 &lt;/pre&gt; &lt;h3&gt;Operators, namespaces, and role bindings&lt;/h3&gt; &lt;p&gt;Initially, we will install the &lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/4.5/pipelines/installing-pipelines.html"&gt;OpenShift Pipelines&lt;/a&gt; and &lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/4.5/serverless/installing_serverless/installing-openshift-serverless.html"&gt;OpenShift Serverless&lt;/a&gt; Operators in the &lt;code&gt;openshift-operators&lt;/code&gt; namespace.&lt;/p&gt; &lt;p&gt;We&amp;#8217;ll also create four new namespaces: &lt;code&gt;cicd&lt;/code&gt;, &lt;code&gt;development&lt;/code&gt;, &lt;code&gt;staging&lt;/code&gt;, and &lt;code&gt;production&lt;/code&gt;. Images are pushed within the boundaries of the &lt;code&gt;cicd&lt;/code&gt; namespace, so all of the other namespaces require &lt;code&gt;system:image-puller&lt;/code&gt; privileges in order to pull the new images.&lt;/p&gt; &lt;p&gt;Finally, we&amp;#8217;ll add a new &lt;code&gt;view&lt;/code&gt; role to the &lt;code&gt;development&lt;/code&gt;, &lt;code&gt;staging&lt;/code&gt;, and &lt;code&gt;production&lt;/code&gt; default service accounts. This role provides access from our &lt;a href="https://developers.redhat.com/products/quarkus/getting-started"&gt;Quarkus&lt;/a&gt; application pods to &lt;code&gt;ConfigMaps&lt;/code&gt; and &lt;code&gt;Secrets&lt;/code&gt;. (I&amp;#8217;ll introduce the Quarkus application later.)&lt;/p&gt; &lt;p&gt;Here is the script, which basically uses three Helm charts for the required installations:&lt;/p&gt; &lt;pre&gt;$ ./bootstrap.sh --------------- Installing openshift-pipelines operator Release "openshift-pipelines" does not exist. Installing it now. NAME: openshift-pipelines LAST DEPLOYED: Thu Sep 10 10:55:14 2020 NAMESPACE: default STATUS: deployed REVISION: 1 TEST SUITE: None Installing openshift-serverless Release "openshift-serverless" does not exist. Installing it now. NAME: openshift-serverless LAST DEPLOYED: Thu Sep 10 10:55:16 2020 NAMESPACE: default STATUS: deployed REVISION: 1 TEST SUITE: None Creating cicd, development, staging and production namespaces Added cicd system:image-puller role to default sa in development, staging and production namespaces Added view role to default sa in development, staging and production namespaces Release "bootstrap-projects" does not exist. Installing it now. NAME: bootstrap-projects LAST DEPLOYED: Thu Sep 10 10:55:18 2020 NAMESPACE: default STATUS: deployed REVISION: 1 TEST SUITE: None &lt;/pre&gt; &lt;p&gt;You can execute the script as-is, or use the Helm charts independently, overriding any values that you wish. For instance, you could override the value of the channel subscription for each OpenShift Operator.&lt;/p&gt; &lt;p&gt;Figure 2 shows the installation so far, with both Operators installed under the &lt;code&gt;openshift-operators&lt;/code&gt; namespace.&lt;/p&gt; &lt;div id="attachment_780277" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/installed-openshift-operators.png"&gt;&lt;img aria-describedby="caption-attachment-780277" class="wp-image-780277 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/installed-openshift-operators-1024x253.png" alt="A screenshot of the OpenShift Serverless and OpenShift Pipelines Operators listed in the openshift-operators namespace." width="640" height="158" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/installed-openshift-operators-1024x253.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/installed-openshift-operators-300x74.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/installed-openshift-operators-768x190.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-780277" class="wp-caption-text"&gt;Figure 2: The OpenShift Serverless and OpenShift Pipelines Operators installed under openshift-operators.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Verify that the OpenShift Pipelines Operator is installed at version 1.1.1 or greater.&lt;/p&gt; &lt;p&gt;Next, we&amp;#8217;ll complete the OpenShift Serverless components installation by installing the &lt;a target="_blank" rel="nofollow" href="https://knative.dev/docs/serving/"&gt;Knative Serving&lt;/a&gt; control plane.&lt;/p&gt; &lt;h3&gt;Install a Knative Serving instance&lt;/h3&gt; &lt;p&gt;We need to create a &lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/4.5/serverless/installing_serverless/installing-knative-serving.html#installing-knative-serving"&gt;Knative Serving&lt;/a&gt; instance that will provide a set of serverless capabilities to our applications. Run the following to create the Knative Serving instance and install the control plane:&lt;/p&gt; &lt;pre&gt;$ ./add-knative-serving.sh ------------------------------ Creating knative-serving namespace namespace/knative-serving created Installing basic knative serving control plane knativeserving.operator.knative.dev/knative-serving created &lt;/pre&gt; &lt;p&gt;We&amp;#8217;ve deployed a set of pods representing a basic Knative Serving control plane in the &lt;code&gt;knative-serving&lt;/code&gt; namespace, as shown in Figure 3.&lt;/p&gt; &lt;div id="attachment_778117" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/knative-serving-ns-1.png"&gt;&lt;img aria-describedby="caption-attachment-778117" class="wp-image-778117 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/knative-serving-ns-1-1024x498.png" alt="A screenshot of the Knative serving control plane." width="640" height="311" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/knative-serving-ns-1-1024x498.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/knative-serving-ns-1-300x146.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/knative-serving-ns-1-768x374.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-778117" class="wp-caption-text"&gt;Figure 3: The Knative Serving control plane in the knative-serving namespace.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;As shown in Figure 4, we&amp;#8217;ve also created a new namespace, &lt;code&gt;knative-serving-ingress&lt;/code&gt;, for the Knative installation&amp;#8217;s ingress gateways.&lt;/p&gt; &lt;div id="attachment_778087" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/knative-serving-ingress.png"&gt;&lt;img aria-describedby="caption-attachment-778087" class="wp-image-778087 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/knative-serving-ingress-1024x332.png" alt="A screenshot of the knative-serving-ingress namespace in the OpenShift console." width="640" height="208" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/knative-serving-ingress-1024x332.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/knative-serving-ingress-300x97.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/knative-serving-ingress-768x249.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-778087" class="wp-caption-text"&gt;Figure 4: The new knative-serving-ingress namespace.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;We&amp;#8217;ve installed the OpenShift Operators and created the namespaces and the Knative Serving instance to manage our serverless workloads. We&amp;#8217;re now ready to create the &lt;a target="_blank" rel="nofollow" href="https://github.com/tektoncd/pipeline"&gt;Tekton&lt;/a&gt; resources that we&amp;#8217;ll need to run the continuous integration pipeline.&lt;/p&gt; &lt;h2&gt;Configure the Tekton tasks and pipeline&lt;/h2&gt; &lt;p&gt;When you install the OpenShift Pipelines Operator, it comes with an out-of-the-box set of cluster tasks that you can use to build your pipeline. In some situations, you will need other tasks to execute specific functionality. You can easily create these tasks in Tekton. You can also search the &lt;a target="_blank" rel="nofollow" href="https://hub-preview.tekton.dev/"&gt;Tekton Hub&lt;/a&gt; for reusable tasks and pipelines that are ready to be consumed.&lt;/p&gt; &lt;p&gt;For our pipeline, we will use one task from the Tekton Hub and two custom tasks. To make these tasks available to our pipeline, we&amp;#8217;ll need to create them in the &lt;code&gt;cicd&lt;/code&gt; namespace. (Note that you can create &lt;code&gt;ClusterTask&lt;/code&gt;s if you think that you&amp;#8217;ll reuse them in different pipelines from different namespaces.) Run the following script to install the needed tasks and create the pipeline in the same namespace.&lt;/p&gt; &lt;pre&gt;$ ./add-tekton-customs.sh cicd ------------------------------ Installing buildah task from https://hub-preview.tekton.dev/ task.tekton.dev/buildah created Installing custom tasks task.tekton.dev/push-knative-manifest created task.tekton.dev/workspace-cleaner created Installing knative-pipeline pipeline.tekton.dev/knative-pipeline created &lt;/pre&gt; &lt;p&gt;Navigate to the OpenShift console and open the &lt;b&gt;Pipelines&lt;/b&gt; menu and project &lt;b&gt;cicd&lt;/b&gt;. You will discover your new tasks, as shown in Figure 5.&lt;/p&gt; &lt;div id="attachment_780317" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/tasks.png"&gt;&lt;img aria-describedby="caption-attachment-780317" class="wp-image-780317 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/tasks-1024x429.png" alt="A screenshot of the Tekton tasks in the CICD namespace." width="640" height="268" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/tasks-1024x429.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/tasks-300x126.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/tasks-768x322.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-780317" class="wp-caption-text"&gt;Figure 5: New Tekton tasks in the cicd namespace.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Figure 6 shows your new pipeline in the same namespace.&lt;/p&gt; &lt;div id="attachment_780287" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/pipeline.png"&gt;&lt;img aria-describedby="caption-attachment-780287" class="wp-image-780287 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/pipeline-1024x430.png" alt="A screenshot of the Tekton pipeline in the CICD namespace." width="640" height="269" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/pipeline-1024x430.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/pipeline-300x126.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/pipeline-768x323.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-780287" class="wp-caption-text"&gt;Figure 6: The Tekton pipeline in the cicd namespace.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Tekton workspaces&lt;/h3&gt; &lt;p&gt;Some of our tasks in the pipeline require either loading certain configurations from &lt;code&gt;ConfigMap&lt;/code&gt;s or storing the state of the resulting execution to be shared with other tasks. For instance, the Maven task requires that we include a specific &lt;code&gt;settings.xml&lt;/code&gt; in a &lt;code&gt;ConfigMap&lt;/code&gt;. On the other hand, the first task fetches the application&amp;#8217;s source code repository. The Maven task, which follows, will need those files to build the application JAR. We&amp;#8217;re using an OpenShift &lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/4.5/storage/understanding-persistent-storage.html#persistent-volumes_understanding-persistent-storage"&gt;PersistentVolume&lt;/a&gt; to share these source files.&lt;/p&gt; &lt;p&gt;Tekton provides the concept of &lt;a target="_blank" rel="nofollow" href="https://github.com/tektoncd/pipeline/blob/master/docs/workspaces.md#workspaces"&gt;workspaces&lt;/a&gt; for these purposes. Run the following script to add a set of &lt;code&gt;ConfigMap&lt;/code&gt;s and a &lt;code&gt;PersistentVolumeClaim&lt;/code&gt; to the &lt;code&gt;cicd&lt;/code&gt; namespace:&lt;/p&gt; &lt;pre&gt;$ ./add-tekton-workspaces.sh cicd ----------------------------------- Creating knative-kustomize-base ConfigMap with base kustomize files for Knative services configmap/knative-kustomize-base created Creating knative-kustomize-environment ConfigMap with environment dependent kustomize files configmap/knative-kustomize-environment created Creating maven ConfigMap with settings.xml configmap/maven created Creating PVC using default storage class persistentvolumeclaim/source-pvc created &lt;/pre&gt; &lt;p&gt;Notice that this script creates a &lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/4.5/storage/understanding-persistent-storage.html#pvc-storage-class_understanding-persistent-storage"&gt;PersistentVolumeClaim&lt;/a&gt; with no &lt;a target="_blank" rel="nofollow" href="https://docs.openshift.com/container-platform/4.5/storage/understanding-persistent-storage.html#pvc-storage-class_understanding-persistent-storage"&gt;StorageClass&lt;/a&gt; defined. Unless you choose to specify one, the default &lt;code&gt;StorageClass&lt;/code&gt; will be used. Feel free to uncomment any lines in the provided script to fit your needs.&lt;/p&gt; &lt;h2&gt;The demo application&lt;/h2&gt; &lt;p&gt;Until now, I&amp;#8217;ve said almost nothing about the demo application. The application is based on &lt;a target="_blank" rel="nofollow" href="https://quarkus.io/get-started/"&gt;Quarkus&lt;/a&gt;, which is a perfect match for serverless applications due to its fast boot time and low memory consumption. The application itself is a simple &amp;#8220;Hello, world&amp;#8221; REST API that greets users when the &lt;code&gt;/hello&lt;/code&gt; URI is hit.&lt;/p&gt; &lt;p&gt;The application uses the &lt;a target="_blank" rel="nofollow" href="https://quarkus.io/guides/kubernetes-config"&gt;kubernetes-config&lt;/a&gt; extension to facilitate the consumption of &lt;code&gt;ConfigMap&lt;/code&gt;s and &lt;code&gt;Secrets&lt;/code&gt; in Kubernetes. The &amp;#8220;Hello, world&amp;#8221; application reads a list of &lt;code&gt;ConfigMap&lt;/code&gt;s, which gives us the chance to manage configuration at different levels, overriding duplicated properties.&lt;/p&gt; &lt;p&gt;Figure 7 shows an extract of the &lt;a target="_blank" rel="nofollow" href="https://github.com/dsanchor/quarkus-hello-world/blob/c076ee940b1f1d9576b7af3250bbbd7114e82263/src/main/resources/application.yaml#L18"&gt;application.yaml&lt;/a&gt; that defines the list of &lt;code&gt;ConfigMap&lt;/code&gt;s.&lt;/p&gt; &lt;div id="attachment_782297" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/configmap-list-vsc.png"&gt;&lt;img aria-describedby="caption-attachment-782297" class="wp-image-782297" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/configmap-list-vsc.png" alt="A screenshot of the YAML file in the console." width="640" height="211" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/configmap-list-vsc.png 923w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/configmap-list-vsc-300x99.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/configmap-list-vsc-768x254.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-782297" class="wp-caption-text"&gt;Figure 7: Application YAML with the list of ConfigMaps.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;You can find the complete application source code in the &lt;a target="_blank" rel="nofollow" href="https://github.com/dsanchor/quarkus-hello-world.git"&gt;GitHub repository for this article&lt;/a&gt;. Note that the pipeline also initializes and continuously updates a different repository that contains, in a declarative way, all of the Kubernetes manifest for our application deployments and configurations. Later in the article, we&amp;#8217;ll use &lt;a target="_blank" rel="nofollow" href="https://kustomize.io/"&gt;Kustomize&lt;/a&gt; to declaratively customize the application configuration and deployment.&lt;/p&gt; &lt;h2&gt;Create your own repository&lt;/h2&gt; &lt;p&gt;At this stage, you must &lt;a target="_blank" rel="nofollow" href="https://docs.github.com/en/github/getting-started-with-github/create-a-repo"&gt;create a GitHub repository&lt;/a&gt; that you will use to store the customization files required for the demonstration. My repository is named &lt;code&gt;quarkus-hello-world-deployment&lt;/code&gt;, and I&amp;#8217;ll use that name to reference the repository in the upcoming scripts. You can use the same name or a different one for your repository.&lt;/p&gt; &lt;p&gt;After you have created and named the repository, leave it empty and initialized.&lt;/p&gt; &lt;p&gt;In order to allow the Tekton pipeline to push changes into the new repository, you will have to provide a valid set of GitHub credentials. You&amp;#8217;ll store the credentials in a &lt;code&gt;Secret&lt;/code&gt; and link them to the &lt;code&gt;ServiceAccount&lt;/code&gt; pipeline, which was automatically created in the &lt;code&gt;cicd&lt;/code&gt; namespace.&lt;/p&gt; &lt;p&gt;Execute the following script:&lt;/p&gt; &lt;pre&gt;$ ./add-github-credentials.sh cicd &lt;strong&gt;YOUR_GITHUB_USER YOUR_GITHUB_PASSWORD&lt;/strong&gt; --------------------------------------------------------------------------- Creating secret with github credentials for user dsanchor secret/github-credentials created Linking pipeline sa in namespace cicd with your github credentials serviceaccount/pipeline patched &lt;/pre&gt; &lt;h2&gt;A manual pipeline run&lt;/h2&gt; &lt;p&gt;We are now ready to manually test the pipeline&amp;#8217;s execution and see the results. The pipeline workflow includes a webhook setup that triggers the pipeline automatically. We&amp;#8217;ll leave that part for the end of this article (in Part 2); for now, we&amp;#8217;ll just test the workflow by triggering the pipeline manually.&lt;/p&gt; &lt;p&gt;I&amp;#8217;ve provided two options to trigger the pipeline manually:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Create a pipeline run from a YAML file.&lt;/li&gt; &lt;li&gt;Start the pipeline using the &lt;a target="_blank" rel="nofollow" href="https://github.com/tektoncd/cli"&gt;Tekton CLI: tkn&lt;/a&gt;.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;In both cases, we&amp;#8217;ll use a given &lt;code&gt;commit&lt;/code&gt; from the application repository. Also, we need to provide the repository that keeps all of our config and deployment manifests. In the script below, &lt;a target="_blank" rel="nofollow" href="https://github.com/dsanchor/quarkus-hello-world-deployment.git"&gt;I reference my deployment repository&lt;/a&gt;—you should replace that reference with the name of your repository. When you are ready, execute the following:&lt;/p&gt; &lt;pre&gt;$ cat tekton/pipelines/knative-pipeline-run.yaml | \   SOURCE_REPO=https://github.com/dsanchor/quarkus-hello-world.git \ COMMIT=9ce90240f96a9906b59225fec16d830ab4f3fe12 \ SHORT_COMMIT=9ce9024 \ DEPLOYMENT_REPO=https://github.com/dsanchor/quarkus-hello-world-deployment.git \   IMAGES_NS=cicd envsubst | \ oc create -f - -n cicd ------------------------------------------------------------------------------------------ pipelinerun.tekton.dev/knative-pipeline-run-54kpq created &lt;/pre&gt; &lt;p&gt;If you prefer to, you can start the pipeline using the &lt;em&gt;tkn&lt;/em&gt; CLI:&lt;/p&gt; &lt;pre&gt;$ tkn pipeline start knative-pipeline -p application=quarkus-hello-world \ -p source-repo-url=https://github.com/dsanchor/quarkus-hello-world.git \ -p source-revision=9ce90240f96a9906b59225fec16d830ab4f3fe12 \ -p short-source-revision=9ce9024 \ -p deployment-repo-url=https://github.com/dsanchor/quarkus-hello-world-deployment.git \ -p deployment-revision=master \ -p dockerfile=./src/main/docker/Dockerfile.jvm \ -p image-registry=image-registry.openshift-image-registry.svc.cluster.local:5000 \ -p image-repository=cicd \ -w name=source,claimName=source-pvc \ -w name=maven-settings,config=maven \ -w name=knative-kustomize-base,config=knative-kustomize-base \ -w name=knative-kustomize-environment,config=knative-kustomize-environment \ -n cicd &lt;/pre&gt; &lt;p&gt;Another option is to trigger the pipeline from the OpenShift console.&lt;/p&gt; &lt;h3&gt;Monitor the pipeline&amp;#8217;s execution&lt;/h3&gt; &lt;p&gt;To check the execution progress, visit the &lt;b&gt;Pipeline Runs&lt;/b&gt; dashboard in the OpenShift console, as shown in Figure 8.&lt;/p&gt; &lt;div id="attachment_780397" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/prun.png"&gt;&lt;img aria-describedby="caption-attachment-780397" class="wp-image-780397 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/prun-1024x187.png" alt="A screenshot of the Pipeline Runs dashboard." width="640" height="117" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/prun-1024x187.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/prun-300x55.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/prun-768x140.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-780397" class="wp-caption-text"&gt;Figure 8: Use the Pipeline Runs dashboard to check the execution progress.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;If you want to see all the details of each pipeline task, click in the name of the pipeline run. You will get the logs for each task, as shown in Figure 9:&lt;/p&gt; &lt;div id="attachment_780417" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/prun-detail.png"&gt;&lt;img aria-describedby="caption-attachment-780417" class="wp-image-780417 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/prun-detail-1024x584.png" alt="A screenshot of the pipeline task logs." width="640" height="365" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/prun-detail-1024x584.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/prun-detail-300x171.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/prun-detail-768x438.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-780417" class="wp-caption-text"&gt;Figure 9: View the logs for each pipeline task.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;If you trigger the pipeline with exactly the same parameters twice (for instance, using both examples that I have provided) you will see that the second run fails when pushing the &lt;i&gt;Kustomization&lt;/i&gt; manifests. The failure happens because there is nothing new to commit—awesome!&lt;/p&gt; &lt;h3&gt;Outcomes of the pipeline execution&lt;/h3&gt; &lt;p&gt;The diagram in Figure 10 shows what we&amp;#8217;ve achieved so far:&lt;/p&gt; &lt;div id="attachment_790057" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ci-manual-knative-2.png"&gt;&lt;img aria-describedby="caption-attachment-790057" class="wp-image-790057" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ci-manual-knative-2.png" alt="A diagram of the continuous integration workflow so far." width="640" height="390" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/ci-manual-knative-2.png 836w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ci-manual-knative-2-300x183.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/ci-manual-knative-2-768x469.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-790057" class="wp-caption-text"&gt;Figure 10: The CI/CD workflow in progress.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Note that we replaced the steps related to &amp;#8220;Push code&amp;#8221; and &amp;#8220;repository webhook&amp;#8221; with a manual pipeline trigger based on a given commit ID.&lt;/p&gt; &lt;p&gt;At this point, we&amp;#8217;ve pushed a new image to the OpenShift internal registry. We&amp;#8217;ve also initialized the repository that will contain all of the config and deployment manifests, along with all of the Kubernetes manifests that are required to run the first version of our serverless application.&lt;/p&gt; &lt;h2&gt;Reviewing the deployment repository structure&lt;/h2&gt; &lt;p&gt;Now is a good time to review the structure of the deployment repository and what will eventually be the final manifests that we&amp;#8217;ll generate with &lt;a target="_blank" rel="nofollow" href="https://kustomize.io/"&gt;Kustomize&lt;/a&gt;. If you are not familiar with Kustomize and its capabilities, feel free to learn more about it. Understanding Kustomize could help you to better understand the structure of the repository.&lt;/p&gt; &lt;p&gt;Update your deployment repository (&lt;code&gt;git pull&lt;/code&gt;) and you should see similar output to this:&lt;/p&gt; &lt;pre&gt;├── &lt;strong&gt;base&lt;/strong&gt; │   ├── global-ops-configmap.yaml │   ├── kservice.yaml │   └── kustomization.yaml ├── &lt;strong&gt;development&lt;/strong&gt; │   ├── env-ops-configmap.yaml │   ├── kustomization.yaml │   ├── r9ce9024 │   │   ├── configmap.yaml │   │   ├── revision-patch.yaml │   │   └── routing-patch.yaml │   └── traffic-routing.yaml ├── &lt;strong&gt;production&lt;/strong&gt; │   ├── env-ops-configmap.yaml │   ├── kustomization-r9ce9024.yaml │   ├── r9ce9024 │   │   ├── configmap.yaml │   │   ├── revision-patch.yaml │   │   └── routing-patch.yaml │   └── traffic-routing.yaml ├── README.md └── &lt;strong&gt;staging&lt;/strong&gt; ├── env-ops-configmap.yaml ├── kustomization-r9ce9024.yaml ├── r9ce9024 │   ├── configmap.yaml │   ├── revision-patch.yaml │   └── routing-patch.yaml └── traffic-routing.yaml &lt;/pre&gt; &lt;p&gt;For simplicity, I will only focus on the &lt;code&gt;base&lt;/code&gt; and &lt;code&gt;development&lt;/code&gt; folders for now:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The &lt;code&gt;base&lt;/code&gt; folder has all of the shared resources between the three environments. It holds the basic structure of a &lt;a target="_blank" rel="nofollow" href="https://knative.dev/docs/serving/spec/knative-api-specification-1.0/#service"&gt;Knative service&lt;/a&gt; and a global config map.&lt;/li&gt; &lt;li&gt;The &lt;code&gt;development&lt;/code&gt; folder contains the overlays to complete the &lt;a target="_blank" rel="nofollow" href="https://knative.dev/docs/serving/spec/knative-api-specification-1.0/#service"&gt;Knative service&lt;/a&gt; manifest generation for a given application version (an example is the &lt;code&gt;r9ce9024&lt;/code&gt; folder) and two config maps that are related to the environment and developer configuration levels or ownership. The one under the revision folder has been copied from the application source code, letting the developer provide a set of configuration properties for the application.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;We are taking advantage of the simplicity of Knative services to define independent &lt;a target="_blank" rel="nofollow" href="https://knative.dev/docs/serving/spec/knative-api-specification-1.0/#route"&gt;routes&lt;/a&gt; for each &lt;a target="_blank" rel="nofollow" href="https://knative.dev/docs/serving/spec/knative-api-specification-1.0/#revision"&gt;service revision&lt;/a&gt; and to &lt;a target="_blank" rel="nofollow" href="https://knative.dev/docs/serving/samples/traffic-splitting/"&gt;split traffic between revisions&lt;/a&gt;. Thus, the &lt;code&gt;traffic-routing.yaml&lt;/code&gt; and the &lt;code&gt;routing-patch.yaml&lt;/code&gt; form the final traffic-routing section of a Knative service.&lt;/p&gt; &lt;p&gt;Each time a new revision is available in &lt;code&gt;development&lt;/code&gt;, an independent route is created for it, to ensure that it is accessible for testing. The main route remains the same (for instance, targeting the other two previous revisions). We achieve this behavior by not modifying the main &lt;code&gt;traffic-routing.yaml&lt;/code&gt; automatically from the pipeline but only adding the new route (&lt;code&gt;routing-patch.yaml&lt;/code&gt;) for the new revision.&lt;/p&gt; &lt;p&gt;These details will be easier to understand when we run additional tests in Part 2. For now, just note a significant difference between the &lt;code&gt;staging&lt;/code&gt; and &lt;code&gt;production&lt;/code&gt; namespaces and &lt;code&gt;development&lt;/code&gt;: The CI pipeline does not create a &lt;code&gt;kustomization.yaml&lt;/code&gt; file (with that exact name) for them. There will always be one with an additional revision prefix: &lt;code&gt;kustomization-r9ce9024.yaml&lt;/code&gt;. Those changes will not be considered during the synchronization process unless this new revision is referenced in the &lt;code&gt;kustomization.yaml&lt;/code&gt;. A manual action is required to make the changes visible to Kustomize.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;&lt;strong&gt;Note&lt;/strong&gt;: The point of the file-name difference is to differentiate the demonstration: I wanted those two environments to behave differently so that they would require someone to approve the changes. Renaming the file is a simple approach to approval that does not overcomplicate the demonstration. I would prefer to create a different branch for every new revision, then generate a pull request once it&amp;#8217;s ready to be promoted.&lt;/p&gt; &lt;h2&gt;Kustomize: Put all the pieces together&lt;/h2&gt; &lt;p&gt;We&amp;#8217;ve reviewed the content and structure of the deployment repository, but we still don&amp;#8217;t have the final composition of the Knative service and &lt;code&gt;ConfigMap&lt;/code&gt;s. The following script uses &lt;code&gt;kustomize&lt;/code&gt; to build the final manifests so that we can see how they look:&lt;/p&gt; &lt;pre&gt;$ kustomize build development ------------------------------ apiVersion: v1 kind: ConfigMap metadata: name: env-ops-quarkus-hello-world --- apiVersion: v1 kind: ConfigMap metadata: name: global-ops-quarkus-hello-world --- apiVersion: v1 data: application.yaml: |- message: hola environment: name: dev kind: ConfigMap metadata: name: quarkus-hello-world --- apiVersion: serving.knative.dev/v1 kind: Service metadata: name: quarkus-hello-world spec: template: metadata: name: quarkus-hello-world-r9ce9024 spec: containers: - image: image-registry.openshift-image-registry.svc.cluster.local:5000/cicd/quarkus-hello-world:9ce90240f96a9906b59225fec16d830ab4f3fe12 livenessProbe: httpGet: path: /health/live readinessProbe: httpGet: path: /health/ready traffic: - percent: 100 revisionName: quarkus-hello-world-r9ce9024 - revisionName: quarkus-hello-world-r9ce9024 tag: r9ce9024 &lt;/pre&gt; &lt;h2&gt;Conclusion for Part 1&lt;/h2&gt; &lt;p&gt;At this point, we could apply our set of objects into the &lt;code&gt;development&lt;/code&gt; namespace to get a serverless application running, but we don&amp;#8217;t want to do the deployment step manually. In the second half of this article, I will show you how to integrate &lt;a target="_blank" rel="nofollow" href="https://argoproj.github.io/argo-cd/"&gt;Argo CD&lt;/a&gt; into the CI/CD pipeline that we&amp;#8217;ve developed so far.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F10%2F01%2Fbuilding-modern-ci-cd-workflows-for-serverless-applications-with-red-hat-openshift-pipelines-and-argo-cd-part-1%2F&amp;#38;linkname=Building%20modern%20CI%2FCD%20workflows%20for%20serverless%20applications%20with%20Red%20Hat%20OpenShift%20Pipelines%20and%20Argo%20CD%2C%20Part%201" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F10%2F01%2Fbuilding-modern-ci-cd-workflows-for-serverless-applications-with-red-hat-openshift-pipelines-and-argo-cd-part-1%2F&amp;#38;linkname=Building%20modern%20CI%2FCD%20workflows%20for%20serverless%20applications%20with%20Red%20Hat%20OpenShift%20Pipelines%20and%20Argo%20CD%2C%20Part%201" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F10%2F01%2Fbuilding-modern-ci-cd-workflows-for-serverless-applications-with-red-hat-openshift-pipelines-and-argo-cd-part-1%2F&amp;#38;linkname=Building%20modern%20CI%2FCD%20workflows%20for%20serverless%20applications%20with%20Red%20Hat%20OpenShift%20Pipelines%20and%20Argo%20CD%2C%20Part%201" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F10%2F01%2Fbuilding-modern-ci-cd-workflows-for-serverless-applications-with-red-hat-openshift-pipelines-and-argo-cd-part-1%2F&amp;#38;linkname=Building%20modern%20CI%2FCD%20workflows%20for%20serverless%20applications%20with%20Red%20Hat%20OpenShift%20Pipelines%20and%20Argo%20CD%2C%20Part%201" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F10%2F01%2Fbuilding-modern-ci-cd-workflows-for-serverless-applications-with-red-hat-openshift-pipelines-and-argo-cd-part-1%2F&amp;#38;linkname=Building%20modern%20CI%2FCD%20workflows%20for%20serverless%20applications%20with%20Red%20Hat%20OpenShift%20Pipelines%20and%20Argo%20CD%2C%20Part%201" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F10%2F01%2Fbuilding-modern-ci-cd-workflows-for-serverless-applications-with-red-hat-openshift-pipelines-and-argo-cd-part-1%2F&amp;#38;linkname=Building%20modern%20CI%2FCD%20workflows%20for%20serverless%20applications%20with%20Red%20Hat%20OpenShift%20Pipelines%20and%20Argo%20CD%2C%20Part%201" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F10%2F01%2Fbuilding-modern-ci-cd-workflows-for-serverless-applications-with-red-hat-openshift-pipelines-and-argo-cd-part-1%2F&amp;#38;linkname=Building%20modern%20CI%2FCD%20workflows%20for%20serverless%20applications%20with%20Red%20Hat%20OpenShift%20Pipelines%20and%20Argo%20CD%2C%20Part%201" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F10%2F01%2Fbuilding-modern-ci-cd-workflows-for-serverless-applications-with-red-hat-openshift-pipelines-and-argo-cd-part-1%2F&amp;#038;title=Building%20modern%20CI%2FCD%20workflows%20for%20serverless%20applications%20with%20Red%20Hat%20OpenShift%20Pipelines%20and%20Argo%20CD%2C%20Part%201" data-a2a-url="https://developers.redhat.com/blog/2020/10/01/building-modern-ci-cd-workflows-for-serverless-applications-with-red-hat-openshift-pipelines-and-argo-cd-part-1/" data-a2a-title="Building modern CI/CD workflows for serverless applications with Red Hat OpenShift Pipelines and Argo CD, Part 1"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/10/01/building-modern-ci-cd-workflows-for-serverless-applications-with-red-hat-openshift-pipelines-and-argo-cd-part-1/"&gt;Building modern CI/CD workflows for serverless applications with Red Hat OpenShift Pipelines and Argo CD, Part 1&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/eafqH_hG3wo" height="1" width="1" alt=""/&gt;</content><summary>A recent article, The present and future of CI/CD with GitOps on Red Hat OpenShift, proposed Tekton as a framework for cloud-native CI/CD pipelines, and Argo CD as its perfect partner for GitOps. GitOps practices support continuous delivery in hybrid, multi-cluster Kubernetes environments. In this two-part article, we’ll build a CI/CD workflow that demonstrates the potential of combining Tekton an...</summary><dc:creator>David Sancho</dc:creator><dc:date>2020-10-01T07:00:27Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/10/01/building-modern-ci-cd-workflows-for-serverless-applications-with-red-hat-openshift-pipelines-and-argo-cd-part-1/</feedburner:origLink></entry><entry><title>Payments Architecture - Anti-money Laundering Example</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/I-3jDDAa8DY/payments-architecture-anti-money-laundering-example.html" /><category term="Architecture Blueprints" scheme="searchisko:content:tags" /><category term="Automate" scheme="searchisko:content:tags" /><category term="Decision Manager" scheme="searchisko:content:tags" /><category term="feed_group_name_global" scheme="searchisko:content:tags" /><category term="feed_name_ericschabell" scheme="searchisko:content:tags" /><category term="FUSE" scheme="searchisko:content:tags" /><category term="JBoss" scheme="searchisko:content:tags" /><category term="JBossAMQ" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><category term="Process Automation Manager" scheme="searchisko:content:tags" /><author><name>Eric D. Schabell</name></author><id>searchisko:content:id:jbossorg_blog-payments_architecture_anti_money_laundering_example</id><updated>2020-10-01T08:43:59Z</updated><published>2020-10-01T05:00:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;&lt;table cellpadding="0" cellspacing="0" class="tr-caption-container" style="float: left; margin-right: 1em;"&gt;&lt;tbody&gt;&lt;tr&gt;&lt;td style="text-align: center;"&gt;&lt;a href="https://1.bp.blogspot.com/-NhImz2b--gU/X1jsrXrG_jI/AAAAAAAAxeI/2I4wj4AD4YUcuxWk1-464UVs5OiejZFwQCNcBGAsYHQ/s1600/christiann-koepke-0jPuWm8_9wY-unsplash.jpg" style="clear: left; margin-bottom: 1em; margin-left: auto; margin-right: auto;"&gt;&lt;img alt="anti-money laundering" border="0" data-original-height="1067" data-original-width="1600" height="213" src="https://1.bp.blogspot.com/-NhImz2b--gU/X1jsrXrG_jI/AAAAAAAAxeI/2I4wj4AD4YUcuxWk1-464UVs5OiejZFwQCNcBGAsYHQ/s320/christiann-koepke-0jPuWm8_9wY-unsplash.jpg" title="" width="320" /&gt;&lt;/a&gt;&lt;/td&gt;&lt;/tr&gt;&lt;tr&gt;&lt;td class="tr-caption" style="font-size: 12.8px; text-align: center;"&gt;Part 4 - Anti-money laundering&lt;/td&gt;&lt;/tr&gt;&lt;/tbody&gt;&lt;/table&gt;Cloud technology is changing the way payment services are architectured. In this series we will be presenting insight from our customers on adopting open source and cloud technology to modernize their payment service.&lt;br /&gt;&lt;br /&gt;So far we've presented research-based architectural blueprints of&amp;nbsp;&lt;a href="http://www.schabell.org/2018/11/integration-key-to-customer-experience-introduction.html" target="_blank"&gt;omnichannel customer experience&lt;/a&gt;,&amp;nbsp;&lt;a href="https://www.schabell.org/2020/01/integrating-saas-applications-an-introduction.html" target="_blank"&gt;integrating with SaaS applications&lt;/a&gt;, and&amp;nbsp;&lt;a href="https://www.schabell.org/2020/05/cloud-native-development-a-blueprint.html" target="_blank"&gt;cloud-native development solutions&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;In&amp;nbsp;&lt;a href="https://www.schabell.org/2020/09/payments-architecture-immediate-payments-example.html" target="_blank"&gt;the previous article&lt;/a&gt;&amp;nbsp;in this series we walked through the immediate payments physical architecture.&lt;br /&gt;&lt;br /&gt;In this article we're diving into the anti-money laundering (AML) physical architecture, one based on successful customer solutions.&lt;br /&gt;&lt;a name='more'&gt;&lt;/a&gt;&lt;br /&gt;&lt;h3 style="text-align: left;"&gt;Blueprints&lt;/h3&gt;&lt;div&gt;As a reminder, the architectural details covered here are base on real customer integration solutions using open source technologies.&lt;br /&gt;&lt;br /&gt;The example scenario presented here is a generic common blueprint that was uncovered researching customer solutions. It's our intent to provide a blueprint that provides guidance and not deep technical details.&lt;br /&gt;&lt;br /&gt;This section covers the visual representations as presented. There are many ways to represent each element in this architectural blueprint, but we've chosen icons, text and colors that I hope are going to make it all easy to absorb. Feel free to post comments at the bottom of this post, or&amp;nbsp;&lt;a href="https://www.schabell.org/p/contact.html" target="_blank"&gt;contact us&lt;/a&gt;&amp;nbsp;directly with your feedback.&lt;br /&gt;&lt;br /&gt;Now let's take a look at the details in this blueprint and outline the example.&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;div&gt;&lt;h3 style="text-align: left;"&gt;Anti-money laundering&lt;/h3&gt;&lt;/div&gt;&lt;div&gt;The example blueprint shown on the right entitled&amp;nbsp;&lt;i&gt;Anti-money laundering (AML) data example&lt;/i&gt;&amp;nbsp;outlines the solution in a physical architecture. Note that this diagram is focusing on the highest level of the AML solution and the element groupings that apply to this process.&lt;br /&gt;&lt;br /&gt;When you look at &lt;a href="https://www.schabell.org/2020/09/payments-architecture-immediate-payments-example.html" target="_blank"&gt;our previous article &lt;/a&gt;where the immediate payments architecture was laid out as an overview, but if you look closely you'll notice one of the elements was called&amp;nbsp;&lt;i&gt;AML microservices. &lt;/i&gt;This section takes a closer look at what happens behind the scenes to a payments request that triggers a need for AML processing and detection.&lt;br /&gt;&lt;br /&gt;&lt;a href="https://1.bp.blogspot.com/-0cjVcI58GXM/X2nn49vh8rI/AAAAAAAAxj4/9K20_peOcpAed6tc8OjDvhaZnaEdAE9YQCNcBGAsYHQ/s1600/payments-anti-money-laundering-sd.png" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"&gt;&lt;img alt="anti-money laundering" border="0" data-original-height="900" data-original-width="1600" height="180" src="https://1.bp.blogspot.com/-0cjVcI58GXM/X2nn49vh8rI/AAAAAAAAxj4/9K20_peOcpAed6tc8OjDvhaZnaEdAE9YQCNcBGAsYHQ/s320/payments-anti-money-laundering-sd.png" title="" width="320" /&gt;&lt;/a&gt;In this example, starting from the top left corner, a user sends an event or message to execute a payment as an entry point. The users can be mobile, web, or any external device / application that acts as the entry point with the organizations payments architecture.&lt;br /&gt;&lt;br /&gt;This request to execute payments connects through API gateways (not depicted) to internal centralized p&lt;i&gt;ayments event streams&lt;/i&gt;. This element takes these streams and determines what selection or sub-selection of actions need to be taken. For this example, we'll proceed through this architecture as if AML processing is necessary.&lt;br /&gt;&lt;br /&gt;When an event triggers a compliance issue, such as suspected money laundering, the payment transaction(s) are analysed in &lt;i&gt;transaction scoring and labeling. &lt;/i&gt;It's a collection of rules fueled by data analytics that examine the suspect transactions, score them with a value, and tag them with labels before sending them on for specific evaluation as potential money laundering transactions.&lt;br /&gt;&lt;br /&gt;Feeding into&amp;nbsp;&lt;i&gt;transaction scoring and labeling&lt;/i&gt; are several elements of interest that provide a bit of data, analysis, and potential for applying artificial intelligence along with machine learning concepts. This starts with &lt;i&gt;know your customer (KYC) &lt;/i&gt;applications that are used to&amp;nbsp;verify the identity, suitability, and risks involved with maintaining a business relationship with each customer. Feeding the &lt;i&gt;KYC &lt;/i&gt;applications is data from &lt;i&gt;customers and transaction data.&amp;nbsp; &lt;/i&gt;Both of these elements are providing input to the &lt;i&gt;model training and serving&lt;/i&gt;&amp;nbsp;elements that generate models for scoring and labeling transactions.&lt;br /&gt;&lt;br /&gt;After modeling, scoring, and labeling suspect transactions, they're sent to &lt;i&gt;anti-money laundering rules&lt;/i&gt;, a collection of decision services that provide final evaluations and decision making on the suspect transactions. If it's determined the transactions are not money laundering actions, this outcome's fed back into the &lt;i&gt;payments event stream &lt;/i&gt;in a topic for further clearing processing (not shown in this diagram, see the previous article for clearing and routing architectural details).&lt;br /&gt;&lt;br /&gt;Finally, if the outcome is that the transactions are suspect, then they are passed off to the &lt;i&gt;malicious activity streams&lt;/i&gt;&amp;nbsp;element to start a topic of investigation. The actions taken are to open a case with the &lt;i&gt;case management &lt;/i&gt;element and to start a &lt;i&gt;suspicious activity reporting &lt;/i&gt;process. When investigations into the case and final reporting processing is completed, a reporting topic is used to funnel information back to the &lt;i&gt;malicious activity streams.&lt;/i&gt;&lt;br /&gt;&lt;i&gt;&lt;br /&gt;&lt;/i&gt;The anti-money laundering architecture blueprint shown here is detailing the internal workings of the scoring, labeling, evanuation, processing, and reporting of suspect transactions. It's to be viewed as zooming in on the previous article's single element to provide more details on the physical architecture blueprint for this specific solution.&lt;br /&gt;&lt;br /&gt;&lt;/div&gt;&lt;h3&gt;Project examples&lt;/h3&gt;&lt;div&gt;Sharing the process results for our payments blueprint is what this series is about, but there are project artifacts and diagrams that can also be shared with you the reader. We've pulled together an&amp;nbsp;&lt;a href="https://gitlab.com/redhatdemocentral/portfolio-architecture-examples" target="_blank"&gt;examples repository&lt;/a&gt;&amp;nbsp;for all our architecture blueprint diagrams.&amp;nbsp;&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;&lt;div style="text-align: right;"&gt;&lt;/div&gt;The&amp;nbsp;&lt;a href="https://gitlab.com/redhatdemocentral/portfolio-architecture-examples" target="_blank"&gt;Portfolio Architecture Examples&lt;/a&gt;&amp;nbsp;repository makes it possible to collect and share individual images from each diagram element as well as the entire project as a whole.&lt;/div&gt;&lt;div&gt;&lt;div style="text-align: right;"&gt;&lt;a href="https://1.bp.blogspot.com/-4t4sRfvBdlA/X2CrzVQ9sFI/AAAAAAAAxgY/vZ61Z75fKhk3GFBC3ZZlOyGpIJWtBgDngCNcBGAsYHQ/s1600/Screenshot%2B2020-09-15%2Bat%2B13.55.42.png" style="clear: right; float: right; margin-bottom: 1em; margin-left: 1em;"&gt;&lt;img alt="anti-money laundering" border="1" data-original-height="232" data-original-width="530" height="139" src="https://1.bp.blogspot.com/-4t4sRfvBdlA/X2CrzVQ9sFI/AAAAAAAAxgY/vZ61Z75fKhk3GFBC3ZZlOyGpIJWtBgDngCNcBGAsYHQ/s320/Screenshot%2B2020-09-15%2Bat%2B13.55.42.png" title="" width="320" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;/div&gt;&lt;div&gt;For example, if you scroll down to the file listings on the main page, you can locate all the example physical diagrams as shown on the right.&lt;br /&gt;&lt;div style="text-align: right;"&gt;&lt;/div&gt;&lt;br /&gt;This is the collection associated with payments:&lt;br /&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;in this case there are multiple images you can click to view&lt;/li&gt;&lt;li&gt;a project file you can download to your local machine using the&amp;nbsp;&lt;i&gt;Download Diagram&lt;/i&gt;&amp;nbsp;link&lt;/li&gt;&lt;li&gt;a&amp;nbsp;&lt;i&gt;Load Diagram&lt;/i&gt;&amp;nbsp;link that you can&amp;nbsp;&lt;a href="https://redhatdemocentral.gitlab.io/portfolio-architecture-tooling/index.html?#/portfolio-architecture-examples/projects/schematic-diagrams-payments.drawio" target="_blank"&gt;click to automatically open the project diagrams&lt;/a&gt;&amp;nbsp;in the diagram tooling used in this blueprint (use private or incognito browser mode to avoid caching issues and a smoother tooling experience)&amp;nbsp;&lt;/li&gt;&lt;/ul&gt;&lt;/div&gt;&lt;div&gt;Give it a try and feel free to explore the collection of logical, schematic, detailed, solution, and community diagrams. This should allow you to get started much quicker than from scratch if you can kick-start a project with existing diagrams.&lt;br /&gt;&lt;br /&gt;Should you desire to start designing your own diagrams, please contribute the project file (ending in .drawio) by raising an issue with the file attached. We'd love to continue collecting these projects for others to use.&lt;br /&gt;&lt;br /&gt;Finally, there is a free online&amp;nbsp;&lt;a href="https://redhatdemocentral.gitlab.io/portfolio-architecture-workshops" target="_blank"&gt;beginners guide workshop&lt;/a&gt;&amp;nbsp;available focused on using the diagram tooling, please explore to learn tips and tricks from the experts.&lt;/div&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;h3&gt;What's next&lt;/h3&gt;&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;An overview of the series on the payments portfolio architecture blueprint can be found here:&lt;br /&gt;&lt;ol style="text-align: left;"&gt;&lt;li&gt;&lt;a href="https://www.schabell.org/2020/09/financial-payments-architecture-an-introduction.html" target="_blank"&gt;An introduction&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.schabell.org/2020/09/payments-architecture-common-elements.html" target="_blank"&gt;Common architecture elements&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.schabell.org/2020/09/payments-architecture-immediate-payments-example.html" target="_blank"&gt;Immediate payments example&lt;/a&gt;&lt;/li&gt;&lt;li&gt;&lt;a href="https://www.schabell.org/2020/10/payments-architecture-anti-money-laundering-example.html"&gt;Anti-money laundering example&lt;/a&gt;&lt;/li&gt;&lt;li&gt;Fraud detection example&lt;/li&gt;&lt;li&gt;Financial calculations example&lt;/li&gt;&lt;/ol&gt;&lt;ol style="text-align: left;"&gt;&lt;/ol&gt;Catch up on any articles you missed by following one of the links above.&lt;br /&gt;&lt;br /&gt;Next in this series, taking a look at the&amp;nbsp;generic&amp;nbsp;&lt;i&gt;fraud detection example&lt;/i&gt;&amp;nbsp;in a cloud-native architecture focused on payment processing.&lt;br /&gt;&lt;br /&gt;(Article co-authored by&amp;nbsp;&lt;a href="https://www.linkedin.com/in/ramonv/?originalSubdomain=uk" target="_blank"&gt;Ramon Villarreal&lt;/a&gt;)&lt;br /&gt;&lt;div&gt;&lt;br /&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class="feedflare"&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=6PTj8MCJpxw:S1ILhJD8_Ws:yIl2AUoC8zA"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=yIl2AUoC8zA" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=6PTj8MCJpxw:S1ILhJD8_Ws:63t7Ie-LG7Y"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=63t7Ie-LG7Y" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=6PTj8MCJpxw:S1ILhJD8_Ws:4cEx4HpKnUU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=6PTj8MCJpxw:S1ILhJD8_Ws:4cEx4HpKnUU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=6PTj8MCJpxw:S1ILhJD8_Ws:F7zBnMyn0Lo"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=6PTj8MCJpxw:S1ILhJD8_Ws:F7zBnMyn0Lo" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=6PTj8MCJpxw:S1ILhJD8_Ws:V_sGLiPBpWU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=6PTj8MCJpxw:S1ILhJD8_Ws:V_sGLiPBpWU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=6PTj8MCJpxw:S1ILhJD8_Ws:qj6IDK7rITs"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?d=qj6IDK7rITs" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/schabell/jboss?a=6PTj8MCJpxw:S1ILhJD8_Ws:gIN9vFwOqvQ"&gt;&lt;img src="http://feeds.feedburner.com/~ff/schabell/jboss?i=6PTj8MCJpxw:S1ILhJD8_Ws:gIN9vFwOqvQ" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/schabell/jboss/~4/6PTj8MCJpxw" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/I-3jDDAa8DY" height="1" width="1" alt=""/&gt;</content><summary>Part 4 - Anti-money launderingCloud technology is changing the way payment services are architectured. In this series we will be presenting insight from our customers on adopting open source and cloud technology to modernize their payment service. So far we've presented research-based architectural blueprints of omnichannel customer experience, integrating with SaaS applications, and cloud-native ...</summary><dc:creator>Eric D. Schabell</dc:creator><dc:date>2020-10-01T05:00:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/schabell/jboss/~3/6PTj8MCJpxw/payments-architecture-anti-money-laundering-example.html</feedburner:origLink></entry><entry><title>AI software stack inspection with Thoth and TensorFlow</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/lvnLRySjp0s/" /><category term="Big Data" scheme="searchisko:content:tags" /><category term="ci/cd" scheme="searchisko:content:tags" /><category term="data science" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="human machine interaction" scheme="searchisko:content:tags" /><category term="Jupyter notebook" scheme="searchisko:content:tags" /><category term="machine learning" scheme="searchisko:content:tags" /><category term="performance" scheme="searchisko:content:tags" /><category term="Project Thoth" scheme="searchisko:content:tags" /><category term="software stack analysis" scheme="searchisko:content:tags" /><category term="TensorFlow" scheme="searchisko:content:tags" /><author><name>Francesco Murdaca</name></author><id>searchisko:content:id:jbossorg_blog-ai_software_stack_inspection_with_thoth_and_tensorflow</id><updated>2020-09-30T08:02:04Z</updated><published>2020-09-30T08:02:04Z</published><content type="html">&lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/thoth-station/core/blob/master/doc/ROADMAP.md#thoth-roadmap"&gt;Project Thoth&lt;/a&gt; develops &lt;a href="https://developers.redhat.com/topics/open-source"&gt;open source&lt;/a&gt; tools that enhance the day-to-day life of developers and data scientists. Thoth uses machine-generated knowledge to boost the performance, security, and quality of your applications using &lt;a href="https://developers.redhat.com/topics/ai-ml"&gt;artificial intelligence&lt;/a&gt; (AI) through &lt;a target="_blank" rel="nofollow" href="https://en.wikipedia.org/wiki/Reinforcement_learning#:~:text=Reinforcement%20learning%20(RL)%20is%20an,supervised%20learning%20and%20unsupervised%20learning."&gt;reinforcement learning (RL)&lt;/a&gt;. This machine-learning approach is implemented in &lt;a target="_blank" rel="nofollow" href="https://github.com/thoth-station/adviser"&gt;Thoth adviser&lt;/a&gt; (if you want to know more, &lt;a target="_blank" rel="nofollow" href="https://www.youtube.com/watch?v=WEJ65Rvj3lc&amp;#38;t=1s"&gt;click here&lt;/a&gt;) and it is used by &lt;a target="_blank" rel="nofollow" href="https://github.com/thoth-station/adviser/blob/master/docs/source/integration.rst"&gt;Thoth integrations&lt;/a&gt; to provide the software stack based on &lt;a target="_blank" rel="nofollow" href="https://github.com/thoth-station/thamos#using-custom-configuration-file-template"&gt;user inputs&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;In this article, I introduce a case study—a recent inspection of a runtime issue when importing TensorFlow 2.1.0—to demonstrate the human-machine interaction between the Thoth team and Thoth components. By following the case study from start to finish, you will learn how Thoth gathers and analyzes some of the data to provide &lt;a target="_blank" rel="nofollow" href="https://thoth-station.ninja/justifications"&gt;advice&lt;/a&gt; to its users, including bots such as &lt;a target="_blank" rel="nofollow" href="https://github.com/thoth-station/kebechet#kebechet"&gt;Kebechet&lt;/a&gt;, &lt;a target="_blank" rel="nofollow" href="https://github.com/AICoE/aicoe-ci"&gt;AI-backed continuous integration pipelines&lt;/a&gt;, and developers using &lt;a target="_blank" rel="nofollow" href="https://github.com/thoth-station/qeb-hwt"&gt;GitHub apps&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Both the &lt;a target="_blank" rel="nofollow" href="https://github.com/thoth-station"&gt;Thoth machinery&lt;/a&gt; and team rely on bots and automated pipelines running on Red Hat OpenShift. Thoth takes a variety of inputs to determine the correct advice:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/thoth-station/solver"&gt;Solver&lt;/a&gt;, which Thoth uses to discover if something can be installed in a particular runtime environment, such as &lt;a href="https://developers.redhat.com/topics/linux"&gt;Red Hat Enterprise Linux&lt;/a&gt; (RHEL) 8 with Python 3.6.&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/thoth-station/datasets/tree/master/notebooks/thoth-security-dataset#thoth-security-datasets"&gt;Security indicators&lt;/a&gt; that uncover vulnerabilities of a different nature, which can be applied to security advice.&lt;/li&gt; &lt;li&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/thoth-station/mi"&gt;Project meta information&lt;/a&gt;, such as project-maintenance status or development-process behavior that affects the overall project.&lt;/li&gt; &lt;li&gt;Inspections, which Thoth uses to discover code quality issues or performance across packages.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;This article focuses on inspections. I will show you the results from an automated software stack inspection run through &lt;a target="_blank" rel="nofollow" href="https://thoth-station.ninja/"&gt;Project Thoth&lt;/a&gt;&amp;#8216;s &lt;a target="_blank" rel="nofollow" href="https://github.com/thoth-station/adviser/blob/master/docs/source/dependency_monkey.rst"&gt;Dependency Monkey&lt;/a&gt; and &lt;a target="_blank" rel="nofollow" href="https://github.com/thoth-station/amun-api#amun-service"&gt;Amun&lt;/a&gt; components. Thoth uses automated inspections to introduce new advice about software stacks for Thoth users. Another way to integrate advice could be via automated pipelines that can:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Boost performance&lt;/li&gt; &lt;li&gt;Optimize &lt;a href="https://developers.redhat.com/blog/category/machine-learning/"&gt;machine learning&lt;/a&gt; (ML) model inference&lt;/li&gt; &lt;li&gt;Ensure that there are no failures during the model runtime (for example, during inference)&lt;/li&gt; &lt;li&gt;Avoid using software stacks that does not guarantee security.&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Thoth components: Amun and Dependency Monkey&lt;/h2&gt; &lt;p&gt;Given the list of packages that should be installed and the hardware requested to run the application, &lt;a target="_blank" rel="nofollow" href="https://github.com/thoth-station/amun-api#amun-service"&gt;Amun&lt;/a&gt; executes the requested application stack in the requested environment. Amun acts as an execution engine for Thoth. Applications are then built and tested using &lt;a target="_blank" rel="nofollow" href="https://github.com/thoth-station/performance"&gt;Thoth Performance Indicators (PI)&lt;/a&gt;. See Amun&amp;#8217;s &lt;a target="_blank" rel="nofollow" href="https://github.com/thoth-station/amun-api/blob/master/README.rst"&gt;README documentation&lt;/a&gt; for more information about this service.&lt;/p&gt; &lt;p&gt;Another Thoth component, &lt;a target="_blank" rel="nofollow" href="https://github.com/thoth-station/adviser/blob/master/docs/source/dependency_monkey.rst"&gt;Dependency Monkey&lt;/a&gt;, can be used to schedule Amun. Dependency Monkey was designed to automate the evaluation of certain aspects of a software stack, such as code quality or performance. Therefore, it aims to automatically verify software stacks and aggregate relevant observations.&lt;/p&gt; &lt;p&gt;From these two components, the Thoth team created &lt;a target="_blank" rel="nofollow" href="https://github.com/thoth-station/datasets/blob/master/notebooks/thoth-performance-dataset"&gt;Thoth Performance Datasets&lt;/a&gt;, which contains observations about performance for software stacks. For example, Thoth Performance Datasets could use &lt;a target="_blank" rel="nofollow" href="https://github.com/thoth-station/performance/blob/master/tensorflow/conv2d.py"&gt;PIconv2d&lt;/a&gt; to obtain performance data for different application types (such as machine learning) and code quality. It could then use a performance indicator like &lt;a target="_blank" rel="nofollow" href="https://github.com/thoth-station/performance/blob/master/tensorflow/import.py"&gt;PiImport&lt;/a&gt; to discover errors during an application run.&lt;/p&gt; &lt;h2&gt;Transparent and reproducible datasets&lt;/h2&gt; &lt;p&gt;In the spirit of open source, the Thoth team wants to guarantee that the datasets and knowledge that we collect and use are transparent and reproducible. Machine learning models, such as the reinforcement learning model leveraged by &lt;a target="_blank" rel="nofollow" href="https://github.com/thoth-station/adviser"&gt;Thoth Adviser&lt;/a&gt;, should be as transparent as the datasets they are working on.&lt;/p&gt; &lt;p&gt;For transparency, we&amp;#8217;ve introduced &lt;a target="_blank" rel="nofollow" href="https://github.com/thoth-station/datasets#thoth-datasets"&gt;Thoth Datasets&lt;/a&gt;, where we share the notebooks that we used to analyze a data collection and all of the results. We encourage anyone interested in the topic to use Thoth Datasets to verify our findings or for other purposes.&lt;/p&gt; &lt;p&gt;For reproducibility, we&amp;#8217;ve introduced &lt;a target="_blank" rel="nofollow" href="https://github.com/thoth-station/dependency-monkey-zoo"&gt;Dependency Monkey Zoo&lt;/a&gt;, where we collect all of the specifications used to run an analysis. Having all of the specs in one place allows us to reproduce the results of a study. Anyone can use the specs to perform similar studies in different environments for comparison.&lt;/p&gt; &lt;h2&gt;Case study: Automated software stack inspection for TensorFlow 2.1.0&lt;/h2&gt; &lt;p&gt;For this case study, we will use Thoth&amp;#8217;s Amun and Dependency Monkey components to automatically produce data. We&amp;#8217;ll then introduce reusable &lt;a target="_blank" rel="nofollow" href="https://github.com/thoth-station/datasets/blob/master/notebooks/templates/Amun%20Inspection%20Analysis%20Template.ipynb"&gt;Jupyter notebook templates&lt;/a&gt; to extract specific information from the datasets. Finally, we&amp;#8217;ll create new advice based on the results.&lt;/p&gt; &lt;p&gt;The human side of this human-machine interaction focuses on assessing the quality of the results and formulating the advice. The rest of the process is machine-automated. Automation makes the process easy to repeat to produce a new source of information for analysis.&lt;/p&gt; &lt;p&gt;In the next sections, I introduce the initial problem, then describe the analysis performed and the resulting new advice for Thoth users.&lt;/p&gt; &lt;h2&gt;Initial request&lt;/h2&gt; &lt;p&gt;Our goal with this inspection is to analyze build- and runtime failures when importing TensorFlow 2.1.0 and use these to derive observations about the quality of the software stack.&lt;/p&gt; &lt;p&gt;For this analysis, Dependency Monkey sampled the state space of all of the possible &lt;code&gt;TensorFlow==2.1.0&lt;/code&gt; stacks (from upstream builds). For inspection purposes, we built and ran the application using the &lt;a target="_blank" rel="nofollow" href="https://github.com/thoth-station/performance/blob/master/tensorflow/matmul.py"&gt;PiMatmul&lt;/a&gt; performance indicator.&lt;/p&gt; &lt;p&gt;The sections below detail the &lt;a target="_blank" rel="nofollow" href="https://github.com/thoth-station/dependency-monkey-zoo/tree/master/tensorflow/inspection-2020-09-04"&gt;Dependency Monkey inspection results&lt;/a&gt; and the resulting &lt;a target="_blank" rel="nofollow" href="https://github.com/thoth-station/notebooks/issues/70"&gt;analysis&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;The first analysis&lt;/h2&gt; &lt;p&gt;From the &lt;a target="_blank" rel="nofollow" href="https://github.com/thoth-station/datasets/blob/master/notebooks/thoth-performance-dataset/PerformanceTensorFlow2.1.0SoftwareStackCombinations.ipynb"&gt;software stack analysis&lt;/a&gt; of inspection results, we discovered that TensorFlow 2.1.0 was giving errors during approximately 50% of inspections during a run. The error is shown in the following output from the Jupyter Notebook:&lt;/p&gt; &lt;pre&gt;'2020-09-05 07:14:36.333589: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library \'libnvinfer.so.6\'; dlerror: libnvinfer.so.6: cannot open shared object file: No such file or directory 2020-09-05 07:14:36.333811: W tensorflow/stream_executor/platform/default/dso_loader.cc:55] Could not load dynamic library \'libnvinfer_plugin.so.6\'; dlerror: libnvinfer_plugin.so.6: cannot open shared object file: No such file or directory 2020-09-05 07:14:36.333844: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:30] Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly. /opt/app-root/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`. from ._conv import register_converters as _register_converters /opt/app-root/lib/python3.6/site-packages/requests/__init__.py:91: RequestsDependencyWarning: urllib3 (1.5) or chardet (2.3.0) doesn\'t match a supported version! RequestsDependencyWarning) Traceback (most recent call last): File "/home/amun/script", line 14, in &amp;#60;module&amp;#62; import tensorflow as tf File "/opt/app-root/lib/python3.6/site-packages/tensorflow/__init__.py", line 101, in &amp;#60;module&amp;#62; from tensorflow_core import * File "/opt/app-root/lib/python3.6/site-packages/tensorflow_core/__init__.py", line 40, in &amp;#60;module&amp;#62; from tensorflow.python.tools import module_util as _module_util File "/opt/app-root/lib/python3.6/site-packages/tensorflow/__init__.py", line 50, in __getattr__ module = self._load() File "/opt/app-root/lib/python3.6/site-packages/tensorflow/__init__.py", line 44, in _load\n module = _importlib.import_module(self.__name__) File "/opt/app-root/lib64/python3.6/importlib/__init__.py", line 126, in import_module return _bootstrap._gcd_import(name[level:], package, level) File "/opt/app-root/lib/python3.6/site-packages/tensorflow_core/python/__init__.py", line 95, in &amp;#60;module&amp;#62; from tensorflow.python import keras File "/opt/app-root/lib/python3.6/site-packages/tensorflow_core/python/keras/__init__.py", line 27, in &amp;#60;module&amp;#62; from tensorflow.python.keras import models File "/opt/app-root/lib/python3.6/site-packages/tensorflow_core/python/keras/__init__.py", line 27, in &amp;#60;module&amp;#62; from tensorflow.python.keras import models File "/opt/app-root/lib/python3.6/site-packages/tensorflow_core/python/keras/models.py", line 25, in &amp;#60;module&amp;#62; from tensorflow.python.keras.engine import network File "/opt/app-root/lib/python3.6/site-packages/tensorflow_core/python/keras/engine/network.py", line 46, in &amp;#60;module&amp;#62; from tensorflow.python.keras.saving import hdf5_format File "/opt/app-root/lib/python3.6/site-packages/tensorflow_core/python/keras/saving/hdf5_format.py", line 32, in &amp;#60;module&amp;#62; from tensorflow.python.keras.utils import conv_utils File "/opt/app-root/lib/python3.6/site-packages/tensorflow_core/python/keras/utils/conv_utils.py", line 22, in &amp;#60;module&amp;#62; from six.moves import range # pylint: disable=redefined-builtin ImportError: cannot import name \'range\''&lt;/pre&gt; &lt;p&gt;Specifically, we could see that some combinations of &lt;code&gt;six&lt;/code&gt; and &lt;code&gt;urllib3&lt;/code&gt; produced that error, as described in the following &lt;a target="_blank" rel="nofollow" href="https://github.com/thoth-station/notebooks/issues/70#issuecomment-688656575"&gt;output&lt;/a&gt;:&lt;/p&gt; &lt;pre&gt;============================================= urllib3 ============================================= In successfull inspections: ['urllib3-1.10.4-pypi-org' 'urllib3-1.16-pypi-org' 'urllib3-0.3-pypi-org' 'urllib3-1.21.1-pypi-org' 'urllib3-1.25.1-pypi-org' 'urllib3-1.25-pypi-org' 'urllib3-1.18.1-pypi-org' 'urllib3-1.24.1-pypi-org' 'urllib3-1.10.1-pypi-org' 'urllib3-1.10.3-pypi-org' 'urllib3-1.25.7-pypi-org' 'urllib3-1.10-pypi-org' 'urllib3-1.7.1-pypi-org' 'urllib3-1.13-pypi-org' 'urllib3-1.19.1-pypi-org' 'urllib3-1.11-pypi-org' 'urllib3-1.10.2-pypi-org' 'urllib3-1.15.1-pypi-org' 'urllib3-1.25.3-pypi-org' 'urllib3-1.13.1-pypi-org' 'urllib3-1.21-pypi-org' 'urllib3-1.17-pypi-org' 'urllib3-1.23-pypi-org'] In failed inspections: ['urllib3-1.5-pypi-org'] In failed inspections but not in successfull: {'urllib3-1.5-pypi-org'} In failed inspections and in successfull: set() ============================================= six ============================================= In successfull inspections: ['six-1.13.0-pypi-org' 'six-1.12.0-pypi-org'] In failed inspections: ['six-1.13.0-pypi-org' 'six-1.12.0-pypi-org'] In failed inspections but not in successfull: set() In failed inspections and in successfull: {'six-1.13.0-pypi-org', 'six-1.12.0-pypi-org'}&lt;/pre&gt; &lt;p&gt;Therefore, we discovered that &lt;a target="_blank" rel="nofollow" href="https://pypi.org/project/urllib3/"&gt;&lt;strong&gt;urllib3&lt;/strong&gt;&lt;/a&gt; library releases were the same across all failed inspections but not in any of the successful inspections, while &lt;a target="_blank" rel="nofollow" href="https://pypi.org/project/six/"&gt;&lt;strong&gt;six&lt;/strong&gt;&lt;/a&gt; library releases didn&amp;#8217;t show any differences between failed and successful once.&lt;/p&gt; &lt;h2&gt;The second analysis&lt;/h2&gt; &lt;p&gt;For our next step, we decided to run another analysis to restrict the cases. For this run, we used a newly created performance indicator called &lt;a target="_blank" rel="nofollow" href="https://github.com/thoth-station/performance/blob/master/tensorflow/import.py"&gt;PiImport&lt;/a&gt; as shown in Table 1.&lt;/p&gt; &lt;table&gt; &lt;caption&gt;Table 1: The PiImport performance indicator.&lt;/caption&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;strong&gt;Description&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;Dependency Monkey sampled the state space of all the possible &lt;code&gt;TensorFlow==2.1.0&lt;/code&gt; stacks (from upstream builds). The application was built and run using the &lt;a target="_blank" rel="nofollow" href="https://github.com/thoth-station/performance/blob/master/tensorflow/import.py"&gt;PiImport&lt;/a&gt; performance indicator.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;strong&gt;Specification  &lt;/strong&gt;&lt;/td&gt; &lt;td&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/thoth-station/dependency-monkey-zoo/tree/master/tensorflow/inspection-2020-09-08.1"&gt;Dependency Monkey specification&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;strong&gt;Goal&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;Identify specific versions that fail to produce final &lt;a target="_blank" rel="nofollow" href="https://github.com/thoth-station/adviser/pull/1172"&gt;advice&lt;/a&gt;.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;strong&gt;Reference&lt;/strong&gt;&lt;/td&gt; &lt;td&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/thoth-station/datasets/issues/16"&gt;Issue&lt;/a&gt;&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;h2&gt;Results of the second analysis&lt;/h2&gt; &lt;p&gt;From the new &lt;a target="_blank" rel="nofollow" href="https://github.com/thoth-station/datasets/blob/master/notebooks/thoth-performance-dataset/PerformanceTensorFlow2.1.0SoftwareStackCombinationsErrors.ipynb"&gt;analysis&lt;/a&gt;, we were able to identify all of the specific versions of &lt;code&gt;urllib3&lt;/code&gt; and &lt;code&gt;six&lt;/code&gt; that did not work together and that were causing issues during runtime. The output in Figure 1 shows the incompatible versions of the two packages.&lt;/p&gt; &lt;p&gt;dFigure 1: Identifying the incompatible versions of urllib3 and six that do not allow to run Tensorflow 2.1.0.&lt;/p&gt; &lt;h2&gt;The advice&lt;/h2&gt; &lt;p&gt;All of this backtracing led to an &lt;a target="_blank" rel="nofollow" href="https://github.com/thoth-station/adviser/pull/1172"&gt;adviser step&lt;/a&gt; called &lt;a target="_blank" rel="nofollow" href="https://github.com/thoth-station/adviser/blob/master/thoth/adviser/steps/tensorflow_21_urllib3.py"&gt;TensorFlow21Urllib3Step&lt;/a&gt;. With this step, we can penalize software stacks containing the specific version of &lt;code&gt;urllib3&lt;/code&gt; that cause runtime issues when attempting to import TensorFlow 2.1.0. The following prediction, created by Thoth, results in a higher quality software stack for users.&lt;/p&gt; &lt;table&gt; &lt;caption&gt;Table 2: The TensorFlow21Urllib3Step adviser step.&lt;/caption&gt; &lt;tbody&gt; &lt;tr&gt; &lt;td&gt;&lt;b&gt;Title&lt;/b&gt;&lt;/td&gt; &lt;td&gt;TensorFlow in version 2.1 can cause runtime errors when imported, caused by incompatibility between &lt;code&gt;urllib3&lt;/code&gt; and &lt;code&gt;six&lt;/code&gt; packages.&lt;/td&gt; &lt;/tr&gt; &lt;tr&gt; &lt;td&gt;&lt;b&gt;Issue description&lt;/b&gt;&lt;/td&gt; &lt;td&gt;Package &lt;code&gt;urllib3&lt;/code&gt; in some versions is shipped with a bundled version of &lt;code&gt;six&lt;/code&gt;, which has its own mechanism for imports and import context handling. Importing &lt;code&gt;urllib3&lt;/code&gt; in the TensorFlow codebase causes initialization of the bundled &lt;code&gt;six&lt;/code&gt; module, which collides with a subsequent import from unbundled &lt;code&gt;six&lt;/code&gt; modules.&lt;/td&gt; &lt;/tr&gt; &lt;/tbody&gt; &lt;/table&gt; &lt;p&gt;You can find the complete issue description, and the recommended resolution, &lt;a target="_blank" rel="nofollow" href="https://thoth-station.ninja/j/tf_21_urllib3.html"&gt;here&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F09%2F30%2Fai-software-stack-inspection-with-thoth-and-tensorflow%2F&amp;#38;linkname=AI%20software%20stack%20inspection%20with%20Thoth%20and%20TensorFlow" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F09%2F30%2Fai-software-stack-inspection-with-thoth-and-tensorflow%2F&amp;#38;linkname=AI%20software%20stack%20inspection%20with%20Thoth%20and%20TensorFlow" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F09%2F30%2Fai-software-stack-inspection-with-thoth-and-tensorflow%2F&amp;#38;linkname=AI%20software%20stack%20inspection%20with%20Thoth%20and%20TensorFlow" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F09%2F30%2Fai-software-stack-inspection-with-thoth-and-tensorflow%2F&amp;#38;linkname=AI%20software%20stack%20inspection%20with%20Thoth%20and%20TensorFlow" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F09%2F30%2Fai-software-stack-inspection-with-thoth-and-tensorflow%2F&amp;#38;linkname=AI%20software%20stack%20inspection%20with%20Thoth%20and%20TensorFlow" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F09%2F30%2Fai-software-stack-inspection-with-thoth-and-tensorflow%2F&amp;#38;linkname=AI%20software%20stack%20inspection%20with%20Thoth%20and%20TensorFlow" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F09%2F30%2Fai-software-stack-inspection-with-thoth-and-tensorflow%2F&amp;#38;linkname=AI%20software%20stack%20inspection%20with%20Thoth%20and%20TensorFlow" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F09%2F30%2Fai-software-stack-inspection-with-thoth-and-tensorflow%2F&amp;#038;title=AI%20software%20stack%20inspection%20with%20Thoth%20and%20TensorFlow" data-a2a-url="https://developers.redhat.com/blog/2020/09/30/ai-software-stack-inspection-with-thoth-and-tensorflow/" data-a2a-title="AI software stack inspection with Thoth and TensorFlow"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/09/30/ai-software-stack-inspection-with-thoth-and-tensorflow/"&gt;AI software stack inspection with Thoth and TensorFlow&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/lvnLRySjp0s" height="1" width="1" alt=""/&gt;</content><summary>Project Thoth develops open source tools that enhance the day-to-day life of developers and data scientists. Thoth uses machine-generated knowledge to boost the performance, security, and quality of your applications using artificial intelligence (AI) through reinforcement learning (RL). This machine-learning approach is implemented in Thoth adviser (if you want to know more, click here) and it is...</summary><dc:creator>Francesco Murdaca</dc:creator><dc:date>2020-09-30T08:02:04Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/09/30/ai-software-stack-inspection-with-thoth-and-tensorflow/</feedburner:origLink></entry><entry><title>This Week in JBoss - 30 September 2020</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/6SrCuoxXhnk/weekly-2020-09-30.html" /><category term="Camel" scheme="searchisko:content:tags" /><category term="camelk" scheme="searchisko:content:tags" /><category term="devconf" scheme="searchisko:content:tags" /><category term="feed_group_name_global" scheme="searchisko:content:tags" /><category term="feed_name_weeklyeditorial" scheme="searchisko:content:tags" /><category term="jBPM" scheme="searchisko:content:tags" /><category term="Kafka" scheme="searchisko:content:tags" /><category term="OCP" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><author><name>Paul Robinson</name></author><id>searchisko:content:id:jbossorg_blog-this_week_in_jboss_30_september_2020</id><updated>2020-09-30T00:00:00Z</updated><published>2020-09-30T00:00:00Z</published><content type="html">&lt;article class="" data-tags="jBPM, OCP, OpenShift, Camel, CamelK, DevConf, Kafka"&gt; &lt;h1&gt;This Week in JBoss - 30 September 2020&lt;/h1&gt; &lt;p&gt;It’s that time again where we round up the latest news from the community…&lt;/p&gt; &lt;p&gt;Are you looking to develop projects on your local machine, and push them on to a real OpenShift Container Platform, without having to worry about cloud hosting of your container platform? In this &lt;a href="https://www.schabell.org/2020/09/how-to-setup-openshift-container-platform-45.html"&gt;post&lt;/a&gt; Eric Schabell provides an easy way to get up and running with CodeReady containers on your own development machine. He’s automated most of the process through scripts, and guides you through the rest of the process. Eric also shows you how to drop into the Developer console in OCP providing a developer focused view that hides much of the plumbing that is not needed during development.&lt;/p&gt; &lt;p&gt;In this &lt;a href="https://developers.redhat.com/blog/2020/09/28/call-an-existing-rest-service-with-apache-camel-k/"&gt;post&lt;/a&gt; Mary Cochran shows us a simple way to connect existing services together using CamelK via each service’s REST APIs. Mary gets deep into the details providing code examples and commands to get you up and running.&lt;/p&gt; &lt;p&gt;Eric Schabell continues his &lt;a href="https://www.schabell.org/2020/09/financial-payments-architecture-an-introduction.html"&gt;blog series&lt;/a&gt;, bringing you architectural blueprints for&amp;#160;cloud-native financial payment services. The blueprints are focused on proven interactions, messaging, processing, and integration patterns that you can put to use when building a cloud-native payment architecture. This week he covers the &lt;a href="https://www.schabell.org/2020/09/payments-architecture-common-elements.html"&gt;Common Architecture Elements&lt;/a&gt; that make up the architecture, and gets into some details with the &lt;a href="https://www.schabell.org/2020/09/payments-architecture-immediate-payments-example.html"&gt;Immediate Payments Example&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;As is normal for this time of year, the conference season is beginning to kick off. Albeit this year in a virtual arena. Undoubtedly this is an unfortunate situation for those that enjoy the in-person events. However, it’s great for accessibility and reach allowing many more people across to globe to attend. DevConf.US 2020 is one such event. It’s a free, Red Hat sponsored technology conference for community project and professional contributors to Free and Open Source technologies. Read more &lt;a href="https://www.schabell.org/2020/09/devconfus-2020-appdev-containerization-ask-the-experts.html"&gt;here&lt;/a&gt; where Eric describes the “AppDev &amp;#38; Containerization Ask the Experts” Panels that he and Kurt Stam will be moderating.&lt;/p&gt; &lt;p&gt;This week Kapil Shukla explains how to &lt;a href="https://developers.redhat.com/blog/2020/09/28/build-a-data-streaming-pipeline-using-kafka-streams-and-quarkus/"&gt;build a data streaming pipeline using Kafka Streams and Quarkus&lt;/a&gt;. In this post Kapil shows how data can be processed in real-time as and when it arrives, instead of being batch processed as was needed in the past.&lt;/p&gt; &lt;p&gt;In this &lt;a href="https://developers.redhat.com/blog/2020/09/22/troubleshooting-user-task-errors-in-red-hat-process-automation-manager-and-red-hat-jboss-bpm-suite/"&gt;Post&lt;/a&gt; Anton Giertli provides help with troubleshooting user task errors in Red Hat Process Automation Manager and Red Hat JBoss BPM Suite. If you are a developer working with user tasks and having trouble debugging them, this post might well help you out.&lt;/p&gt; &lt;p&gt;With the recent release of Apache Camel VS Code extension (0.0.27) comes several new language support features for Apache Camel. Read this &lt;a href="https://developers.redhat.com/blog/2020/09/18/new-language-support-features-in-apache-camel-vs-code-extension-0-0-27/"&gt;post&lt;/a&gt; to learn more.&lt;/p&gt; &lt;div class="author"&gt; &lt;pfe-avatar pfe-shape="circle" pfe-pattern="squares" pfe-src="/img/people/paul-robinson.png"&gt;&lt;/pfe-avatar&gt; &lt;span&gt;Paul Robinson&lt;/span&gt; &lt;/div&gt;&lt;/article&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/6SrCuoxXhnk" height="1" width="1" alt=""/&gt;</content><summary>This Week in JBoss - 30 September 2020 It’s that time again where we round up the latest news from the community… Are you looking to develop projects on your local machine, and push them on to a real OpenShift Container Platform, without having to worry about cloud hosting of your container platform? In this post Eric Schabell provides an easy way to get up and running with CodeReady containers on...</summary><dc:creator>Paul Robinson</dc:creator><dc:date>2020-09-30T00:00:00Z</dc:date><feedburner:origLink>https://www.jboss.org/posts/weekly-2020-09-30.html</feedburner:origLink></entry><entry><title>Quicker, easier GraphQL queries with Open Liberty 20.0.0.9</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/CeJhWusLdiQ/" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="graphql mutation" scheme="searchisko:content:tags" /><category term="graphql query" scheme="searchisko:content:tags" /><category term="Java" scheme="searchisko:content:tags" /><category term="Kubernetes" scheme="searchisko:content:tags" /><category term="microprofile" scheme="searchisko:content:tags" /><category term="microservices" scheme="searchisko:content:tags" /><category term="open source" scheme="searchisko:content:tags" /><category term="OpenLiberty" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><author><name>Jakub Pomykala</name></author><id>searchisko:content:id:jbossorg_blog-quicker_easier_graphql_queries_with_open_liberty_20_0_0_9</id><updated>2020-09-29T07:00:48Z</updated><published>2020-09-29T07:00:48Z</published><content type="html">&lt;p&gt;Open Liberty 20.0.0.9 lets developers experiment with the type-safe SmallRye GraphQL Client API, and write and run GraphQL queries and mutations more easily with a built-in GraphiQL user interface (UI). This article introduces the new features and updates in Open Liberty 20.0.0.9:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="#GraphQLAPIs"&gt;Experiment with a third-party GraphQL client API.&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="#GraphiQL"&gt;Use the built-in GraphiQL UI for faster queries and mutations.&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="#feedback"&gt;Give us your feedback!&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Run your apps using Open Liberty 20.0.0.9&lt;/h2&gt; &lt;p&gt;If you are using &lt;a target="_blank" rel="nofollow" href="https://openliberty.io//guides/maven-intro.html"&gt;Maven&lt;/a&gt;, use these coordinates to update to the newest version of Open Liberty:&lt;/p&gt; &lt;pre&gt;&amp;#60;dependency&amp;#62; &amp;#60;groupId&amp;#62;io.openliberty&amp;#60;/groupId&amp;#62; &amp;#60;artifactId&amp;#62;openliberty-runtime&amp;#60;/artifactId&amp;#62; &amp;#60;version&amp;#62;20.0.0.9&amp;#60;/version&amp;#62; &amp;#60;type&amp;#62;zip&amp;#60;/type&amp;#62; &amp;#60;/dependency&amp;#62; &lt;/pre&gt; &lt;p&gt;For &lt;a target="_blank" rel="nofollow" href="https://openliberty.io//guides/gradle-intro.html"&gt;Gradle&lt;/a&gt;, enter:&lt;/p&gt; &lt;pre&gt;dependencies { libertyRuntime group: 'io.openliberty', name: 'openliberty-runtime', version: '[20.0.0.9,)' } &lt;/pre&gt; &lt;p&gt;If you&amp;#8217;re using Docker, it&amp;#8217;s:&lt;/p&gt; &lt;pre&gt;FROM open-liberty &lt;/pre&gt; &lt;h2 id="GraphQLAPIs"&gt;Experiment with a third-party GraphQL client API&lt;/h2&gt; &lt;p&gt;&lt;a target="_blank" rel="nofollow" href="https://github.com/eclipse/microprofile-graphql"&gt;MicroProfile GraphQL&lt;/a&gt; has only been available in Open Liberty for a few months, and it is already a hit. That said, there are a few ways that we want to improve it and make it more complete. One feature that we want to improve is the GraphQL client API. While the official client API is not expected until the next release of MicroProfile GraphQL, you can start experimenting now with the type-safe SmallRye GraphQL client API.&lt;/p&gt; &lt;p&gt;SmallRye is the underlying implementation of MicroProfile GraphQL. You can access its above-and-beyond-the-spec features by adding the &amp;#8220;third-party&amp;#8221; API type visibility to your application:&lt;/p&gt; &lt;pre&gt;&amp;#60;application name="MyGraphQLApp" location="MyGraphQLApp.war"&amp;#62; &amp;#60;classloader apiTypeVisibility="+third-party"/&amp;#62; &amp;#60;/application&amp;#62; &lt;/pre&gt; &lt;p&gt;This update lets you access SmallRye GraphQL APIs like the type-safe client. Note that these APIs might change in future releases because SmallRye is continuously evolving. For more information, please visit &lt;a target="_blank" rel="nofollow" href="https://github.com/smallrye/smallrye-graphql"&gt;SmallRye GraphQL project&lt;/a&gt;. For Open Liberty 20.0.0.9, we are using SmallRye GraphQL 1.0.7.&lt;/p&gt; &lt;h3&gt;Type-safe invocation for remote methods&lt;/h3&gt; &lt;p&gt;The SmallRye GraphQL client APIs are very similar to &lt;a href="https://developers.redhat.com/cheat-sheets/microprofile-rest-client"&gt;MicroProfile Rest Client&lt;/a&gt;, which uses an interface to invoke remote methods in a type-safe manner. For example, suppose we want a client that can invoke a query of all of the superheroes in a given location. We would create a query interface like this:&lt;/p&gt; &lt;pre&gt;@GraphQlClientApi interface SuperHeroesApi { List allHeroesIn(String location); } &lt;/pre&gt; &lt;p&gt;Where &lt;code&gt;SuperHero&lt;/code&gt; on the client-side looks like this:&lt;/p&gt; &lt;pre&gt;class SuperHero { private String name; private List superPowers; } &lt;/pre&gt; &lt;p&gt;The &lt;code&gt;SuperHero&lt;/code&gt; entity might contain dozens of fields on the server-side, but if we&amp;#8217;re only interested in the hero&amp;#8217;s name and superpowers, then we only need those two fields in our client-side class. Now, we can invoke the query with code like this:&lt;/p&gt; &lt;pre&gt;SuperHeroesApi api = GraphQlClientBuilder.newBuilder().build(SuperHeroesApi.class); List heroesOfNewYork = api.allHeroesIn("NYC"); &lt;/pre&gt; &lt;p&gt;Remember that this client API is not official, but the official MicroProfile GraphQL 1.1 API will be based on it. Think of this as a preview.&lt;/p&gt; &lt;h2 id="GraphiQL"&gt;Use the built-in GraphiQL UI for faster queries and mutations&lt;/h2&gt; &lt;p&gt;Open Liberty now sports a built-in &lt;a target="_blank" rel="nofollow" href="https://github.com/graphql/graphiql/blob/main/packages/graphiql/README.md"&gt;GraphiQL&lt;/a&gt; user interface as shown in Figure 1. The new, web-based UI allows you to write and execute GraphQL queries and mutations in real-time with advanced editing features like command completion, query history, schema introspection, and so on.&lt;/p&gt; &lt;div id="attachment_786817" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2020/09/Screenshot-2020-09-22-at-10.50.00.png"&gt;&lt;img aria-describedby="caption-attachment-786817" class="wp-image-786817 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2020/09/Screenshot-2020-09-22-at-10.50.00-1024x391.png" alt="Web UI open to edit a query, with hover-over text displayed." width="640" height="244" srcset="https://developers.redhat.com/blog/wp-content/uploads/2020/09/Screenshot-2020-09-22-at-10.50.00-1024x391.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/Screenshot-2020-09-22-at-10.50.00-300x115.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2020/09/Screenshot-2020-09-22-at-10.50.00-768x293.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-786817" class="wp-caption-text"&gt;Figure 1: Work faster with the GraphiQL web UI.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;To enable the UI, you must first &lt;a target="_blank" rel="nofollow" href="https://openliberty.io/blog/2020/06/10/microprofile-graphql-open-liberty.html"&gt;write and deploy a MicroProfile GraphQL application&lt;/a&gt;. Then add this line to your &lt;code&gt;server.xml&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;&amp;#60;variable name="io.openliberty.enableGraphQLUI" value="true" /&amp;#62; &lt;/pre&gt; &lt;p&gt;You can use a web browser to access the UI, by merely opening your GraphQL application&amp;#8217;s context root and adding &lt;code&gt;/graphql-ui&lt;/code&gt;. As an example, suppose that we use the default port (9080) and our application is named&lt;code&gt;myGraphQLApp&lt;/code&gt;. In that case, we would access the UI at &lt;code&gt;http://localhost:9080/myGraphQLApp/graphql-ui&lt;/code&gt;.&lt;/p&gt; &lt;p&gt;This workaround was &lt;a target="_blank" rel="nofollow" href="https://github.com/OpenLiberty/open-liberty/issues/13201"&gt;resolved in issue #13201&lt;/a&gt;.&lt;/p&gt; &lt;h2 id="feedback"&gt;We want your feedback&lt;/h2&gt; &lt;p&gt;As an open source team, we love receiving feedback from Open Liberty users. A recent example is this comment, taken from Open Liberty &lt;a target="_blank" rel="nofollow" href="https://github.com/OpenLiberty/open-liberty/issues/13036"&gt;#13036&lt;/a&gt;): &amp;#8220;Hello, I am using microprofile-graphql on openliberty and everything goes well except for the exception whitelisting mechanism via microprofile config &amp;#8230;&amp;#8221;&lt;/p&gt; &lt;p&gt;Our MicroProfile GraphQL feature has only been generally available for a few months, so it&amp;#8217;s great to know that users are adopting it. We&amp;#8217;re also excited that some of you are already exploring the &amp;#8220;dark corners&amp;#8221; of exception handling and similar features.&lt;/p&gt; &lt;p&gt;While we dislike discovering that we let a bug slip through the cracks, we&amp;#8217;re eager to fix them when they do. If you find an issue or want to suggest an enhancement that would make your experience with Open Liberty better, please let us know. You can always reach us by &lt;a target="_blank" rel="nofollow" href="https://github.com/OpenLiberty/open-liberty/issues"&gt;opening an issue on GitHub&lt;/a&gt; or contacting us on Twitter at &lt;a target="_blank" rel="nofollow" href="https://twitter.com/OpenLibertyIO"&gt;@OpenLibertyIO&lt;/a&gt;. We&amp;#8217;re also available to chat online using &lt;a target="_blank" rel="nofollow" href="https://gitter.im/OpenLiberty/help"&gt;Gitter&lt;/a&gt; and on the &lt;a target="_blank" rel="nofollow" href="https://gitter.im/OpenLiberty/developer-experience"&gt;Open Liberty Developer Experience&lt;/a&gt; page.&lt;/p&gt; &lt;h2&gt;Try Open Liberty 20.0.0.8 in Red Hat Runtimes now&lt;/h2&gt; &lt;p&gt;Open Liberty is part of the Red Hat Runtimes offering and is available to &lt;a target="_blank" rel="nofollow" href="https://access.redhat.com/products/red-hat-runtimes"&gt;Red Hat Runtimes subscribers&lt;/a&gt;. To learn more about deploying Open Liberty applications to &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift&lt;/a&gt;, see our &lt;i&gt;&lt;a href="https://openliberty.io/guides/cloud-openshift.html" target="_blank" rel="nofollow noopener noreferrer"&gt;Open Liberty guide: Deploying microservices to OpenShift&lt;/a&gt;&lt;/i&gt;.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F09%2F29%2Fquicker-easier-graphql-queries-with-open-liberty-20-0-0-9%2F&amp;#38;linkname=Quicker%2C%20easier%20GraphQL%20queries%20with%20Open%20Liberty%2020.0.0.9" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F09%2F29%2Fquicker-easier-graphql-queries-with-open-liberty-20-0-0-9%2F&amp;#38;linkname=Quicker%2C%20easier%20GraphQL%20queries%20with%20Open%20Liberty%2020.0.0.9" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F09%2F29%2Fquicker-easier-graphql-queries-with-open-liberty-20-0-0-9%2F&amp;#38;linkname=Quicker%2C%20easier%20GraphQL%20queries%20with%20Open%20Liberty%2020.0.0.9" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F09%2F29%2Fquicker-easier-graphql-queries-with-open-liberty-20-0-0-9%2F&amp;#38;linkname=Quicker%2C%20easier%20GraphQL%20queries%20with%20Open%20Liberty%2020.0.0.9" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F09%2F29%2Fquicker-easier-graphql-queries-with-open-liberty-20-0-0-9%2F&amp;#38;linkname=Quicker%2C%20easier%20GraphQL%20queries%20with%20Open%20Liberty%2020.0.0.9" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F09%2F29%2Fquicker-easier-graphql-queries-with-open-liberty-20-0-0-9%2F&amp;#38;linkname=Quicker%2C%20easier%20GraphQL%20queries%20with%20Open%20Liberty%2020.0.0.9" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F09%2F29%2Fquicker-easier-graphql-queries-with-open-liberty-20-0-0-9%2F&amp;#38;linkname=Quicker%2C%20easier%20GraphQL%20queries%20with%20Open%20Liberty%2020.0.0.9" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F09%2F29%2Fquicker-easier-graphql-queries-with-open-liberty-20-0-0-9%2F&amp;#038;title=Quicker%2C%20easier%20GraphQL%20queries%20with%20Open%20Liberty%2020.0.0.9" data-a2a-url="https://developers.redhat.com/blog/2020/09/29/quicker-easier-graphql-queries-with-open-liberty-20-0-0-9/" data-a2a-title="Quicker, easier GraphQL queries with Open Liberty 20.0.0.9"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/09/29/quicker-easier-graphql-queries-with-open-liberty-20-0-0-9/"&gt;Quicker, easier GraphQL queries with Open Liberty 20.0.0.9&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/CeJhWusLdiQ" height="1" width="1" alt=""/&gt;</content><summary>Open Liberty 20.0.0.9 lets developers experiment with the type-safe SmallRye GraphQL Client API, and write and run GraphQL queries and mutations more easily with a built-in GraphiQL user interface (UI). This article introduces the new features and updates in Open Liberty 20.0.0.9: Experiment with a third-party GraphQL client API. Use the built-in GraphiQL UI for faster queries and mutations. Give ...</summary><dc:creator>Jakub Pomykala</dc:creator><dc:date>2020-09-29T07:00:48Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/09/29/quicker-easier-graphql-queries-with-open-liberty-20-0-0-9/</feedburner:origLink></entry><entry><title>Call an existing REST service with Apache Camel K</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/TdDN8vPz2vY/" /><category term="application integration" scheme="searchisko:content:tags" /><category term="Camel K" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="Java" scheme="searchisko:content:tags" /><category term="jitpack" scheme="searchisko:content:tags" /><category term="Kubernetes" scheme="searchisko:content:tags" /><category term="OpenAPI" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><category term="operator" scheme="searchisko:content:tags" /><category term="serverless" scheme="searchisko:content:tags" /><author><name>Mary Cochran</name></author><id>searchisko:content:id:jbossorg_blog-call_an_existing_rest_service_with_apache_camel_k</id><updated>2020-09-28T07:00:41Z</updated><published>2020-09-28T07:00:41Z</published><content type="html">&lt;p&gt;With the &lt;a href="https://developers.redhat.com/blog/2020/06/18/camel-k-1-0-the-serverless-integration-platform-goes-ga/"&gt;release of Apache Camel K&lt;/a&gt;, it is possible to create and deploy integrations with existing applications that are quicker and more lightweight than ever. In many cases, calling an existing REST endpoint is the best way to connect a new system to an existing one. Take the example of a cafe serving coffee. What happens when the cafe wants to allow customers to use a delivery service like GrubHub? You would only need to introduce a single &lt;a href="https://developers.redhat.com/blog/2020/05/12/six-reasons-to-love-camel-k/"&gt;Camel K&lt;/a&gt; integration to connect the cafe and GrubHub systems.&lt;/p&gt; &lt;p&gt;In this article, I will show you how to create a &lt;a href="https://developers.redhat.com/videos/youtube/51x9BewGCYA"&gt;Camel K integration&lt;/a&gt; that calls an existing REST service and uses its existing data format. For the data format, I have a Maven project configured with &lt;a href="https://developers.redhat.com/topics/enterprise-java"&gt;Java&lt;/a&gt; objects. Ideally, you would have this packaged and available in a Nexus repository. For the purpose of my demonstration, I utilized &lt;a target="_blank" rel="nofollow" href="https://jitpack.io/"&gt;JitPack&lt;/a&gt;, which lets me have my dependency available in a repository directly from my GitHub code. See the &lt;a target="_blank" rel="nofollow" href="https://github.com/jeremyrdavis/quarkus-cafe-demo/tree/kamel-1.0.0/grubhub-cafe-core"&gt;GitHub repository associated with this demo&lt;/a&gt; for the data format code and directions for getting it into JitPack.&lt;br /&gt; &lt;span id="more-760597"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Prerequisites&lt;/h2&gt; &lt;p&gt;In order to follow the demonstration, you will need the following installed in your development environment:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;The &lt;code&gt;oc&lt;/code&gt; command-line tools&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/apache/camel-k/releases"&gt;Camel K client 1.0.0&lt;/a&gt;&lt;/li&gt; &lt;li&gt;A &lt;a href="https://developers.redhat.com/products/openshift/overview"&gt;Red Hat OpenShift 4.4 cluster&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;h2&gt;Create the Camel K route&lt;/h2&gt; &lt;p&gt;First, we create the Camel K route file, which I have named &lt;code&gt;RestWithUndertow.java&lt;/code&gt;. Here, we open the file and create the class structure:&lt;/p&gt; &lt;pre&gt;public class RestWithUndertow extends org.apache.camel.builder.RouteBuilder { @Override public void configure() throws Exception { } }&lt;/pre&gt; &lt;p&gt;Next, we create the REST endpoint, and we also create the data formats that we will use. In this case, we&amp;#8217;ll receive the REST request as a &lt;code&gt;GrubHubOrder&lt;/code&gt;. We&amp;#8217;ll then transform it to a &lt;code&gt;CreateOrderCommand&lt;/code&gt;, which we&amp;#8217;ll send to the REST service that is already in use:&lt;/p&gt; &lt;pre&gt;import org.apache.camel.model.rest.RestBindingMode; import com.redhat.quarkus.cafe.domain.CreateOrderCommand; import com.redhat.grubhub.cafe.domain.GrubHubOrder; import org.apache.camel.component.jackson.JacksonDataFormat; public class RestWithUndertow extends org.apache.camel.builder.RouteBuilder { @Override public void configure() throws Exception { JacksonDataFormat df = new JacksonDataFormat(CreateOrderCommand.class); rest() .post("/order").type(GrubHubOrder.class).consumes("application/json") .bindingMode(RestBindingMode.json) .produces("application/json") .to("direct:order"); } } &lt;/pre&gt; &lt;h2&gt;Create the data transformation&lt;/h2&gt; &lt;p&gt;Now we can create a method in the same file, which will assist with the data transformation from the &lt;code&gt;GrubHubOrder&lt;/code&gt; to the &lt;code&gt;CreateOrderCommand&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt; public void transformMessage(Exchange exchange){ Message in = exchange.getIn(); GrubHubOrder gho = in.getBody(GrubHubOrder.class); List oi = gho.getOrderItems(); List list = new ArrayList(); for(GrubHubOrderItem i : oi){ LineItem li = new LineItem(Item.valueOf(i.getOrderItem()),i.getName()); list.add(li); } CreateOrderCommand coc = new CreateOrderCommand(list, null); in.setBody(coc); } &lt;/pre&gt; &lt;p&gt;Make sure that you add the following imports to the file, as well:&lt;/p&gt; &lt;pre&gt;import org.apache.camel.Exchange; import org.apache.camel.Message; import com.redhat.quarkus.cafe.domain.LineItem; import com.redhat.quarkus.cafe.domain.Item; import java.util.List; import java.util.ArrayList; import com.redhat.grubhub.cafe.domain.GrubHubOrderItem; &lt;/pre&gt; &lt;h2&gt;Call the existing service from your Camel K REST endpoint&lt;/h2&gt; &lt;p&gt;Now that we have a method to do the transformation, we can implement the rest of the Camel K REST endpoint and make it call the existing service. Add the following below the code that you have so far:&lt;/p&gt; &lt;pre&gt; from("direct:order") .log("Incoming Body is ${body}") .log("Incoming Body after unmarshal is ${body}") .bean(this,"transformMessage") .log("Outgoing pojo Body is ${body}") .marshal(df) //transforms the java object into json .setHeader(Exchange.HTTP_METHOD, constant("POST")) .setHeader(Exchange.CONTENT_TYPE, constant("application/json")) .setHeader("Accept",constant("application/json")) .log("Body after transformation is ${body} with headers: ${headers}") .to("http://?bridgeEndpoint=true&amp;#38;throwExceptionOnFailure=false") .setHeader(Exchange.HTTP_RESPONSE_CODE,constant(200)) .transform().simple("{Order Placed}"); &lt;/pre&gt; &lt;p&gt;Note that this example includes plenty of logging to give visibility to what is being done. I have set the &lt;code&gt;BridgeEndpoint&lt;/code&gt; option to &lt;code&gt;true&lt;/code&gt;, which allows us to ignore the &lt;code&gt;HTTP_URI&lt;/code&gt; incoming header and use the full URL that we&amp;#8217;ve specified. This is important when taking an incoming REST request that will call a new one. You can read more about &lt;a target="_blank" rel="nofollow" href="https://camel.apache.org/components/latest/http-component.html"&gt;the &lt;code&gt;BridgeEndpoint&lt;/code&gt; option here&lt;/a&gt;.&lt;/p&gt; &lt;h2&gt;Save the route file&lt;/h2&gt; &lt;p&gt;Your complete Camel K route file should look something like this:&lt;/p&gt; &lt;pre&gt;import org.apache.camel.Exchange; import org.apache.camel.Message; import org.apache.camel.model.rest.RestBindingMode; import com.redhat.quarkus.cafe.domain.LineItem; import com.redhat.quarkus.cafe.domain.Item; import java.util.List; import java.util.ArrayList; import com.redhat.quarkus.cafe.domain.CreateOrderCommand; import com.redhat.grubhub.cafe.domain.GrubHubOrder; import com.redhat.grubhub.cafe.domain.GrubHubOrderItem; import org.apache.camel.component.jackson.JacksonDataFormat; public class RestWithUndertow extends org.apache.camel.builder.RouteBuilder { @Override public void configure() throws Exception { JacksonDataFormat df = new JacksonDataFormat(CreateOrderCommand.class); rest() .post("/order").type(GrubHubOrder.class).consumes("application/json") .bindingMode(RestBindingMode.json) .produces("application/json") .to("direct:order"); from("direct:order") .log("Incoming Body is ${body}") .log("Incoming Body after unmarshal is ${body}") .bean(this,"transformMessage") .log("Outgoing pojo Body is ${body}") .marshal(df) .setHeader(Exchange.HTTP_METHOD, constant("POST")) .setHeader(Exchange.CONTENT_TYPE, constant("application/json")) .setHeader("Accept",constant("application/json")) .log("Body after transformation is ${body} with headers: ${headers}") //need to change url after knowing what the cafe-web url will be .to("http://sampleurl.com?bridgeEndpoint=true&amp;#38;throwExceptionOnFailure=false") .setHeader(Exchange.HTTP_RESPONSE_CODE,constant(200)) .transform().simple("{Order Placed}"); } public void transformMessage(Exchange exchange){ Message in = exchange.getIn(); GrubHubOrder gho = in.getBody(GrubHubOrder.class); List oi = gho.getOrderItems(); List list = new ArrayList(); for(GrubHubOrderItem i : oi){ LineItem li = new LineItem(Item.valueOf(i.getOrderItem()),i.getName()); list.add(li); } CreateOrderCommand coc = new CreateOrderCommand(list, null); in.setBody(coc); } }&lt;/pre&gt; &lt;p&gt;Save this file and get ready for the last step.&lt;/p&gt; &lt;h2&gt;Run the integration&lt;/h2&gt; &lt;p&gt;To run your integration, you will need to have the Camel K Operator installed and ensure that it has access to the dependencies in JitPack. Do the following to get your infrastructure ready for the integration:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Log in to OpenShift using the &lt;code&gt;oc&lt;/code&gt; command line.&lt;/li&gt; &lt;li&gt;Install the Camel K Operator via the OpenShift OperatorHub. The default options are fine.&lt;/li&gt; &lt;li&gt;Ensure you have &lt;a target="_blank" rel="nofollow" href="https://camel.apache.org/camel-k/latest/cli/cli.html"&gt;Kamel CLI tooling &lt;/a&gt;&lt;/li&gt; &lt;li&gt;Use the &lt;code&gt;oc&lt;/code&gt; and &lt;code&gt;kamel&lt;/code&gt; tools and the following command to create an integration platform that provides access to JitPack: &lt;pre&gt;kamel install --olm=false --skip-cluster-setup --skip-operator-setup --maven-repository https://jitpack.io@id=jitpack@snapshots &lt;/pre&gt; &lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Once you see that everything is ready in your OpenShift console (you can always enter &lt;code&gt;oc get pods&lt;/code&gt;to check), deploy the integration. Using your Kamel tools again, make sure that you are logged into OpenShift and on the appropriate project, and run the following command:&lt;/p&gt; &lt;pre&gt;kamel run --name=rest-with-undertow --dependency=camel-jackson --dependency=mvn:com.github.jeremyrdavis:quarkus-cafe-demo:1.5-SNAPSHOT --dependency=mvn:com.github.jeremyrdavis.quarkus-cafe-demo:grubhub-cafe-core:1.5-SNAPSHOT --dependency=camel-openapi-java RestWithUndertow.java &lt;/pre&gt; &lt;p&gt;This command ensures that your route starts with all of the appropriate dependencies. See the &lt;a target="_blank" rel="nofollow" href="https://github.com/jeremyrdavis/quarkus-cafe-demo/tree/kamel-1.0.0/camel-k-grub-hub"&gt;GitHub repository for this article&lt;/a&gt; for a complete,  working version of this code and the service that it calls.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;Camel K allows you to develop your integrations quickly and efficiently while keeping your footprint small. Even when you have some dependencies for your integrations you can utilize the Knative technology in Camel K to make your integrations less resource intensive and allow for quicker deployments.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F09%2F28%2Fcall-an-existing-rest-service-with-apache-camel-k%2F&amp;#38;linkname=Call%20an%20existing%20REST%20service%20with%20Apache%20Camel%20K" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F09%2F28%2Fcall-an-existing-rest-service-with-apache-camel-k%2F&amp;#38;linkname=Call%20an%20existing%20REST%20service%20with%20Apache%20Camel%20K" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F09%2F28%2Fcall-an-existing-rest-service-with-apache-camel-k%2F&amp;#38;linkname=Call%20an%20existing%20REST%20service%20with%20Apache%20Camel%20K" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F09%2F28%2Fcall-an-existing-rest-service-with-apache-camel-k%2F&amp;#38;linkname=Call%20an%20existing%20REST%20service%20with%20Apache%20Camel%20K" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F09%2F28%2Fcall-an-existing-rest-service-with-apache-camel-k%2F&amp;#38;linkname=Call%20an%20existing%20REST%20service%20with%20Apache%20Camel%20K" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F09%2F28%2Fcall-an-existing-rest-service-with-apache-camel-k%2F&amp;#38;linkname=Call%20an%20existing%20REST%20service%20with%20Apache%20Camel%20K" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F09%2F28%2Fcall-an-existing-rest-service-with-apache-camel-k%2F&amp;#38;linkname=Call%20an%20existing%20REST%20service%20with%20Apache%20Camel%20K" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2020%2F09%2F28%2Fcall-an-existing-rest-service-with-apache-camel-k%2F&amp;#038;title=Call%20an%20existing%20REST%20service%20with%20Apache%20Camel%20K" data-a2a-url="https://developers.redhat.com/blog/2020/09/28/call-an-existing-rest-service-with-apache-camel-k/" data-a2a-title="Call an existing REST service with Apache Camel K"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2020/09/28/call-an-existing-rest-service-with-apache-camel-k/"&gt;Call an existing REST service with Apache Camel K&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/TdDN8vPz2vY" height="1" width="1" alt=""/&gt;</content><summary>With the release of Apache Camel K, it is possible to create and deploy integrations with existing applications that are quicker and more lightweight than ever. In many cases, calling an existing REST endpoint is the best way to connect a new system to an existing one. Take the example of a cafe serving coffee. What happens when the cafe wants to allow customers to use a delivery service like Grub...</summary><dc:creator>Mary Cochran</dc:creator><dc:date>2020-09-28T07:00:41Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2020/09/28/call-an-existing-rest-service-with-apache-camel-k/</feedburner:origLink></entry></feed>
