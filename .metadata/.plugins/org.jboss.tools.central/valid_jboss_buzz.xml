<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" media="screen" href="/~d/styles/atom10full.xsl"?><?xml-stylesheet type="text/css" media="screen" href="http://feeds.feedburner.com/~d/styles/itemcontent.css"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:feedburner="http://rssnamespace.org/feedburner/ext/1.0"><title>JBoss Tools Aggregated Feed</title><link rel="alternate" href="http://tools.jboss.org" /><subtitle>JBoss Tools Aggregated Feed</subtitle><dc:creator>JBoss Tools</dc:creator><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="self" type="application/atom+xml" href="http://feeds.feedburner.com/jbossbuzz" /><feedburner:info uri="jbossbuzz" /><atom10:link xmlns:atom10="http://www.w3.org/2005/Atom" rel="hub" href="http://pubsubhubbub.appspot.com/" /><entry><title>This Week in JBoss, 10th December 2019 - Camel 3, Infinispan 10.1, Keycloak 8... A bucketload of releases!</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/a5ToOBWtoac/this-week-in-jboss-10th-december-2019-camel-3-infinispan-101-keycloak-8-a-bucketload-of-releases" /><category term="AMQ" scheme="searchisko:content:tags" /><category term="Camel" scheme="searchisko:content:tags" /><category term="feed_group_name_global" scheme="searchisko:content:tags" /><category term="feed_name_weeklyeditorial" scheme="searchisko:content:tags" /><category term="infinispan-10" scheme="searchisko:content:tags" /><category term="keycloak" scheme="searchisko:content:tags" /><category term="kogito" scheme="searchisko:content:tags" /><category term="microprofile" scheme="searchisko:content:tags" /><category term="narayana" scheme="searchisko:content:tags" /><category term="Operators" scheme="searchisko:content:tags" /><author><name>Romain Pelisse</name></author><id>searchisko:content:id:jbossorg_blog-this_week_in_jboss_10th_december_2019_camel_3_infinispan_10_1_keycloak_8_a_bucketload_of_releases</id><updated>2019-12-10T14:49:26Z</updated><published>2019-12-10T14:49:26Z</published><content type="html">&lt;!-- [DocumentBodyStart:5ee2f36e-7030-4c29-b663-04f6ff4b06a9] --&gt;&lt;div class="jive-rendered-content"&gt;&lt;p&gt;&lt;em&gt;There've been some noteworthy releases in the last two weeks such as &lt;a class="jive-link-external-small" href="https://infinispan.org/blog/2019/12/09/infinispan-10/" rel="nofollow"&gt;Infinispan 10.1.0.CR1&lt;/a&gt;, &lt;a class="jive-link-external-small" href="https://www.keycloak.org/2019/12/keycloak-801-released.html" rel="nofollow"&gt;Keycloak 8.0.1&lt;/a&gt; and, of course, &lt;a class="jive-link-external-small" href="http://janstey.blogspot.com/2019/11/apache-camel-3-is-out.html" rel="nofollow"&gt;Camel 3.0&lt;/a&gt; !&amp;#160; Just taking a look at all the new cool features coming with those should already keep you busy! But if it&amp;#8217;s not enough, don&amp;#8217;t worry, the rest of the JBoss community has you covered!&lt;/em&gt;&lt;/p&gt;&lt;p&gt;&lt;a href="https://farm1.staticflickr.com/755/22604188601_612696b9a7_b.jpg"&gt;&lt;img alt="" class="image-1 jive-image" src="https://farm1.staticflickr.com/755/22604188601_612696b9a7_b.jpg" style="width: 620px; height: 453px; display: block; margin-left: auto; margin-right: auto;"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;h1&gt;Pimp your tooling&lt;/h1&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;Developers like sysadmins can only accomplish their work properly with the right tooling. What could a developer do nowadays without Github or a decent IDE? Same goes for admin. That&amp;#8217;s why you might be interested to know about a couple of new tools that have been released in the last weeks. The first one is a &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2019/11/25/kogito-tooling-for-friendly-dmn-and-bpmn-visualization-on-github/" rel="nofollow"&gt;Kogito tooling for friendly DMN and BPMN visualization on GitHub &lt;/a&gt;&amp;mdash; if you do anything with BPMN and/or Kogito, you should definitely check it out! We&amp;#8217;ve mentioned IDE as being a crucial tool for the developer, so you&amp;#8217;ll be happy to read about the &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2019/11/21/new-features-in-quarkus-tools-for-visual-studio-code-1-2-0/" rel="nofollow"&gt;New features in Quarkus Tools for Visual Studio Code 1.2.0&lt;/a&gt;!&lt;/p&gt;&lt;p&gt;Beyond tooling, knowledge is also a strong ally of the developer, so maybe checking this &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2019/12/02/new-eclipse-microprofile-book-provides-introduction-to-enterprise-java-microservices/" rel="nofollow"&gt;New Eclipse MicroProfile book provides introduction to enterprise Java microservices&lt;/a&gt; might do you good &lt;span aria-label="Happy" class="emoticon_happy emoticon-inline" style="height:16px;width:16px;"&gt;&lt;/span&gt;. As we are talking theorical matter and concept, you should also take a look at this article on&lt;/p&gt;&lt;p&gt;&lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2019/12/03/testing-in-production-from-devtestoops-to-devtestops/" rel="nofollow"&gt;Testing in production: From DevTestOops to DevTestOps&lt;/a&gt;...&lt;/p&gt;&lt;p&gt;&lt;a href="https://live.staticflickr.com/6193/6074298666_2017626332_b.jpg"&gt;&lt;img alt="" class="image-2 jive-image" src="https://live.staticflickr.com/6193/6074298666_2017626332_b.jpg" style="width: 620px; height: 465px; display: block; margin-left: auto; margin-right: auto;"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;h1&gt;All you ever wanted to know about AMQ Streams (even on OpenShift!)&lt;/h1&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;OK, if you ever wanted to learn anything or everything on the AMQ Streams you are in for a treat. First, you have a nice overview of &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2019/11/21/event-based-microservices-with-red-hat-amq-streams/" rel="nofollow"&gt;Event-based microservices with Red Hat AMQ Streams&lt;/a&gt;&lt;/p&gt;&lt;p&gt;, but if it&amp;#8217;s not enough you have a three parts detailed series on &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2019/12/04/understanding-red-hat-amq-streams-components-for-openshift-and-kubernetes-part-1/" rel="nofollow"&gt;Understanding Red Hat AMQ Streams components for OpenShift and Kubernetes (Part 1) &lt;/a&gt;, &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2019/12/05/understanding-red-hat-amq-streams-components-for-openshift-and-kubernetes-part-2/" rel="nofollow"&gt;Part 2&lt;/a&gt; and &lt;a class="jive-link-external-small" href="https://developers.redhat.com/blog/2019/12/06/understanding-red-hat-amq-streams-components-for-openshift-and-kubernetes-part-3/" rel="nofollow"&gt;Part 3&lt;/a&gt;.&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;&lt;a href="https://farm5.staticflickr.com/4641/38237140825_f078a14863_b.jpg"&gt;&lt;img alt="" class="image-3 jive-image" src="https://farm5.staticflickr.com/4641/38237140825_f078a14863_b.jpg" style="width: 620px; height: 414px; display: block; margin-left: auto; margin-right: auto;"/&gt;&lt;/a&gt;&lt;/p&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;h1&gt;Releases, releases, releases...&lt;/h1&gt;&lt;ul&gt;&lt;li&gt;&lt;a class="jive-link-external-small" href="http://janstey.blogspot.com/2019/11/apache-camel-3-is-out.html" rel="nofollow"&gt;Jon Anstey's Blog: Apache Camel 3 is out!! &lt;/a&gt;&lt;/li&gt;&lt;li&gt;Check out &lt;a class="jive-link-external-small" href="http://www.davsclaus.com/2019/12/apache-camel-3-whats-new-top-10.html" rel="nofollow"&gt;this article&lt;/a&gt; to know more about the main new features&lt;/li&gt;&lt;li&gt;&lt;a class="jive-link-external-small" href="https://infinispan.org/blog/2019/12/09/infinispan-10/" rel="nofollow"&gt;Infinispan 10.1.0.CR1 - Infinispan&lt;/a&gt; along with&lt;ul&gt;&lt;li&gt;&lt;a class="jive-link-external-small" href="https://infinispan.org/blog/2019/11/25/infinispan-operator-1/" rel="nofollow"&gt;Infinispan Operator 1.0.1 - Infinispan&lt;/a&gt; and&lt;/li&gt;&lt;li&gt;&lt;a class="jive-link-external-small" href="https://infinispan.org/blog/2019/12/02/image/" rel="nofollow"&gt;Infinispan's new image - Infinispan&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;/li&gt;&lt;li&gt;&lt;a class="jive-link-external-small" href="http://jbossts.blogspot.com/2019/12/narayana-5101final-released.html" rel="nofollow"&gt;Narayana team blog: Narayana 5.10.1.Final released&lt;/a&gt; &lt;/li&gt;&lt;li&gt;&lt;a class="jive-link-external-small" href="https://www.keycloak.org/2019/12/keycloak-801-released.html" rel="nofollow"&gt;Keycloak - Blog - Keycloak 8.0.1 released&lt;/a&gt;&lt;/li&gt;&lt;/ul&gt;&lt;p style="min-height: 8pt; padding: 0px;"&gt;&amp;#160;&lt;/p&gt;&lt;p&gt;&lt;em&gt;That's all for another edition of the JBoss Editorial, please join us again for more exciting development from the JBoss Communities.&lt;/em&gt;&lt;/p&gt;&lt;/div&gt;&lt;!-- [DocumentBodyEnd:5ee2f36e-7030-4c29-b663-04f6ff4b06a9] --&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/a5ToOBWtoac" height="1" width="1" alt=""/&gt;</content><summary>There've been some noteworthy releases in the last two weeks such as Infinispan 10.1.0.CR1, Keycloak 8.0.1 and, of course, Camel 3.0 !  Just taking a look at all the new cool features coming with those should already keep you busy! But if it’s not enough, don’t worry, the rest of the JBoss community has you covered! Pimp your tooling   Developers like sysadmins can only accomplish their work prope...</summary><dc:creator>Romain Pelisse</dc:creator><dc:date>2019-12-10T14:49:26Z</dc:date><feedburner:origLink>https://developer.jboss.org/blogs/weekly-editorial/2019/12/10/this-week-in-jboss-10th-december-2019-camel-3-infinispan-101-keycloak-8-a-bucketload-of-releases</feedburner:origLink></entry><entry><title>LoRaWAN setup at the EclipseCon IoT playground</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/-e9rSu8APmA/" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="integration" scheme="searchisko:content:tags" /><category term="Internet of Things" scheme="searchisko:content:tags" /><category term="IoT solutions" scheme="searchisko:content:tags" /><category term="LoRaWAN" scheme="searchisko:content:tags" /><category term="Red Hat AMQ" scheme="searchisko:content:tags" /><author><name>Jens Reimann</name></author><id>searchisko:content:id:jbossorg_blog-lorawan_setup_at_the_eclipsecon_iot_playground</id><updated>2019-12-10T08:00:41Z</updated><published>2019-12-10T08:00:41Z</published><content type="html">&lt;p&gt;At the recent &lt;a href="https://www.eclipsecon.org/europe2019" target="_blank" rel="noopener noreferrer"&gt;EclipseCon Europe&lt;/a&gt; in Ludwigsburg, Germany, we had a big dashboard in the IoT playground area showing graphs of the number of WiFi devices, the temperature, and air quality, all transmitted via &lt;a href="https://lora-alliance.org/about-lorawan" target="_blank" rel="noopener noreferrer"&gt;LoRaWAN&lt;/a&gt;. We worked on this project during the community day and kept the setup throughout the conference, where we showed it and played with it even further. This article describes the architecture of the setup and gives pointers to replicate it.&lt;/p&gt; &lt;p&gt;&lt;span id="more-653217"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;The sensors&lt;/h2&gt; &lt;p&gt;We chose this &lt;a href="https://github.com/cyberman54/ESP32-Paxcounter" target="_blank" rel="noopener noreferrer"&gt;PAX Counter&lt;/a&gt; as our sensor device. Based on the ESP32 and LoRaWAN, it allows you to measure the number of unique WiFi clients in the area. The PAX counter, as the name suggests, only counts devices. It doesn&amp;#8217;t track them, and this functionality is exactly what we wanted. Also, you can add extra sensors, and the BME680 air quality sensor is supported right out of the box. While it is great to have open source firmware, having a ready-to-run experience is great as well. Fortunately, this PAX counter gave us both.&lt;/p&gt; &lt;p&gt;&lt;img class=" aligncenter wp-image-653367 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/11/pax-counter-1024x602.jpg" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/pax-counter-1024x602.jpg" alt="Photo of LoRaWAN PAX Counter" width="640" height="376" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/pax-counter-1024x602.jpg 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/pax-counter-300x176.jpg 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/pax-counter-768x452.jpg 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/p&gt; &lt;h2&gt;The cloud side&lt;/h2&gt; &lt;p&gt;To have good LoRa coverage, we deployed two &lt;a href="https://www.thethingsnetwork.org/docs/gateways/thethingsindoor/"&gt;Things Network Indoor&lt;/a&gt; gateways. Those devices are rather cheap and easy to set up, and two of them were fine to cover the whole venue. Our initial goal was to provide the data visualization in a simple Grafana dashboard so that people could get a feeling of what we deployed.&lt;/p&gt; &lt;p&gt;Our back-end architecture made use of Eclipse Hono, the Qpid Dispatch Router, and Apache Kafka, and looked like this:&lt;/p&gt; &lt;p&gt;&lt;img class=" aligncenter wp-image-653237 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/11/IoTPlaygroundOverview-1920px-1024x809.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/IoTPlaygroundOverview-1920px-1024x809.png" alt="Architectural Diagram of the IoT Playground" width="640" height="506" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/IoTPlaygroundOverview-1920px-1024x809.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/IoTPlaygroundOverview-1920px-300x237.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/IoTPlaygroundOverview-1920px-768x607.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/p&gt; &lt;p&gt;Forwarding telemetry data from The Things Network to a Grafana dashboard shouldn&amp;#8217;t require that many components. However, we had a little more in mind than just showing the data on a dashboard.&lt;/p&gt; &lt;h2&gt;Ready for more than LoRaWAN&lt;/h2&gt; &lt;p&gt;We teamed up with people from &lt;a href="https://developers.redhat.com/videos/youtube/GKYROutwJHU/"&gt;Eclipse MicroProfile&lt;/a&gt;, offering a connection to the data stream as well. For that, &lt;a href="https://developers.redhat.com/videos/youtube/CZhOJ_ysIiI/"&gt;Apache Kafka&lt;/a&gt; seemed to be the right choice. Kafka can persist the data stream and allow you to connect to it at a later time, restarting to consume from the beginning while the already existing dashboard would continue to receive data without any change or interruption. We also could add as many users as we liked, consuming the data like all the others.&lt;/p&gt; &lt;p&gt;We didn&amp;#8217;t want to limit ourselves to this single sensor, and only to LoRaWAN or The Things Network. This is where Eclipse Hono comes into play. It has the ability to normalize different IoT protocols, like the LoRaWAN uplink, or MQTT and Sigfox into AMQP 1.0. Using this tool gave us the ability to plug in any other data provider without the rest of the data pipeline noticing.&lt;/p&gt; &lt;h2&gt;Completing the setup&lt;/h2&gt; &lt;p&gt;Of course, there is the issue of data formats. Both Eclipse Hono and Kafka are payload agnostic. Unfortunately, the sensors have their own data format, and InfluxDB has its custom API. Bringing both together isn&amp;#8217;t too difficult, but it&amp;#8217;s simpler when using Apache Camel. A few lines of XML or Java, and you have two running bridges, one forwarding raw IoT data from the EnMasse messaging address to the Kafka topic. The other one, for parsing the payload, and injects it into the InfluxDB.&lt;/p&gt; &lt;p&gt;Why did we decide to parse the payload in the second step? Kafka makes it so easy to store each and every message coming from the IoT layer. The sensors provided more data than we wanted to insert into the time series database. By handling things this way, we still had the raw values available in the Kafka cluster, ready for everyone else to consume them if necessary.&lt;/p&gt; &lt;p&gt;After deploying all of the sensors, it was awesome to see this visualization come to life:&lt;/p&gt; &lt;p&gt;&lt;img class=" aligncenter wp-image-653307 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/11/IoTPlayground-Screenshot-Dashboard-1024x456.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/IoTPlayground-Screenshot-Dashboard-1024x456.png" alt="Devices overview dashboard" width="640" height="285" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/IoTPlayground-Screenshot-Dashboard-1024x456.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/IoTPlayground-Screenshot-Dashboard-300x134.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/IoTPlayground-Screenshot-Dashboard-768x342.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/p&gt; &lt;p&gt;The big dashboard showed each sensor’s information with the number of WiFi devices, the current temperature, and an air quality index. By default, you could see the last three hours.&lt;/p&gt; &lt;h2&gt;Playing with Microprofile&lt;/h2&gt; &lt;p&gt;Of course, it would be great to do something more interesting with the data than just having a nice dashboard. That is what we started to play with during the community day by connecting a &lt;a href="https://quarkus.io/" target="_blank" rel="noopener noreferrer"&gt;Quarkus&lt;/a&gt; application to the Kafka data stream and beginning to process it. Unfortunately, setting up proper TLS and authentication took longer than anticipated, so we ran out of time.&lt;/p&gt; &lt;p&gt;However, that doesn’t stop us from continuing. The repository in the next section will definitely see Quarkus examples related to IoT.&lt;/p&gt; &lt;h2&gt;Try it for yourself&lt;/h2&gt; &lt;p&gt;Deploying this solution was actually rather easy, and it should be easy enough for you to replicate. After all, we reused existing components like EnMasse and Strimzi to deploy Hono and Kafka. Of course, you can do the same with &lt;a href="https://developers.redhat.com/blog/2019/05/14/bringing-iot-to-red-hat-amq-online/"&gt;Red Hat AMQ Online&lt;/a&gt; and &lt;a href="https://access.redhat.com/products/red-hat-amq" target="_blank" rel="noopener noreferrer"&gt;Red Hat AMQ Streams&lt;/a&gt;, as the LoRaWAN adapter is part of Red Hat AMQ Online 1.3&amp;#8217;s IoT tech preview.&lt;/p&gt; &lt;p&gt;You can find the deployment scripts in the GitHub repository &lt;a href="https://github.com/ctron/ece2019-iot-playground/" target="_blank" rel="noopener noreferrer"&gt;ctron/ece2019-iot-playground&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F10%2Florawan-setup-at-the-eclipsecon-iot-playground%2F&amp;#38;linkname=LoRaWAN%20setup%20at%20the%20EclipseCon%20IoT%20playground" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F10%2Florawan-setup-at-the-eclipsecon-iot-playground%2F&amp;#38;linkname=LoRaWAN%20setup%20at%20the%20EclipseCon%20IoT%20playground" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F10%2Florawan-setup-at-the-eclipsecon-iot-playground%2F&amp;#38;linkname=LoRaWAN%20setup%20at%20the%20EclipseCon%20IoT%20playground" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F10%2Florawan-setup-at-the-eclipsecon-iot-playground%2F&amp;#38;linkname=LoRaWAN%20setup%20at%20the%20EclipseCon%20IoT%20playground" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F10%2Florawan-setup-at-the-eclipsecon-iot-playground%2F&amp;#38;linkname=LoRaWAN%20setup%20at%20the%20EclipseCon%20IoT%20playground" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F10%2Florawan-setup-at-the-eclipsecon-iot-playground%2F&amp;#38;linkname=LoRaWAN%20setup%20at%20the%20EclipseCon%20IoT%20playground" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F10%2Florawan-setup-at-the-eclipsecon-iot-playground%2F&amp;#38;linkname=LoRaWAN%20setup%20at%20the%20EclipseCon%20IoT%20playground" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F10%2Florawan-setup-at-the-eclipsecon-iot-playground%2F&amp;#038;title=LoRaWAN%20setup%20at%20the%20EclipseCon%20IoT%20playground" data-a2a-url="https://developers.redhat.com/blog/2019/12/10/lorawan-setup-at-the-eclipsecon-iot-playground/" data-a2a-title="LoRaWAN setup at the EclipseCon IoT playground"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/12/10/lorawan-setup-at-the-eclipsecon-iot-playground/"&gt;LoRaWAN setup at the EclipseCon IoT playground&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/-e9rSu8APmA" height="1" width="1" alt=""/&gt;</content><summary>At the recent EclipseCon Europe in Ludwigsburg, Germany, we had a big dashboard in the IoT playground area showing graphs of the number of WiFi devices, the temperature, and air quality, all transmitted via LoRaWAN. We worked on this project during the community day and kept the setup throughout the conference, where we showed it and played with it even further. This article describes the architec...</summary><dc:creator>Jens Reimann</dc:creator><dc:date>2019-12-10T08:00:41Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/12/10/lorawan-setup-at-the-eclipsecon-iot-playground/</feedburner:origLink></entry><entry><title>Infinispan 10.1.0.CR1</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/-pmfPi_HXVs/" /><category term="feed_group_name_infinispan" scheme="searchisko:content:tags" /><category term="feed_name_infinispan" scheme="searchisko:content:tags" /><category term="release" scheme="searchisko:content:tags" /><category term="release candidate" scheme="searchisko:content:tags" /><author><name>Tristan Tarrant</name></author><id>searchisko:content:id:jbossorg_blog-infinispan_10_1_0_cr1</id><updated>2019-12-09T12:55:22Z</updated><published>2019-12-09T12:00:00Z</published><content type="html">&lt;div id="preamble"&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Dear Infinispan community,&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;as we are closing in on 10.1, we have been working on a lot of polishing and bugfixing.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_server"&gt;&lt;a class="anchor" href="#_server"&gt;&lt;/a&gt;Server&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;The new console has received a lot of improvements,&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;A new welcome page&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;A command-line switch to specify an alternate logging configuration file&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_query"&gt;&lt;a class="anchor" href="#_query"&gt;&lt;/a&gt;Query&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;The query components have been reorganized so that they are more modular.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_monitoring"&gt;&lt;a class="anchor" href="#_monitoring"&gt;&lt;/a&gt;Monitoring&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;The introduction of histogram and timer metrics.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_stores"&gt;&lt;a class="anchor" href="#_stores"&gt;&lt;/a&gt;Stores&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;The REST cache store has been updated to use the v2 RESTful API.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_removals_and_deprecations"&gt;&lt;a class="anchor" href="#_removals_and_deprecations"&gt;&lt;/a&gt;Removals and deprecations&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="ulist"&gt; &lt;ul&gt; &lt;li&gt; &lt;p&gt;The old RESTful API (v1) has been removed&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The Infinispan Lucene Directory has been deprecated.&lt;/p&gt; &lt;/li&gt; &lt;li&gt; &lt;p&gt;The memcached protocol server has been deprecated. If you were relying on this, come and talk to us about working on a binary protocol implementation.&lt;/p&gt; &lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_bug_fixes_clean_ups_and_documentation"&gt;&lt;a class="anchor" href="#_bug_fixes_clean_ups_and_documentation"&gt;&lt;/a&gt;Bug fixes, clean-ups and documentation&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Over 40 issues fixed including a lot of documentation updates. See the &lt;a href=""&gt;full list of changes and fixes&lt;/a&gt;&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt; &lt;div class="sect1"&gt; &lt;h2 id="_get_it_use_it_ask_us"&gt;&lt;a class="anchor" href="#_get_it_use_it_ask_us"&gt;&lt;/a&gt;Get it, Use it, Ask us!&lt;/h2&gt; &lt;div class="sectionbody"&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Please &lt;a href="http://infinispan.org/download/"&gt;download&lt;/a&gt;, &lt;a href="https://issues.jboss.org/projects/ISPN"&gt;report bugs&lt;/a&gt;, &lt;a href="https://infinispan.zulipchat.com/"&gt;chat with us&lt;/a&gt;, ask questions on &lt;a href="https://stackoverflow.com/questions/tagged/?tagnames=infinispan&amp;amp;sort=newest"&gt;StackOverflow&lt;/a&gt;.&lt;/p&gt; &lt;/div&gt; &lt;div class="paragraph"&gt; &lt;p&gt;Infinispan 10.1.0.Final is scheduled for December the 20th.&lt;/p&gt; &lt;/div&gt; &lt;/div&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/-pmfPi_HXVs" height="1" width="1" alt=""/&gt;</content><summary>Dear Infinispan community, as we are closing in on 10.1, we have been working on a lot of polishing and bugfixing. Server The new console has received a lot of improvements, A new welcome page A command-line switch to specify an alternate logging configuration file Query The query components have been reorganized so that they are more modular. Monitoring The introduction of histogram and timer met...</summary><dc:creator>Tristan Tarrant</dc:creator><dc:date>2019-12-09T12:00:00Z</dc:date><feedburner:origLink>http://infinispan.org/blog/2019/12/09/infinispan-10/</feedburner:origLink></entry><entry><title>CodeReady Workspaces devfile, demystified</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/gmuhd6JAhHI/" /><category term="Containers" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="Java" scheme="searchisko:content:tags" /><category term="Kubernetes" scheme="searchisko:content:tags" /><category term="Red Hat CodeReady Workspaces" scheme="searchisko:content:tags" /><author><name>Don Schenck</name></author><id>searchisko:content:id:jbossorg_blog-codeready_workspaces_devfile_demystified</id><updated>2019-12-09T08:00:55Z</updated><published>2019-12-09T08:00:55Z</published><content type="html">&lt;p&gt;With the exciting advent of &lt;a href="https://developers.redhat.com/blog/2019/12/03/red-hat-codeready-workspaces-2-new-tools-to-speed-kubernetes-development/"&gt;CodeReady Workspaces (CRW) 2.0&lt;/a&gt; comes some important changes. Based on the upstream project Eclipse Che 7, CRW brings even more of the &amp;#8220;Infrastructure as Code&amp;#8221; idea to fruition. Workspaces mimic the environment of a PC, an operating system, programming language support, the tools needed, and an editor. The real power comes by defining a workspace using a YAML file—a text file that can be stored and versioned in a source control system such as Git. This file, called &lt;code&gt;devfile.yaml&lt;/code&gt;, is powerful and complex. This article will attempt to demystify the devfile.&lt;/p&gt; &lt;p&gt;&lt;span id="more-640867"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;A Java Maven example&lt;/h2&gt; &lt;p&gt;The following devfile defines a workspace that has &lt;a href="https://developers.redhat.com/developer-tools/java"&gt;Java&lt;/a&gt; language support, includes the Maven build tool, and has two custom commands.&lt;/p&gt; &lt;pre&gt;&lt;img class=" alignnone size-large wp-image-641947 " data-add-featherlight="https://developers.redhat.com/blog/wp-content/uploads/2019/10/donsBlogImage2-727x1024.png" src="https://developers.redhat.com/blog/wp-content/uploads/2019/10/donsBlogImage2-727x1024.png" alt="" width="640" height="901" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/10/donsBlogImage2-727x1024.png 727w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/donsBlogImage2-213x300.png 213w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/donsBlogImage2-768x1082.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/10/donsBlogImage2.png 878w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/pre&gt; &lt;p&gt;Let&amp;#8217;s break this down.&lt;/p&gt; &lt;h2&gt;Section 1: metadata&lt;/h2&gt; &lt;p&gt;This section is required, and in this case &lt;code&gt;name&lt;/code&gt; is specified as the name of this workspace (wksp-javamaven). You also have the option of a name prefix, in which case the system will generate the rest of the name (e.g., &lt;code&gt;generateName: javamaven-&lt;/code&gt;). Using &lt;code&gt;generateName&lt;/code&gt; means a user can have multiple instances of this workspace at the same time. This is an important distinction and one which must be addressed by management.&lt;/p&gt; &lt;h2&gt;Section 2: projects&lt;/h2&gt; &lt;p&gt;This section is optional (but probably a very good idea) and tells the workspace where to find the project that will be included. In this case, we&amp;#8217;re pointing to the master branch of a Git repository located on GitHub. You can specify multiple projects for a workspace, and the type can be a zip file as well. While the name of the project does not need to match the name of the repo it&amp;#8217;s, again, probably a very good idea. If you make them different, well &amp;#8230; then that&amp;#8217;s a create opportunity to add confusion and really mess things up.&lt;/p&gt; &lt;h2&gt;Section 3: attributes&lt;/h2&gt; &lt;p&gt;This part is optional and can pretty much define anything you wish. In this example, it&amp;#8217;s specifying that any values stored in any specified volumes are &lt;em&gt;not&lt;/em&gt; stored. This will likely be the value you&amp;#8217;ll always want. The idea is that, unless you commit your changes to the Git repo, any work done will be lost. Think of it this way: Whereas on your local PC you perform a &lt;em&gt;File &amp;#8211;&amp;#62; Save&lt;/em&gt; command to keep your work, you&amp;#8217;ll instead do &lt;code&gt;git commit&lt;/code&gt;. In &amp;#8220;devfile-speak,&amp;#8221; &lt;code&gt;persistVolumes: false&lt;/code&gt; makes the data ephemeral. This setting, &lt;code&gt;false&lt;/code&gt;, also makes the workspace perform better.&lt;/p&gt; &lt;h2&gt;Section 4: components&lt;/h2&gt; &lt;p&gt;This is the heaviest part of this example, where we specify what bits and pieces make up our workspace.&lt;/p&gt; &lt;p&gt;The first component is a Che Plugin, identified at &lt;code&gt;redhat/java/latest&lt;/code&gt;. You can see the description of this plug on &lt;a href="https://github.com/eclipse/che-plugin-registry/blob/master/v3/plugins/redhat/java/latest/meta.yaml"&gt;this GitHub page&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;The next component is a type &lt;code&gt;dockerimage&lt;/code&gt; that is the maven support for this workspace. Of special note is the setting &lt;code&gt;mountSources: true&lt;/code&gt;, which makes the source code available to the container that is running this image. In this particular case, we want our Maven build to have access to the source code—which makes sense.&lt;/p&gt; &lt;p&gt;The &lt;code&gt;volumes:&lt;/code&gt; setting defines a directory within the container that is available to this workspace. This is used, for example, to give the workspace access to a needed directory that would otherwise be outside the container and blocked by lack of permissions. In other words, if you run a command in a workspace and get an error message because you are denied access to a directory, you can get around that by defining that directory here, in your devfile, that will be created &lt;em&gt;inside your container&lt;/em&gt;.&lt;/p&gt; &lt;p&gt;The remaining settings associated with this component are related to memory limits, security, etc.&lt;/p&gt; &lt;h2&gt;Section 5: apiVersion&lt;/h2&gt; &lt;p&gt;This section is required and is how you specify which API version you are using. This is pretty much boilerplate text.&lt;/p&gt; &lt;h2&gt;Section 6: commands&lt;/h2&gt; &lt;p&gt;This is the fun part. In this section, you can define custom commands that are available to the user. Typically, this is where you&amp;#8217;ll specify command-line commands that can be run from within the IDE rather than dropping to the command line and typing what may be a lengthy command. The properties here will look pretty much self-explanatory. Note that a macro can be used instead of hard-coded value for the project root directory (e.g., &lt;code&gt;${CHE_PROJECTS_ROOT}&lt;/code&gt;).&lt;/p&gt; &lt;h2&gt;Start exploring&lt;/h2&gt; &lt;p&gt;There are many settings and variations of devfiles. If you have the ability, I suggest going into your CRW 2.0 instance and exploring any existing workspaces&amp;#8217; devfiles. Take an existing devfile, clone it, then change it and implement it to see what happens. Like any good developer, make changes until you break things, then gain understanding.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F09%2Fcodeready-workspaces-devfile-demystified%2F&amp;#38;linkname=CodeReady%20Workspaces%20devfile%2C%20demystified" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F09%2Fcodeready-workspaces-devfile-demystified%2F&amp;#38;linkname=CodeReady%20Workspaces%20devfile%2C%20demystified" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F09%2Fcodeready-workspaces-devfile-demystified%2F&amp;#38;linkname=CodeReady%20Workspaces%20devfile%2C%20demystified" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F09%2Fcodeready-workspaces-devfile-demystified%2F&amp;#38;linkname=CodeReady%20Workspaces%20devfile%2C%20demystified" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F09%2Fcodeready-workspaces-devfile-demystified%2F&amp;#38;linkname=CodeReady%20Workspaces%20devfile%2C%20demystified" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F09%2Fcodeready-workspaces-devfile-demystified%2F&amp;#38;linkname=CodeReady%20Workspaces%20devfile%2C%20demystified" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F09%2Fcodeready-workspaces-devfile-demystified%2F&amp;#38;linkname=CodeReady%20Workspaces%20devfile%2C%20demystified" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F09%2Fcodeready-workspaces-devfile-demystified%2F&amp;#038;title=CodeReady%20Workspaces%20devfile%2C%20demystified" data-a2a-url="https://developers.redhat.com/blog/2019/12/09/codeready-workspaces-devfile-demystified/" data-a2a-title="CodeReady Workspaces devfile, demystified"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/12/09/codeready-workspaces-devfile-demystified/"&gt;CodeReady Workspaces devfile, demystified&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/gmuhd6JAhHI" height="1" width="1" alt=""/&gt;</content><summary>With the exciting advent of CodeReady Workspaces (CRW) 2.0 comes some important changes. Based on the upstream project Eclipse Che 7, CRW brings even more of the “Infrastructure as Code” idea to fruition. Workspaces mimic the environment of a PC, an operating system, programming language support, the tools needed, and an editor. The real power comes by defining a workspace using a YAML file—a text...</summary><dc:creator>Don Schenck</dc:creator><dc:date>2019-12-09T08:00:55Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/12/09/codeready-workspaces-devfile-demystified/</feedburner:origLink></entry><entry><title>Building freely distributed containers with Podman and Red Hat UBI</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/7ZiSI5Cg_w8/" /><category term="Containers" scheme="searchisko:content:tags" /><category term="devnation" scheme="searchisko:content:tags" /><category term="events" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="Podman" scheme="searchisko:content:tags" /><category term="Universal Base Images (UBI)" scheme="searchisko:content:tags" /><author><name>Scott McCarty (fatherlinux)</name></author><id>searchisko:content:id:jbossorg_blog-building_freely_distributed_containers_with_podman_and_red_hat_ubi</id><updated>2019-12-09T08:00:31Z</updated><published>2019-12-09T08:00:31Z</published><content type="html">&lt;p&gt;&lt;a href="https://developers.redhat.com/devnation/"&gt;DevNation tech talks&lt;/a&gt; are hosted by the Red Hat technologists who create our products. These sessions include real solutions and code and sample projects to help you get started. In this talk, you’ll learn about building containers with &lt;a href="https://developers.redhat.com/blog/2019/02/21/podman-and-buildah-for-docker-users/"&gt;Podman&lt;/a&gt; and &lt;a href="https://developers.redhat.com/blog/2019/10/09/what-is-red-hat-universal-base-image/"&gt;Red Hat Universal Base Image (UBI)&lt;/a&gt; from &lt;a href="https://developers.redhat.com/blog/author/fatherlinux/"&gt;Scott McCarty&lt;/a&gt; and &lt;a href="https://developers.redhat.com/blog/author/burrsutter/"&gt;Burr Sutter&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;We will cover how to build and run &lt;a href="https://developers.redhat.com/topics/containers/"&gt;container&lt;/a&gt;s based on UBI using just your regular user account—no daemon, no root, no fuss. Finally, we will order the de-resolution of all of our containers with a really cool command. After this talk, you will have new tools at the ready to help you find, run, build, and share container images.&lt;span id="more-657947"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;Watch the entire presentation:&lt;br /&gt; &lt;iframe src="https://www.youtube.com/embed/Qcys7fKSzB0" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"&gt;&lt;span data-mce-type="bookmark" style="display: inline-block; width: 0px; overflow: hidden; line-height: 0;" class="mce_SELRES_start"&gt;﻿&lt;/span&gt;&lt;/iframe&gt;&lt;/p&gt; &lt;h3&gt;Learn more&lt;/h3&gt; &lt;p&gt;&lt;span style="font-weight: 400;"&gt;Join us at an upcoming&lt;/span&gt;&lt;a href="https://developers.redhat.com/events/"&gt; &lt;span style="font-weight: 400;"&gt;developer event&lt;/span&gt;&lt;/a&gt;&lt;span style="font-weight: 400;"&gt;, and see our collection of&lt;/span&gt;&lt;a href="https://developers.redhat.com/devnation/?page=0"&gt; &lt;span style="font-weight: 400;"&gt;past DevNation Live tech talks&lt;/span&gt;&lt;/a&gt;&lt;a href="https://developers.redhat.com/events/"&gt;&lt;span style="font-weight: 400;"&gt;.&lt;/span&gt;&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F09%2Fbuilding-freely-distributed-containers-with-podman-and-red-hat-ubi%2F&amp;#38;linkname=Building%20freely%20distributed%20containers%20with%20Podman%20and%20Red%20Hat%20UBI" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F09%2Fbuilding-freely-distributed-containers-with-podman-and-red-hat-ubi%2F&amp;#38;linkname=Building%20freely%20distributed%20containers%20with%20Podman%20and%20Red%20Hat%20UBI" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F09%2Fbuilding-freely-distributed-containers-with-podman-and-red-hat-ubi%2F&amp;#38;linkname=Building%20freely%20distributed%20containers%20with%20Podman%20and%20Red%20Hat%20UBI" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F09%2Fbuilding-freely-distributed-containers-with-podman-and-red-hat-ubi%2F&amp;#38;linkname=Building%20freely%20distributed%20containers%20with%20Podman%20and%20Red%20Hat%20UBI" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F09%2Fbuilding-freely-distributed-containers-with-podman-and-red-hat-ubi%2F&amp;#38;linkname=Building%20freely%20distributed%20containers%20with%20Podman%20and%20Red%20Hat%20UBI" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F09%2Fbuilding-freely-distributed-containers-with-podman-and-red-hat-ubi%2F&amp;#38;linkname=Building%20freely%20distributed%20containers%20with%20Podman%20and%20Red%20Hat%20UBI" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F09%2Fbuilding-freely-distributed-containers-with-podman-and-red-hat-ubi%2F&amp;#38;linkname=Building%20freely%20distributed%20containers%20with%20Podman%20and%20Red%20Hat%20UBI" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F09%2Fbuilding-freely-distributed-containers-with-podman-and-red-hat-ubi%2F&amp;#038;title=Building%20freely%20distributed%20containers%20with%20Podman%20and%20Red%20Hat%20UBI" data-a2a-url="https://developers.redhat.com/blog/2019/12/09/building-freely-distributed-containers-with-podman-and-red-hat-ubi/" data-a2a-title="Building freely distributed containers with Podman and Red Hat UBI"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/12/09/building-freely-distributed-containers-with-podman-and-red-hat-ubi/"&gt;Building freely distributed containers with Podman and Red Hat UBI&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/7ZiSI5Cg_w8" height="1" width="1" alt=""/&gt;</content><summary>DevNation tech talks are hosted by the Red Hat technologists who create our products. These sessions include real solutions and code and sample projects to help you get started. In this talk, you’ll learn about building containers with Podman and Red Hat Universal Base Image (UBI) from Scott McCarty and Burr Sutter. We will cover how to build and run containers based on UBI using just your regular...</summary><dc:creator>Scott McCarty (fatherlinux)</dc:creator><dc:date>2019-12-09T08:00:31Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/12/09/building-freely-distributed-containers-with-podman-and-red-hat-ubi/</feedburner:origLink></entry><entry><title>Understanding Red Hat AMQ Streams components for OpenShift and Kubernetes: Part 3</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/j3QGjMa_oUQ/" /><category term="Apache Kafka" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="Red Hat AMQ" scheme="searchisko:content:tags" /><category term="Red Hat AMQ Streams" scheme="searchisko:content:tags" /><category term="Red Hat Integration" scheme="searchisko:content:tags" /><category term="Red Hat OpenShift Container Platform" scheme="searchisko:content:tags" /><author><name>Pramod Padmanabhan</name></author><id>searchisko:content:id:jbossorg_blog-understanding_red_hat_amq_streams_components_for_openshift_and_kubernetes_part_3</id><updated>2019-12-06T08:00:14Z</updated><published>2019-12-06T08:00:14Z</published><content type="html">&lt;p&gt;In the previous articles in this series, we first covered the &lt;a href="https://developers.redhat.com/blog/2019/11/20/red-hat-amq-stre…ubernetes-part-1/"&gt;basics of Red Hat AMQ Streams on OpenShift&lt;/a&gt; and then showed &lt;a href="https://developers.redhat.com/blog/2019/11/20/red-hat-amq-stre…ubernetes-part-2/"&gt;how to set up Kafka Connect, a Kafka Bridge, and Kafka Mirror Maker.&lt;/a&gt; Here are a few key points to keep in mind before we proceed:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;AMQ Streams is based on Apache Kafka.&lt;/li&gt; &lt;li&gt;AMQ Streams for the &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_amq/7.5/html/using_amq_streams_on_openshift_container_platform/" target="_blank" rel="noopener noreferrer"&gt;Red Hat OpenShift Container Platform&lt;/a&gt; is based on the Strimzi project.&lt;/li&gt; &lt;li&gt;AMQ Streams on containers has multiple components, such as the Cluster Operator, Entity Operator, Mirror Maker, Kafka connect, and Kafka Bridge.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Now that we have everything set up (or so we think), let&amp;#8217;s look at monitoring and alerting for our new environment.&lt;span id="more-652107"&gt;&lt;/span&gt;&lt;/p&gt; &lt;h2&gt;Kafka Exporter&lt;/h2&gt; &lt;p&gt;A Kafka cluster, by default, does not export all of its metrics. Hence, we need to use Kafka Exporter to collect the cluster&amp;#8217;s broker state, usage, and performance. It is important to have more insight so you can understand if the consumer&amp;#8217;s message consumption is at the same rate as the producer&amp;#8217;s message pushes. If not, this slow consumption behavior could cost the system. Catching these issues as early as possible is recommended.&lt;/p&gt; &lt;p&gt;To set up Kafka Exporter, begin by editing the existing Kafka cluster config, or creating a new one to include the Kafka Exporter. For example:&lt;/p&gt; &lt;pre&gt;apiVersion: kafka.strimzi.io/v1beta1 kind: Kafka metadata: name: simple-cluster spec: kafka: version: 2.3.0 replicas: 5 listeners: plain: {} tls: {} config: offsets.topic.replication.factor: 5 transaction.state.log.replication.factor: 5 transaction.state.log.min.isr: 2 log.message.format.version: "2.3" storage: type: jbod volumes: - id: 0 type: persistent-claim size: 5Gi deleteClaim: false zookeeper: replicas: 3 storage: type: persistent-claim size: 5Gi deleteClaim: false entityOperator: topicOperator: {} userOperator: {} kafkaExporter: {} &lt;/pre&gt; &lt;p&gt;Next, apply the new changes to the existing cluster:&lt;/p&gt; &lt;pre&gt;$ oc apply -f amq-kafka-cluster-kafka-exporter.yml&lt;/pre&gt; &lt;p&gt;You can see the result in Figure 1:&lt;/p&gt; &lt;div id="attachment_653737" style="width: 510px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dccd925de3ef.png"&gt;&lt;img aria-describedby="caption-attachment-653737" class="wp-image-653737" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dccd925de3ef-300x27.png" alt="Kafka Exporter is deployed." width="500" height="45" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dccd925de3ef-300x27.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dccd925de3ef.png 707w" sizes="(max-width: 500px) 100vw, 500px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-653737" class="wp-caption-text"&gt;Figure 1: Your new Kafka Exporter instance.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Prometheus and Grafana&lt;/h2&gt; &lt;p&gt;&lt;a href="https://prometheus.io/docs/introduction/overview/" target="_blank" rel="noopener noreferrer"&gt;Prometheus&lt;/a&gt; is a system monitoring and alerting toolkit that scrapes metrics from the Kafka cluster. The downside of this tool is that it does not have a good GUI. Hence, we create operational dashboards using &lt;a href="https://grafana.com/oss/grafana/" target="_blank" rel="noopener noreferrer"&gt;Grafana&lt;/a&gt; for the interface and Prometheus for the data feeds.&lt;/p&gt; &lt;p&gt;Let&amp;#8217;s get started with the metrics and creating the dashboard:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Add Kafka metrics to the Kafka resource. This snippet was referenced from the &lt;code&gt;examples/metrics/kafka-metrics.yaml&lt;/code&gt; file provided as part of the Red Hat AMQ Streams product:&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;$ oc project amq-streams $ oc edit kafka simple-cluster # Add the below in the spec-&amp;#62;kafka metrics: # Inspired by config from Kafka 2.0.0 example rules: # https://github.com/prometheus/jmx_exporter/blob/master/example_configs/kafka-2_0_0.yml lowercaseOutputName: true rules: # Special cases and very specific rules - pattern : kafka.server&amp;#60;type=(.+), name=(.+), clientId=(.+), topic=(.+), partition=(.*)&amp;#62;&amp;#60;&amp;#62;Value name: kafka_server_$1_$2 type: GAUGE labels: clientId: "$3" topic: "$4" partition: "$5" - pattern : kafka.server&amp;#60;type=(.+), name=(.+), clientId=(.+), brokerHost=(.+), brokerPort=(.+)&amp;#62;&amp;#60;&amp;#62;Value name: kafka_server_$1_$2 type: GAUGE labels: clientId: "$3" broker: "$4:$5" # Some percent metrics use MeanRate attribute # Ex) kafka.server&amp;#60;type=(KafkaRequestHandlerPool), name=(RequestHandlerAvgIdlePercent)&amp;#62;&amp;#60;&amp;#62;MeanRate - pattern: kafka.(\w+)&amp;#60;type=(.+), name=(.+)Percent\w*&amp;#62;&amp;#60;&amp;#62;MeanRate name: kafka_$1_$2_$3_percent type: GAUGE # Generic gauges for percents - pattern: kafka.(\w+)&amp;#60;type=(.+), name=(.+)Percent\w*&amp;#62;&amp;#60;&amp;#62;Value name: kafka_$1_$2_$3_percent type: GAUGE - pattern: kafka.(\w+)&amp;#60;type=(.+), name=(.+)Percent\w*, (.+)=(.+)&amp;#62;&amp;#60;&amp;#62;Value name: kafka_$1_$2_$3_percent type: GAUGE labels: "$4": "$5" # Generic per-second counters with 0-2 key/value pairs - pattern: kafka.(\w+)&amp;#60;type=(.+), name=(.+)PerSec\w*, (.+)=(.+), (.+)=(.+)&amp;#62;&amp;#60;&amp;#62;Count name: kafka_$1_$2_$3_total type: COUNTER labels: "$4": "$5" "$6": "$7" - pattern: kafka.(\w+)&amp;#60;type=(.+), name=(.+)PerSec\w*, (.+)=(.+)&amp;#62;&amp;#60;&amp;#62;Count name: kafka_$1_$2_$3_total type: COUNTER labels: "$4": "$5" - pattern: kafka.(\w+)&amp;#60;type=(.+), name=(.+)PerSec\w*&amp;#62;&amp;#60;&amp;#62;Count name: kafka_$1_$2_$3_total type: COUNTER # Generic gauges with 0-2 key/value pairs - pattern: kafka.(\w+)&amp;#60;type=(.+), name=(.+), (.+)=(.+), (.+)=(.+)&amp;#62;&amp;#60;&amp;#62;Value name: kafka_$1_$2_$3 type: GAUGE labels: "$4": "$5" "$6": "$7" - pattern: kafka.(\w+)&amp;#60;type=(.+), name=(.+), (.+)=(.+)&amp;#62;&amp;#60;&amp;#62;Value name: kafka_$1_$2_$3 type: GAUGE labels: "$4": "$5" - pattern: kafka.(\w+)&amp;#60;type=(.+), name=(.+)&amp;#62;&amp;#60;&amp;#62;Value name: kafka_$1_$2_$3 type: GAUGE # Emulate Prometheus 'Summary' metrics for the exported 'Histogram's. # Note that these are missing the '_sum' metric! - pattern: kafka.(\w+)&amp;#60;type=(.+), name=(.+), (.+)=(.+), (.+)=(.+)&amp;#62;&amp;#60;&amp;#62;Count name: kafka_$1_$2_$3_count type: COUNTER labels: "$4": "$5" "$6": "$7" - pattern: kafka.(\w+)&amp;#60;type=(.+), name=(.+), (.+)=(.*), (.+)=(.+)&amp;#62;&amp;#60;&amp;#62;(\d+)thPercentile name: kafka_$1_$2_$3 type: GAUGE labels: "$4": "$5" "$6": "$7" quantile: "0.$8" - pattern: kafka.(\w+)&amp;#60;type=(.+), name=(.+), (.+)=(.+)&amp;#62;&amp;#60;&amp;#62;Count name: kafka_$1_$2_$3_count type: COUNTER labels: "$4": "$5" - pattern: kafka.(\w+)&amp;#60;type=(.+), name=(.+), (.+)=(.*)&amp;#62;&amp;#60;&amp;#62;(\d+)thPercentile name: kafka_$1_$2_$3 type: GAUGE labels: "$4": "$5" quantile: "0.$6" - pattern: kafka.(\w+)&amp;#60;type=(.+), name=(.+)&amp;#62;&amp;#60;&amp;#62;Count name: kafka_$1_$2_$3_count type: COUNTER - pattern: kafka.(\w+)&amp;#60;type=(.+), name=(.+)&amp;#62;&amp;#60;&amp;#62;(\d+)thPercentile name: kafka_$1_$2_$3 type: GAUGE labels: quantile: "0.$4" &lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;This process will restart the &lt;code&gt;simple-cluster-kafka&lt;/code&gt; pods one by one, as shown in Figure 2:&lt;/p&gt; &lt;div id="attachment_654297" style="width: 510px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcdd6da69fc4.png"&gt;&lt;img aria-describedby="caption-attachment-654297" class="wp-image-654297" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcdd6da69fc4-300x106.png" alt="Restarting the pods." width="500" height="177" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcdd6da69fc4-300x106.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcdd6da69fc4.png 674w" sizes="(max-width: 500px) 100vw, 500px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-654297" class="wp-caption-text"&gt;Figure 2: Restarting the pods.&lt;/p&gt;&lt;/div&gt; &lt;ol start="2"&gt; &lt;li&gt;Confirm you have Prometheus running in the cluster:&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;$ oc get pod -n openshift-monitoring | grep prometheus prometheus-k8s-0 4/4 Running 140 3d prometheus-k8s-1 4/4 Running 140 3d prometheus-operator-687784bd4b-56vsk 1/1 Running 127 3d&lt;/pre&gt; &lt;p&gt;In case the above does not return any Prometheus pods, check with your infrastructure team to know where they are installed. If they are not installed, then check the &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_amq/7.5/html/using_amq_streams_on_openshift/assembly-metrics-setup-str#assembly-metrics-prometheus-str" target="_blank" rel="noopener noreferrer"&gt;Prometheus installation steps from the docs&lt;/a&gt;.&lt;/p&gt; &lt;ol start="3"&gt; &lt;li&gt;Install Grafana:&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;$ oc create -f https://raw.githubusercontent.com/strimzi/strimzi-kafka-operator/master/metrics/examples/grafana/grafana.yaml&lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;You can see the results in Figure 3:&lt;/p&gt; &lt;div id="attachment_654307" style="width: 510px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcde27326144.png"&gt;&lt;img aria-describedby="caption-attachment-654307" class="wp-image-654307" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcde27326144-300x36.png" alt="Graphana is deployed." width="500" height="60" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcde27326144-300x36.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcde27326144.png 704w" sizes="(max-width: 500px) 100vw, 500px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-654307" class="wp-caption-text"&gt;Figure 3: Grafana is now deployed.&lt;/p&gt;&lt;/div&gt; &lt;ol start="4"&gt; &lt;li&gt;Create a route for the Grafana service:&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;$ oc expose svc grafana --name=grafana-route&lt;/pre&gt; &lt;ol start="5"&gt; &lt;li&gt;Log into the admin console (shown in Figure 4):&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;$ oc get route | grep grafana grafana-route grafana-route-amq-streams.apps.redhat.demo.com grafana&lt;/pre&gt; &lt;div id="attachment_654317" style="width: 510px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcde3b42e910.png"&gt;&lt;img aria-describedby="caption-attachment-654317" class="wp-image-654317" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcde3b42e910-300x130.png" alt="The Grafana admin window." width="500" height="216" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcde3b42e910-300x130.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcde3b42e910.png 762w" sizes="(max-width: 500px) 100vw, 500px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-654317" class="wp-caption-text"&gt;Figure 4: The Grafana admin window.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; The default credentials are &lt;code&gt;admin&lt;/code&gt; and &lt;code&gt;admin&lt;/code&gt;.&lt;/p&gt; &lt;p style="padding-left: 40px;"&gt;When you log in for the first time, Grafana will ask you to change the password.&lt;/p&gt; &lt;ol start="6"&gt; &lt;li&gt;Add Prometheus as a data source. Go to the settings icon and select &lt;em&gt;Data Sources&lt;/em&gt;, and then &lt;em&gt;Prometheus,&lt;/em&gt; as shown in Figure 5:&lt;/li&gt; &lt;/ol&gt; &lt;div id="attachment_654337" style="width: 217px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcde684b32dd.png"&gt;&lt;img aria-describedby="caption-attachment-654337" class="wp-image-654337 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcde684b32dd.png" alt="Graphana settings." width="207" height="205" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcde684b32dd.png 207w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcde684b32dd-150x150.png 150w" sizes="(max-width: 207px) 100vw, 207px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-654337" class="wp-caption-text"&gt;Figure 5: The Graphana settings menu.&lt;/p&gt;&lt;/div&gt; &lt;ol start="7"&gt; &lt;li&gt;Enter the Prometheus details and save them:&lt;/li&gt; &lt;/ol&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;URL:&lt;/strong&gt; https://prometheus-k8s.openshift-monitoring.svc:9091&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Basic Auth:&lt;/strong&gt; Enabled&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Skip TLS Verify:&lt;/strong&gt; Enabled&lt;/li&gt; &lt;li&gt;&lt;strong&gt;User:&lt;/strong&gt; Internal&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Pass:&lt;/strong&gt; Get these details from the cluster admin.&lt;/li&gt; &lt;/ul&gt; &lt;p style="padding-left: 40px;"&gt;The message &amp;#8220;Data source is working&amp;#8221; should appear at the bottom before you continue, as shown in Figure 6:&lt;/p&gt; &lt;div id="attachment_654347" style="width: 310px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcdec58e1277.png"&gt;&lt;img aria-describedby="caption-attachment-654347" class="wp-image-654347" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcdec58e1277-253x300.png" alt="Configuring Graphana." width="300" height="356" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcdec58e1277-253x300.png 253w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcdec58e1277.png 766w" sizes="(max-width: 300px) 100vw, 300px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-654347" class="wp-caption-text"&gt;Figure 6: Ready to proceed with the new configuration.&lt;/p&gt;&lt;/div&gt; &lt;ol start="8"&gt; &lt;li&gt;Open the &lt;em&gt;Import&lt;/em&gt; options by selecting &lt;strong&gt;+&lt;/strong&gt; and then &lt;em&gt;Import&lt;/em&gt;, as shown in Figure 7:&lt;/li&gt; &lt;/ol&gt; &lt;div id="attachment_654327" style="width: 229px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcde5947757f.png"&gt;&lt;img aria-describedby="caption-attachment-654327" class="wp-image-654327 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcde5947757f.png" alt="Open the import menu to import a sample dashboard." width="219" height="241" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-654327" class="wp-caption-text"&gt;Figure 7: Select + and then Import to access the Import options dialog box.&lt;/p&gt;&lt;/div&gt; &lt;ol start="9"&gt; &lt;li&gt;Click &lt;em&gt;Upload .json file&lt;/em&gt; to add the&lt;code&gt; strimzi-kafka.json&lt;/code&gt;file from &lt;code&gt;examples/metrics/grafana-dashboards/strimzi-kafka.json&lt;/code&gt;.&lt;/li&gt; &lt;li&gt;Select &lt;em&gt;Prometheus &lt;/em&gt;as a data source and then click &lt;em&gt;Import:&lt;/em&gt;&lt;/li&gt; &lt;/ol&gt; &lt;div id="attachment_654357" style="width: 510px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcded448a351.png"&gt;&lt;img aria-describedby="caption-attachment-654357" class="wp-image-654357" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcded448a351-300x106.png" alt="Importing the sample dashboard." width="500" height="177" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcded448a351-300x106.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcded448a351-768x272.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcded448a351.png 871w" sizes="(max-width: 500px) 100vw, 500px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-654357" class="wp-caption-text"&gt;Figure 8: Importing the sample dashboard.&lt;/p&gt;&lt;/div&gt; &lt;p style="padding-left: 40px;"&gt;Doing this should result in the sample Grafana dashboard.&lt;/p&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;In this article, we explored tools that can help us monitor Red Hat AMQ Streams. This piece fully rounds out our series, where we covered:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2019/11/20/red-hat-amq-stre%E2%80%A6ubernetes-part-1/"&gt;Zookeeper, Kafka, and Entity Operator creation.&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://developers.redhat.com/blog/2019/11/20/red-hat-amq-stre%E2%80%A6ubernetes-part-2/"&gt;Kafka Connect, Kafka Bridge, and Mirror Maker.&lt;/a&gt;&lt;/li&gt; &lt;li&gt;Monitoring and admin (this article).&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Hopefully, you now have a better understanding of how to run AMQ Streams in a container ecosystem. Work through our examples and see the results for yourself.&lt;/p&gt; &lt;h3&gt;References&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://docs.confluent.io/current/connect/index.html" target="_blank" rel="noopener noreferrer"&gt;Kafka Connect documentation&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://access.redhat.com/documentation/en-us/red_hat_amq/7.5/html-single/using_amq_streams_on_openshift/index" target="_blank" rel="noopener noreferrer"&gt;Using AMQ Streams on OpenShift&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://strimzi.io/2019/10/14/improving-prometheus-metrics.html" target="_blank" rel="noopener noreferrer"&gt;Improving Prometheus metrics&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F06%2Funderstanding-red-hat-amq-streams-components-for-openshift-and-kubernetes-part-3%2F&amp;#38;linkname=Understanding%20Red%20Hat%20AMQ%20Streams%20components%20for%20OpenShift%20and%20Kubernetes%3A%20Part%203" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F06%2Funderstanding-red-hat-amq-streams-components-for-openshift-and-kubernetes-part-3%2F&amp;#38;linkname=Understanding%20Red%20Hat%20AMQ%20Streams%20components%20for%20OpenShift%20and%20Kubernetes%3A%20Part%203" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F06%2Funderstanding-red-hat-amq-streams-components-for-openshift-and-kubernetes-part-3%2F&amp;#38;linkname=Understanding%20Red%20Hat%20AMQ%20Streams%20components%20for%20OpenShift%20and%20Kubernetes%3A%20Part%203" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F06%2Funderstanding-red-hat-amq-streams-components-for-openshift-and-kubernetes-part-3%2F&amp;#38;linkname=Understanding%20Red%20Hat%20AMQ%20Streams%20components%20for%20OpenShift%20and%20Kubernetes%3A%20Part%203" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F06%2Funderstanding-red-hat-amq-streams-components-for-openshift-and-kubernetes-part-3%2F&amp;#38;linkname=Understanding%20Red%20Hat%20AMQ%20Streams%20components%20for%20OpenShift%20and%20Kubernetes%3A%20Part%203" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F06%2Funderstanding-red-hat-amq-streams-components-for-openshift-and-kubernetes-part-3%2F&amp;#38;linkname=Understanding%20Red%20Hat%20AMQ%20Streams%20components%20for%20OpenShift%20and%20Kubernetes%3A%20Part%203" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F06%2Funderstanding-red-hat-amq-streams-components-for-openshift-and-kubernetes-part-3%2F&amp;#38;linkname=Understanding%20Red%20Hat%20AMQ%20Streams%20components%20for%20OpenShift%20and%20Kubernetes%3A%20Part%203" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F06%2Funderstanding-red-hat-amq-streams-components-for-openshift-and-kubernetes-part-3%2F&amp;#038;title=Understanding%20Red%20Hat%20AMQ%20Streams%20components%20for%20OpenShift%20and%20Kubernetes%3A%20Part%203" data-a2a-url="https://developers.redhat.com/blog/2019/12/06/understanding-red-hat-amq-streams-components-for-openshift-and-kubernetes-part-3/" data-a2a-title="Understanding Red Hat AMQ Streams components for OpenShift and Kubernetes: Part 3"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/12/06/understanding-red-hat-amq-streams-components-for-openshift-and-kubernetes-part-3/"&gt;Understanding Red Hat AMQ Streams components for OpenShift and Kubernetes: Part 3&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/j3QGjMa_oUQ" height="1" width="1" alt=""/&gt;</content><summary>In the previous articles in this series, we first covered the basics of Red Hat AMQ Streams on OpenShift and then showed how to set up Kafka Connect, a Kafka Bridge, and Kafka Mirror Maker. Here are a few key points to keep in mind before we proceed: AMQ Streams is based on Apache Kafka. AMQ Streams for the Red Hat OpenShift Container Platform is based on the Strimzi project. AMQ Streams on contai...</summary><dc:creator>Pramod Padmanabhan</dc:creator><dc:date>2019-12-06T08:00:14Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/12/06/understanding-red-hat-amq-streams-components-for-openshift-and-kubernetes-part-3/</feedburner:origLink></entry><entry><title>Introduction to the Red Hat OpenShift deployment extension for Microsoft Azure DevOps</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/KOJekK8uNAg/" /><category term="Developer Tools" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="openshift" scheme="searchisko:content:tags" /><category term="OpenShift VSTS extension" scheme="searchisko:content:tags" /><author><name>luca stocchi</name></author><id>searchisko:content:id:jbossorg_blog-introduction_to_the_red_hat_openshift_deployment_extension_for_microsoft_azure_devops</id><updated>2019-12-05T08:00:11Z</updated><published>2019-12-05T08:00:11Z</published><content type="html">&lt;p&gt;We are extremely pleased to present the new version of the &lt;a href="https://developers.redhat.com/openshift/"&gt;Red Hat OpenShift&lt;/a&gt; deployment extension (OpenShift VSTS) 1.4.0 for Microsoft Azure DevOps. This extension enables users to deploy their applications to any OpenShift cluster directly from their Microsoft Azure DevOps account. In this article, we will look at how to install and use this extension as part of a YAML-defined pipeline with both Microsoft-hosted and self-hosted agents.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; The OpenShift VSTS extension can be downloaded directly from the marketplace at this &lt;a href="https://marketplace.visualstudio.com/items?itemName=redhat.openshift-vsts" target="_blank" rel="noopener noreferrer"&gt;link&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;This article offers a demonstration where we explain how easy it is to set up everything and start working with the extension. Look at the &lt;a href="https://github.com/redhat-developer/openshift-vsts/blob/master/docs/getting-started.md" target="_blank" rel="noopener noreferrer"&gt;README file&lt;/a&gt; for further installation and usage information.&lt;span id="more-650877"&gt;&lt;/span&gt;&lt;/p&gt; &lt;p&gt;&lt;iframe src="https://www.youtube.com/embed/RBwpedmkvow" width="560" height="315" frameborder="0" allowfullscreen="allowfullscreen"&gt;&lt;/iframe&gt;&lt;/p&gt; &lt;h2&gt;The benefits&lt;/h2&gt; &lt;p&gt;The new OpenShift VSTS 1.4.0 extension has three major benefits:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;It allows users to use an &lt;code&gt;oc&lt;/code&gt; CLI already installed on their machine when using a local agent.&lt;/li&gt; &lt;li&gt;It supports and automatically downloads &lt;code&gt;oc&lt;/code&gt; versions greater than four.&lt;/li&gt; &lt;li&gt;It changes the way the &lt;code&gt;oc&lt;/code&gt; CLI is downloaded: No more &amp;#8220;API rate limit exceeded&amp;#8221; error from the GitHub REST API.&lt;/li&gt; &lt;/ol&gt; &lt;h2&gt;Installing the OpenShift VSTS extension&lt;/h2&gt; &lt;p&gt;Before to start using the OpenShift VSTS extension, you first need a running OpenShift instance. In our demo video, we use OpenShift Online, which is hosted and managed by Red Hat. You can &lt;a href="https://www.openshift.com/trial/" target="_blank" rel="noopener noreferrer"&gt;sign up here&lt;/a&gt; and start using OpenShift in the cloud for free.&lt;/p&gt; &lt;p&gt;You also need a Microsoft Azure DevOps account. Once you log into this account, you should see a list of your organizations on the left, and all projects related to your organization on the right. If you do not have any projects, it is time to add a new one. To do so, follow these steps:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Clicking on &lt;em&gt;New Project&lt;/em&gt; and fill in the required fields, as shown in Figure 1:&lt;/li&gt; &lt;/ol&gt; &lt;div id="attachment_651117" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-651117" class="wp-image-651117 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/azure-devops-home-1024x409.png" alt="" width="640" height="256" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/azure-devops-home.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/azure-devops-home-300x120.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/azure-devops-home-768x307.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;p id="caption-attachment-651117" class="wp-caption-text"&gt;Figure 1: Creating a new Microsoft Azure DevOps project.&lt;/p&gt;&lt;/div&gt; &lt;ol start="2"&gt; &lt;li&gt;Go to &lt;a href="https://marketplace.visualstudio.com/items?itemName=redhat.openshift-vsts" target="_blank" rel="noopener noreferrer"&gt;https://marketplace.visualstudio.com/items?itemName=redhat.openshift-vsts&lt;/a&gt;.&lt;/li&gt; &lt;li&gt;Click on &lt;em&gt;Get it free.&lt;/em&gt;&lt;/li&gt; &lt;li&gt;Select your Azure DevOps organization and click &lt;em&gt;Install&lt;/em&gt;. Once this process finishes, the OpenShift VSTS extension install is complete, and you can start setting up your account.&lt;/li&gt; &lt;/ol&gt; &lt;h2&gt;Connecting to your OpenShift cluster&lt;/h2&gt; &lt;p&gt;Now, you need to configure the OpenShift service connection, which connects Microsoft Azure DevOps to your OpenShift cluster:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Log into your Azure DevOps project.&lt;/li&gt; &lt;li&gt;Click on &lt;em&gt;Project Settings&lt;/em&gt; (the cogwheel icon) on the page&amp;#8217;s bottom left.&lt;/li&gt; &lt;li&gt;Select &lt;em&gt;Service Connections&lt;/em&gt;.&lt;/li&gt; &lt;li&gt;Click on &lt;em&gt;New service connection&lt;/em&gt; and search for OpenShift.&lt;/li&gt; &lt;li&gt;Pick the authentication method you would like to use (basic, token, or &lt;code&gt;kubeconfig&lt;/code&gt;). See the details for each option in the next few sections.&lt;/li&gt; &lt;li&gt;Insert your own OpenShift cluster data.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Congratulations! You have connected your Azure DevOps account to your OpenShift cluster.&lt;/p&gt; &lt;p&gt;Now, let&amp;#8217;s look at how to set up each authentication method.&lt;/p&gt; &lt;h3&gt;Basic authentication&lt;/h3&gt; &lt;p&gt;When you select &lt;em&gt;Basic Authentication&lt;/em&gt;, use the following information to fill out the dialog:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Connection Name:&lt;/strong&gt; The name you will use to refer to this service connection.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Server URL:&lt;/strong&gt; The OpenShift cluster&amp;#8217;s URL.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Username:&lt;/strong&gt; The OpenShift username for this instance.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Password:&lt;/strong&gt; The password for the specified user.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Accept untrusted SSL certificates:&lt;/strong&gt; Whether it is ok to accept self-signed (untrusted) certificates.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Allow all pipelines to use this connection:&lt;/strong&gt; Allows YAML-defined pipelines to use our service connection (they are not automatically authorized for service connections).&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The result should look similar to Figure 2:&lt;/p&gt; &lt;div id="attachment_651127" style="width: 638px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-651127" class="wp-image-651127 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/basic-authentication-form.png" alt="" width="628" height="457" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/basic-authentication-form.png 628w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/basic-authentication-form-300x218.png 300w" sizes="(max-width: 628px) 100vw, 628px" /&gt;&lt;p id="caption-attachment-651127" class="wp-caption-text"&gt;Figure 2: Using basic authentication with an OpenShift service connection.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Token authentication&lt;/h3&gt; &lt;p&gt;When you select &lt;em&gt;Token Based Authentication&lt;/em&gt;, use the following information to fill out the dialog:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Connection Name:&lt;/strong&gt; The name you will use to refer to this service connection.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Server URL:&lt;/strong&gt; The OpenShift cluster&amp;#8217;s URL.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Accept untrusted SSL certificates:&lt;/strong&gt; Whether it is ok to accept self-signed (untrusted) certificates.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;API Token:&lt;/strong&gt; The API token used for authentication.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Allow all pipelines to use this connection:&lt;/strong&gt; Allows YAML-defined pipelines to use our service connection (they are not automatically authorized for service connections).&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The result should look similar to Figure 3:&lt;/p&gt; &lt;div id="attachment_651187" style="width: 645px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-651187" class="wp-image-651187 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/token-authetication-form.png" alt="" width="635" height="422" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/token-authetication-form.png 635w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/token-authetication-form-300x199.png 300w" sizes="(max-width: 635px) 100vw, 635px" /&gt;&lt;p id="caption-attachment-651187" class="wp-caption-text"&gt;Figure 3: Using token authentication with an OpenShift service connection.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Kubeconfig&lt;/h3&gt; &lt;p&gt;To use &lt;code&gt;kubeconfig&lt;/code&gt;-based authentication, select &lt;em&gt;No Authentication &lt;/em&gt;and use the following information to fill out the dialog:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;&lt;strong&gt;Connection Name:&lt;/strong&gt; The name you will use to refer to this service connection.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Server URL:&lt;/strong&gt; The OpenShift cluster&amp;#8217;s URL.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Kubeconfig:&lt;/strong&gt; The contents of the &lt;code&gt;kubectl&lt;/code&gt; configuration file.&lt;/li&gt; &lt;li&gt;&lt;strong&gt;Allow all pipelines to use this connection:&lt;/strong&gt; Allows YAML-defined pipelines to use our service connection (they are not automatically authorized for service connections).&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;The result should look similar to Figure 4:&lt;/p&gt; &lt;div id="attachment_651177" style="width: 646px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-651177" class="wp-image-651177 size-full" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/kubectl-authentication-form.png" alt="" width="636" height="397" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/kubectl-authentication-form.png 636w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/kubectl-authentication-form-300x187.png 300w" sizes="(max-width: 636px) 100vw, 636px" /&gt;&lt;p id="caption-attachment-651177" class="wp-caption-text"&gt;Figure 4: Using kubeconfig authentication with an OpenShift service connection.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Exploring the extension&lt;/h2&gt; &lt;p&gt;Once the extension can authenticate to the Red Hat OpenShift cluster, you are ready to create your own YAML pipeline, and then perform operations in OpenShift by executing &lt;code&gt;oc&lt;/code&gt; commands directly from Azure DevOps.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; This extension uses the &lt;code&gt;oc&lt;/code&gt; OpenShift client tool to interact with an OpenShift cluster, so a minimal knowledge of this OpenShift CLI tool is required.&lt;/p&gt; &lt;p&gt;The extension offers three different tasks: install and set up &lt;code&gt;oc&lt;/code&gt;, execute a single &lt;code&gt;oc&lt;/code&gt; command, and update the &lt;code&gt;ConfigMap&lt;/code&gt;.&lt;/p&gt; &lt;h3&gt;Install and set up &lt;code&gt;oc&lt;/code&gt;&lt;/h3&gt; &lt;p&gt;This task allows you to install a specific version of the OpenShift CLI (&lt;code&gt;oc&lt;/code&gt;), adds it to your &lt;code&gt;PATH&lt;/code&gt;, and creates a &lt;code&gt;kubeconfig&lt;/code&gt; file for authenticating with the OpenShift cluster. First, we download and set up &lt;code&gt;oc&lt;/code&gt;, and then we execute &lt;code&gt;oc&lt;/code&gt; commands through a script:&lt;/p&gt; &lt;pre&gt;jobs: - job: myjob   displayName: MyJob   pool:     vmImage: 'windows-latest'   steps:   # Install oc so that it can be used within a 'script' or bash 'task'   - task: oc-setup@2     inputs:       openshiftService: 'My Openshift'       version: '3.11.154' # A script task making use of 'oc'   - script: |       oc new-project my-project       oc apply -f ${SYSTEM_DEFAULTWORKINGDIRECTORY}/openshift/config.yaml -n my-project&lt;/pre&gt; &lt;p&gt;The installed &lt;code&gt;oc&lt;/code&gt; binary will match your agent&amp;#8217;s OS.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; It is possible to use variables defined in the agent. As seen in this example, to reference a file in &lt;code&gt;artefact _my_sources&lt;/code&gt;, you can use:&lt;/p&gt; &lt;pre style="padding-left: 40px;"&gt;${SYSTEM_DEFAULTWORKINGDIRECTORY}/_my_sources/my-openshift-config.yaml&lt;/pre&gt; &lt;p&gt;You can use this task as follows in the GUI:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;In &lt;em&gt;Tasks&lt;/em&gt;, click &lt;em&gt;Install and setup oc&lt;/em&gt;. This action opens the dialog shown in Figure 5:&lt;/li&gt; &lt;/ol&gt; &lt;div id="attachment_651167" style="width: 510px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-651167" class="wp-image-651167" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/install-oc-task-300x113.png" alt="" width="500" height="188" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/install-oc-task-300x113.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/install-oc-task-768x289.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/install-oc-task.png 797w" sizes="(max-width: 500px) 100vw, 500px" /&gt;&lt;p id="caption-attachment-651167" class="wp-caption-text"&gt;Figure 5: Installing and setting up oc.&lt;/p&gt;&lt;/div&gt; &lt;ol start="2"&gt; &lt;li&gt;In the &lt;em&gt;OpenShift service connection &lt;/em&gt;drop-down box, select the service connection you just created, which will be used to execute this command.&lt;/li&gt; &lt;li&gt;In the &lt;em&gt;Version of oc to use&lt;/em&gt; text box, add the version of &lt;code&gt;oc&lt;/code&gt; you want to use (e.g., 3.11.154) or a direct URL to an &lt;code&gt;oc&lt;/code&gt; release bundle. (If left blank, the latest stable oc version is used.)&lt;/li&gt; &lt;/ol&gt; &lt;h3&gt;Execute single &lt;code&gt;oc&lt;/code&gt; commands&lt;/h3&gt; &lt;p&gt;This task allows you to execute a single &lt;code&gt;oc&lt;/code&gt; command directly from Azure DevOps:&lt;/p&gt; &lt;pre&gt;jobs: - job: myjob   displayName: MyJob   pool:     name: 'Default'   steps:   - task: oc-cmd@2     inputs:       openshiftService: 'My Openshift'       version: '4.1'       cmd: 'oc new-app https://github.com/lstocchi/nodejs-ex -l name=demoapp'       uselocalOc: true&lt;/pre&gt; &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; Neither the &lt;code&gt;oc-cmd&lt;/code&gt; or &lt;code&gt;config-map&lt;/code&gt; tasks need to forcibly run after the setup task. If the extension does not find a valid &lt;code&gt;oc&lt;/code&gt; CLI during the execution of an &lt;code&gt;oc&lt;/code&gt; command, first it downloads a copy of a new &lt;code&gt;oc&lt;/code&gt;, and then it executes the command.&lt;/p&gt; &lt;p&gt;To use this task in the GUI:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;In &lt;em&gt;Tasks,&lt;/em&gt; select &lt;em&gt;Execute oc command &lt;/em&gt;to pull up the dialog shown in Figure 6:&lt;/li&gt; &lt;/ol&gt; &lt;div id="attachment_651147" style="width: 510px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-651147" class="wp-image-651147" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/execute-oc-task-300x178.png" alt="" width="500" height="297" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/execute-oc-task-300x178.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/execute-oc-task.png 679w" sizes="(max-width: 500px) 100vw, 500px" /&gt;&lt;p id="caption-attachment-651147" class="wp-caption-text"&gt;Figure 6: Fill out this dialog to execute an oc command.&lt;/p&gt;&lt;/div&gt; &lt;ol start="2"&gt; &lt;li&gt;In the &lt;em&gt;OpenShift service connection&lt;/em&gt; drop-down box, select the service connection you just created, which will be used to execute this command.&lt;/li&gt; &lt;li&gt;In the &lt;em&gt;Version of oc to use&lt;/em&gt; text box, add the version of &lt;code&gt;oc&lt;/code&gt; you want to use (e.g., 3.11.154) or a direct URL to an &lt;code&gt;oc&lt;/code&gt; release bundle. (If left blank, the latest stable oc version is used.)&lt;/li&gt; &lt;li&gt;In the &lt;em&gt;Command to run&lt;/em&gt; text box, enter the actual &lt;code&gt;oc&lt;/code&gt; command to run.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; You can directly type the &lt;code&gt;oc&lt;/code&gt; sub-command by omitting &lt;code&gt;oc&lt;/code&gt; from the input (e.g., &lt;code&gt;rollout latest dc/my-app -n production&lt;/code&gt;).&lt;/p&gt; &lt;ol start="5"&gt; &lt;li&gt;Check or un-check the &lt;em&gt;Ignore non success return value&lt;/em&gt; check box, which specifies whether the &lt;code&gt;oc&lt;/code&gt;command&amp;#8217;s non-success return value has to be ignored (e.g., if a task with the command &lt;code&gt;oc create&lt;/code&gt; or &lt;code&gt;oc delete&lt;/code&gt;fails because the resource has already been created or deleted, the pipeline will continue its execution).&lt;/li&gt; &lt;li&gt;Check or un-check the &lt;em&gt;use local oc executable&lt;/em&gt; check box, which specified whether to force the extension to use, if present, the &lt;code&gt;oc&lt;/code&gt; CLI found on the machine containing the agent. &lt;em&gt;If no version is specified&lt;/em&gt;, the extension uses the local &lt;code&gt;oc&lt;/code&gt; CLI no matter what its version is. &lt;em&gt;If a version is specified&lt;/em&gt;, then the extension checks to see if the &lt;code&gt;oc&lt;/code&gt; CLI installed has the same version requested by the user (if not, the correct &lt;code&gt;oc&lt;/code&gt; CLI will be downloaded).&lt;/li&gt; &lt;/ol&gt; &lt;h3&gt;Update a &lt;code&gt;ConfigMap&lt;/code&gt;&lt;/h3&gt; &lt;p&gt;This task allows you to update the properties of a given &lt;code&gt;ConfigMap&lt;/code&gt; using a grid:&lt;/p&gt; &lt;pre&gt;  jobs: - job: myjob   displayName: MyJob   pool:     name: 'Default' - task: config-map@2      inputs:        openshiftService: 'my_openshift_connection'        configMapName: 'my-config'        namespace: 'my-project'        properties: '-my-key1 my-value1 -my-key2 my-value2'&lt;/pre&gt; &lt;p&gt;It includes six configuration options, which you can fill out in the GUI:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;In &lt;em&gt;Tasks&lt;/em&gt;, select &lt;em&gt;Update ConfigMap&lt;/em&gt; to access the dialog shown in Figure 7:&lt;/li&gt; &lt;/ol&gt; &lt;div id="attachment_651137" style="width: 510px" class="wp-caption aligncenter"&gt;&lt;img aria-describedby="caption-attachment-651137" class="wp-image-651137" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/config-map-task-300x249.png" alt="" width="500" height="414" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/config-map-task-300x249.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/config-map-task.png 683w" sizes="(max-width: 500px) 100vw, 500px" /&gt;&lt;p id="caption-attachment-651137" class="wp-caption-text"&gt;Figure 7: Updating a ConfigMap.&lt;/p&gt;&lt;/div&gt; &lt;ol start="2"&gt; &lt;li&gt;In the &lt;em&gt;OpenShift service connection&lt;/em&gt; drop-down box, select the service connection you just created, which will be used to execute this command.&lt;/li&gt; &lt;li&gt;In the &lt;em&gt;Version of oc&lt;/em&gt; text box, add the version of &lt;code&gt;oc&lt;/code&gt; you want to use (e.g., 3.11.154) or a direct URL to an &lt;code&gt;oc&lt;/code&gt; release bundle. (If left blank, the latest stable oc version is used.)&lt;/li&gt; &lt;li&gt;In the &lt;em&gt;Name of the ConfigMap&lt;/em&gt; text box, enter the name of the &lt;code&gt;ConfigMap&lt;/code&gt; to update. (This field is required.)&lt;/li&gt; &lt;li&gt;In the &lt;em&gt;Namespace of ConfigMap&lt;/em&gt; text box, enter the namespace in which to find the &lt;code&gt;ConfigMap&lt;/code&gt;. The current namespace is used if none is specified.&lt;/li&gt; &lt;li&gt;In the &lt;em&gt;ConfigMap Properties&lt;/em&gt; text box, enter the properties to set or update. Only the properties which need creating or updating need to be listed. Space-separated values need to be surrounded by quotes (&amp;#8220;).&lt;/li&gt; &lt;li&gt;Check or un-check the &lt;em&gt;use local oc executable&lt;/em&gt; checkbox, which specified whether to force the extension to use, if present, the &lt;code&gt;oc&lt;/code&gt; CLI found on the machine containing the agent. &lt;em&gt;If no version is specified&lt;/em&gt;, the extension uses the local &lt;code&gt;oc&lt;/code&gt; CLI no matter what its version is. &lt;em&gt;If a version is specified&lt;/em&gt;, then the extension checks to see if the &lt;code&gt;oc&lt;/code&gt; CLI installed has the same version requested by the user (if not, the correct &lt;code&gt;oc&lt;/code&gt; CLI will be downloaded).&lt;/li&gt; &lt;/ol&gt; &lt;h3&gt;Work with OpenShift&lt;/h3&gt; &lt;p&gt;It is finally time to create your YAML pipeline by using the OpenShift VSTS extension. In our example, we have the application &lt;code&gt;nodejs-ex&lt;/code&gt; already running on our OpenShift cluster, and our goal is to create a pipeline to push a new version of our application whenever our GitHub master branch is updated. Here is our task:&lt;/p&gt; &lt;pre&gt;jobs: - job: demo   displayName: MyDemo   pool:     name: 'Default'   steps:   - task: oc-cmd@2     inputs:       openshiftService: 'My Openshift'       cmd: 'oc start-build nodejs-ex --follow'       uselocalOc: true   - task: oc-cmd@2     inputs:       openshiftService: 'My Openshift'       cmd: 'oc status'       uselocalOc: true&lt;/pre&gt; &lt;p&gt;Every time the pipeline is triggered, a new build starts, and our application is pushed to the cluster eventually. It is important to note that because we are using a local agent to run this pipeline (which is on a machine with the &lt;code&gt;oc&lt;/code&gt; CLI already installed, we set the flag &lt;code&gt;uselocalOc&lt;/code&gt; to &lt;code&gt;true&lt;/code&gt; and did not specify any version. The extension will use the &lt;code&gt;oc&lt;/code&gt; CLI that is installed on the machine, whatever its version is.&lt;/p&gt; &lt;p&gt;Next, we check the status of our cluster to see if there are any misconfigured components (services, deployment configs, build configurations, or active deployments).&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; If you want to use a specific &lt;code&gt;oc&lt;/code&gt; version, be sure to type it correctly, otherwise the latest release will be used (e.g., if you type &lt;code&gt;v3.5&lt;/code&gt; as your version input, the extension will download version 3.5.5, because 3.5 does not exist in our repo. Check the &lt;a href="https://github.com/redhat-developer/openshift-vsts/blob/master/README.md" target="_blank" rel="noopener noreferrer"&gt;README&lt;/a&gt; file for more information).&lt;/p&gt; &lt;h2&gt;Wrapping up&lt;/h2&gt; &lt;p&gt;At this point, you should be able to set up your OpenShift VSTS extension and use it to create your own YAML-defined pipeline, then deploy your application to your OpenShift cluster from Azure DevOps. OpenShift VSTS is an open source project, and we welcome contributions and suggestions. Please reach out to us if you have any requests for further deployments, ideas to improve the extension, questions, or if you encounter any issues. Contacting us is simple: &lt;a href="https://github.com/redhat-developer/openshift-vsts" target="_blank" rel="noopener noreferrer"&gt;Open a new issue&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F05%2Fintroduction-to-the-red-hat-openshift-deployment-extension-for-microsoft-azure-devops%2F&amp;#38;linkname=Introduction%20to%20the%20Red%20Hat%20OpenShift%20deployment%20extension%20for%20Microsoft%20Azure%20DevOps" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F05%2Fintroduction-to-the-red-hat-openshift-deployment-extension-for-microsoft-azure-devops%2F&amp;#38;linkname=Introduction%20to%20the%20Red%20Hat%20OpenShift%20deployment%20extension%20for%20Microsoft%20Azure%20DevOps" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F05%2Fintroduction-to-the-red-hat-openshift-deployment-extension-for-microsoft-azure-devops%2F&amp;#38;linkname=Introduction%20to%20the%20Red%20Hat%20OpenShift%20deployment%20extension%20for%20Microsoft%20Azure%20DevOps" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F05%2Fintroduction-to-the-red-hat-openshift-deployment-extension-for-microsoft-azure-devops%2F&amp;#38;linkname=Introduction%20to%20the%20Red%20Hat%20OpenShift%20deployment%20extension%20for%20Microsoft%20Azure%20DevOps" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F05%2Fintroduction-to-the-red-hat-openshift-deployment-extension-for-microsoft-azure-devops%2F&amp;#38;linkname=Introduction%20to%20the%20Red%20Hat%20OpenShift%20deployment%20extension%20for%20Microsoft%20Azure%20DevOps" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F05%2Fintroduction-to-the-red-hat-openshift-deployment-extension-for-microsoft-azure-devops%2F&amp;#38;linkname=Introduction%20to%20the%20Red%20Hat%20OpenShift%20deployment%20extension%20for%20Microsoft%20Azure%20DevOps" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F05%2Fintroduction-to-the-red-hat-openshift-deployment-extension-for-microsoft-azure-devops%2F&amp;#38;linkname=Introduction%20to%20the%20Red%20Hat%20OpenShift%20deployment%20extension%20for%20Microsoft%20Azure%20DevOps" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F05%2Fintroduction-to-the-red-hat-openshift-deployment-extension-for-microsoft-azure-devops%2F&amp;#038;title=Introduction%20to%20the%20Red%20Hat%20OpenShift%20deployment%20extension%20for%20Microsoft%20Azure%20DevOps" data-a2a-url="https://developers.redhat.com/blog/2019/12/05/introduction-to-the-red-hat-openshift-deployment-extension-for-microsoft-azure-devops/" data-a2a-title="Introduction to the Red Hat OpenShift deployment extension for Microsoft Azure DevOps"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/12/05/introduction-to-the-red-hat-openshift-deployment-extension-for-microsoft-azure-devops/"&gt;Introduction to the Red Hat OpenShift deployment extension for Microsoft Azure DevOps&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/KOJekK8uNAg" height="1" width="1" alt=""/&gt;</content><summary>We are extremely pleased to present the new version of the Red Hat OpenShift deployment extension (OpenShift VSTS) 1.4.0 for Microsoft Azure DevOps. This extension enables users to deploy their applications to any OpenShift cluster directly from their Microsoft Azure DevOps account. In this article, we will look at how to install and use this extension as part of a YAML-defined pipeline with both ...</summary><dc:creator>luca stocchi</dc:creator><dc:date>2019-12-05T08:00:11Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/12/05/introduction-to-the-red-hat-openshift-deployment-extension-for-microsoft-azure-devops/</feedburner:origLink></entry><entry><title>Understanding Red Hat AMQ Streams components for OpenShift and Kubernetes: Part 2</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/XV4puC8LLGM/" /><category term="Apache Kafka" scheme="searchisko:content:tags" /><category term="event-driven" scheme="searchisko:content:tags" /><category term="feed_group_name_nonmiddleware" scheme="searchisko:content:tags" /><category term="feed_name_redhat_developer_blog" scheme="searchisko:content:tags" /><category term="Red Hat AMQ" scheme="searchisko:content:tags" /><category term="Red Hat AMQ Streams" scheme="searchisko:content:tags" /><category term="Red Hat OpenShift Container Platform" scheme="searchisko:content:tags" /><category term="Strimzi" scheme="searchisko:content:tags" /><author><name>Pramod Padmanabhan</name></author><id>searchisko:content:id:jbossorg_blog-understanding_red_hat_amq_streams_components_for_openshift_and_kubernetes_part_2</id><updated>2019-12-05T08:00:07Z</updated><published>2019-12-05T08:00:07Z</published><content type="html">&lt;p&gt;&lt;a href="https://developers.redhat.com/blog/2019/11/20/red-hat-amq-stre…ubernetes-part-1/"&gt;In the previous article in this series&lt;/a&gt;, we discussed the basics of &lt;a href="https://access.redhat.com/products/red-hat-amq" target="_blank" rel="noopener noreferrer"&gt;Red Hat AMQ Streams&lt;/a&gt; on &lt;a href="http://developers.redhat.com/openshift/"&gt;Red Hat OpenShift&lt;/a&gt;. Here are a few key points to keep in mind before we proceed:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;AMQ Streams is based on Apache Kafka.&lt;/li&gt; &lt;li&gt;AMQ Streams for the &lt;a href="https://access.redhat.com/documentation/en-us/red_hat_amq/7.5/html/using_amq_streams_on_openshift_container_platform/"&gt;OpenShift Container Platform&lt;/a&gt; is based on the Strimzi project.&lt;/li&gt; &lt;li&gt;AMQ Streams on containers has multiple components, such as the Cluster Operator, Entity Operator, Mirror Maker, Kafka connect, and Kafka Bridge.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Now, let&amp;#8217;s continue on to setting up Kafka Connect, the Kafka Bridge, and Mirror Maker.&lt;/p&gt; &lt;h2&gt;Kafka Connect&lt;/h2&gt; &lt;p&gt;Kafka Connect is mainly used to stream data &lt;em&gt;in&lt;/em&gt; and &lt;em&gt;out&lt;/em&gt; of Kafka clusters; for instance, getting a Twitter feed and then pushing it to the cluster. We need to understand Kafka Connect&amp;#8217;s concepts before continuing:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Connectors define where the data should be copied &lt;em&gt;to&lt;/em&gt; or &lt;em&gt;from&lt;/em&gt;.&lt;/li&gt; &lt;li&gt;Tasks are the actors that actually copy the data.&lt;/li&gt; &lt;li&gt;Workers are used to schedule units of work for &lt;em&gt;connectors&lt;/em&gt; and &lt;em&gt;tasks&lt;/em&gt;.&lt;/li&gt; &lt;li&gt;Converters are used by &lt;em&gt;task units&lt;/em&gt; to change data format.&lt;/li&gt; &lt;li&gt;Transforms are used by &lt;em&gt;connector&lt;/em&gt; units to do simple data adjustments, routing, and chain transformations.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;&lt;strong&gt;Note:&lt;/strong&gt; For more details on the basic concepts, I recommend reading &lt;a href="https://docs.confluent.io/current/connect/concepts.html#connect-concepts" target="_blank" rel="noopener noreferrer"&gt;Kafka Connect Concepts&lt;/a&gt;.&lt;/p&gt; &lt;h3&gt;Creating a simple Kafka Connect instance&lt;/h3&gt; &lt;p&gt;A Kafka Connect instance in OpenShift can be created using two different Kube objects: KafkaConnect and KafkaConnectS2I. By default, Kafka Connect includes two built-in connectors: FileStreamSourceConnector and FileStreamSinkConnector. However, before you build a new connector, first check the &lt;a href="https://www.confluent.io/hub/" target="_blank" rel="noopener noreferrer"&gt;catalog of existing connectors&lt;/a&gt;.&lt;/p&gt; &lt;p&gt;Let us set up a simple Kafka Connect instance and then perform the source and sink operations. Then, we can add a default producer sample app and a consumer sample app. This process will show multiple publishers and multiple consumers, as shown in Figure 1:&lt;/p&gt; &lt;div id="attachment_652237" style="width: 510px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dca1fbebd0d0.png"&gt;&lt;img aria-describedby="caption-attachment-652237" class="wp-image-652237" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dca1fbebd0d0-300x214.png" alt="The structure for our example." width="500" height="357" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dca1fbebd0d0-300x214.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dca1fbebd0d0-768x548.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dca1fbebd0d0.png 943w" sizes="(max-width: 500px) 100vw, 500px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-652237" class="wp-caption-text"&gt;Figure 1: The overall structure for this example.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Begin by creating the Kafka Connect config &lt;code&gt;amq-kafka-connect.yml&lt;/code&gt;. The example file present in &lt;code&gt;examples/kafka-connect/kafka-connect.yml&lt;/code&gt; was used as a reference for this config file:&lt;/p&gt; &lt;pre&gt;apiVersion: kafka.strimzi.io/v1beta1 kind: KafkaConnect metadata: name: simple-connect-cluster spec: version: 2.3.0 replicas: 1 bootstrapServers: simple-cluster-kafka-bootstrap:9093 tls: trustedCertificates: - secretName: simple-cluster-cluster-ca-cert certificate: ca.crt&lt;/pre&gt; &lt;p&gt;Next, execute the YAML:&lt;/p&gt; &lt;pre&gt;$ oc create -f amq-kafka-connect.yml&lt;/pre&gt; &lt;p&gt;You can see the result in Figure 2:&lt;/p&gt; &lt;div id="attachment_652207" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dc9fc4d92849.png"&gt;&lt;img aria-describedby="caption-attachment-652207" class="wp-image-652207 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dc9fc4d92849-1024x115.png" alt="Kafka Connect is is deployed." width="640" height="72" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dc9fc4d92849-1024x115.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dc9fc4d92849-300x34.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dc9fc4d92849-768x87.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dc9fc4d92849.png 1348w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-652207" class="wp-caption-text"&gt;Figure 2: The new deployment is in place.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Preparing to test your new Kafka Connect instance&lt;/h3&gt; &lt;p&gt;Let us set up to test the new instance by doing the following:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Create a new config, which will &lt;em&gt;sink&lt;/em&gt; from the &lt;code&gt;redhat-demo-topics&lt;/code&gt; topic content to the file &lt;code&gt;amq-demo-sink.txt&lt;/code&gt;:&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;$ oc rsh simple-cluster-kafka-0 sh-4.2$ curl -X POST -H "Content-Type: application/json" --data '{"name": "redhat-file-sink-demo", "config": {"connector.class":"FileStreamSinkConnector", "tasks.max":"1", "file":"/tmp/amq-demo-sink.txt", "topic":"redhat-demo-topics", "value.converter.schemas.enable" : "false", "value.converter" : "org.apache.kafka.connect.storage.StringConverter", "value.converter.schemas.enable" : "false", "key.converter" : "org.apache.kafka.connect.storage.StringConverter", "key.converter.schemas.enable" : "false"}}' http://simple-connect-cluster-connect-api.amq-streams.svc:8083/connectors&lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;Here is the output:&lt;/p&gt; &lt;pre&gt;{"name":"redhat-file-sink-demo","config":{"connector.class":"FileStreamSinkConnector","tasks.max":"1","file":"/tmp/amq-demo-sink.txt","topics":"redhat-demo-topics","value.converter.schemas.enable":"false","value.converter":"org.apache.kafka.connect.storage.StringConverter","key.converter":"org.apache.kafka.connect.storage.StringConverter","key.converter.schemas.enable":"false","name":"redhat-file-sink-demo"},"tasks":[],"type":"sink"}&lt;/pre&gt; &lt;ol start="2"&gt; &lt;li&gt;Create a new config that will &lt;em&gt;source&lt;/em&gt; into the &lt;code&gt;redhat-demo-topics&lt;/code&gt; topic content from the file &lt;code&gt;amq-demo-source.txt&lt;/code&gt;:&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;$ oc rsh simple-cluster-kafka-0 sh-4.2$ curl -X POST -H "Content-Type: application/json" --data '{"name": "redhat-file-source-demo", "config": {"connector.class":"FileStreamSourceConnector", "tasks.max":"1", "file":"/tmp/amq-demo-source.txt", "topic":"redhat-demo-topics", "value.converter.schemas.enable" : "false", "value.converter" : "org.apache.kafka.connect.storage.StringConverter", "value.converter.schemas.enable" : "false", "key.converter" : "org.apache.kafka.connect.storage.StringConverter", "key.converter.schemas.enable" : "false"}}' http://simple-connect-cluster-connect-api.amq-streams.svc:8083/connectors&lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;Here is the output:&lt;/p&gt; &lt;pre&gt;{"name":"redhat-file-source-demo","config":{"connector.class":"FileStreamSourceConnector","tasks.max":"1","file":"/tmp/amq-demo-source.txt","topic":"redhat-demo-topics","value.converter.schemas.enable":"false","value.converter":"org.apache.kafka.connect.storage.StringConverter","key.converter":"org.apache.kafka.connect.storage.StringConverter","key.converter.schemas.enable":"false","name":"redhat-file-source-demo"},"tasks":[],"type":"source"}&lt;/pre&gt; &lt;ol start="3"&gt; &lt;li&gt;In a new terminal start the producer sample app:&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;$ oc run kafka-producer -ti --image=registry.redhat.io/amq7/amq-streams-kafka-23:1.3.0 --rm=true --restart=Never -- bin/kafka-console-producer.sh --broker-list simple-cluster-kafka-bootstrap:9092 --topic redhat-demo-topics&lt;/pre&gt; &lt;ol start="4"&gt; &lt;li&gt;In a new terminal start the consumer sample app:&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;$ oc run kafka-consumer -ti --image=registry.redhat.io/amq7/amq-streams-kafka-23:1.3.0 --rm=true --restart=Never -- bin/kafka-console-consumer.sh --bootstrap-server simple-cluster-kafka-bootstrap:9092 --topic redhat-demo-topics --from-beginning&lt;/pre&gt; &lt;h3&gt;Testing your new Kafka Connect instance&lt;/h3&gt; &lt;p&gt;To test your instance, do the following:&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Log into the Kafka Connect pod and watch the &lt;code&gt;/tmp/amq-demo-sink.txt&lt;/code&gt; file:&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;$ oc get po | grep connect simple-connect-cluster-connect-7479b86c7-tmdbp 1/1 Running 0 3h $ oc rsh simple-connect-cluster-connect-7479b86c7-tmdbp sh-4.2$ tail -100f /tmp/amq-demo-sink.txt hello world from pramod&lt;/pre&gt; &lt;p&gt;Here, you can see that the connector has already sunk two messages into the file.&lt;/p&gt; &lt;ol start="2"&gt; &lt;li&gt; Log into the Kafka Connect pod in a different terminal, then add content into &lt;code&gt;/tmp/amq-demo-source.txt&lt;/code&gt;:&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;$ oc rsh simple-connect-cluster-connect-7479b86c7-tmdbp sh-4.2$ echo redhat-is-my-world &amp;#62; /tmp/amq-demo-source.txt&lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;This set of commands writes a message in &lt;code&gt;/tmp/amq-demo-sink.txt&lt;/code&gt;, and also to the consumer sample app. Figure 3 shows the connector source push and sink output:&lt;/p&gt; &lt;div id="attachment_652277" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dca293c7946a.png"&gt;&lt;img aria-describedby="caption-attachment-652277" class="wp-image-652277 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dca293c7946a-1024x270.png" alt="The connector's push and sink output." width="640" height="169" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dca293c7946a-1024x270.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dca293c7946a-300x79.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dca293c7946a-768x203.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dca293c7946a.png 1380w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-652277" class="wp-caption-text"&gt;Figure 3: The connector source pushing the message redhat-is-my-world in the second terminal.&lt;/p&gt;&lt;/div&gt; &lt;p style="padding-left: 40px;"&gt;Figure 4 shows the sample app consuming the message:&lt;/p&gt; &lt;div id="attachment_652297" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dca2a45c034c.png"&gt;&lt;img aria-describedby="caption-attachment-652297" class="wp-image-652297 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dca2a45c034c-1024x83.png" alt="The sample app consuming the message." width="640" height="52" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dca2a45c034c-1024x83.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dca2a45c034c-300x24.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dca2a45c034c-768x62.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-652297" class="wp-caption-text"&gt;Figure 4: The results on the consuming side.&lt;/p&gt;&lt;/div&gt; &lt;ol start="3"&gt; &lt;li&gt;Now, send a message from the producer sample app. Figure 5 shows how this message flows through the system in three parts. From top to bottom, these are the connector sink, the consumer sample app, and then the producer sample app pushing the message &lt;code&gt;kafka connect sample app&lt;/code&gt;:&lt;/li&gt; &lt;/ol&gt; &lt;div id="attachment_652317" style="width: 650px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dca2be40e1d3.png"&gt;&lt;img aria-describedby="caption-attachment-652317" class="wp-image-652317 size-large" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dca2be40e1d3-1024x444.png" alt="The message flowing through each step." width="640" height="278" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dca2be40e1d3-1024x444.png 1024w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dca2be40e1d3-300x130.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dca2be40e1d3-768x333.png 768w" sizes="(max-width: 640px) 100vw, 640px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-652317" class="wp-caption-text"&gt;Figure 5: The message kafka connect sample app passing through each stage.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Kafka Bridge&lt;/h2&gt; &lt;p&gt;The Bridge component helps us connect to the Kafka Cluster using the HTTP or AMQP protocol. In this article, we demo the HTTP usage as shown in Figure 6:&lt;/p&gt; &lt;div id="attachment_652947" style="width: 510px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcb330887257.png"&gt;&lt;img aria-describedby="caption-attachment-652947" class="wp-image-652947" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcb330887257-300x215.png" alt="Our structure including the Kafka Bridge." width="500" height="358" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcb330887257-300x215.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcb330887257-768x549.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcb330887257.png 938w" sizes="(max-width: 500px) 100vw, 500px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-652947" class="wp-caption-text"&gt;Figure 6: How the Kafka Bridge fits in through the HTTP protocol.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Kafka Bridge produces a REST API for the HTTP protocol, through which it provides multiple operations, such as:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Sending messages.&lt;/li&gt; &lt;li&gt;Subscribing to topics.&lt;/li&gt; &lt;li&gt;Receiving messages.&lt;/li&gt; &lt;li&gt;Committing offsets.&lt;/li&gt; &lt;li&gt;Seeking specific positions.&lt;/li&gt; &lt;/ul&gt; &lt;h3&gt;Creating your Kafka Bridge&lt;/h3&gt; &lt;ol&gt; &lt;li&gt;Create the &lt;code&gt;kafka-bridge&lt;/code&gt; config file &lt;code&gt;amq-kafka-bridge.yml&lt;/code&gt;. The example file present in &lt;code&gt;examples/kafka-bridge/kafka-bridge.yaml&lt;/code&gt; was used as a reference for the following config:&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;apiVersion: kafka.strimzi.io/v1alpha1 kind: KafkaBridge metadata: name: simple-bridge spec: replicas: 1 bootstrapServers: simple-cluster-kafka-bootstrap:9092 http: port: 8080&lt;/pre&gt; &lt;ol start="2"&gt; &lt;li&gt;Create the bridge in OCP:&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;$ oc create -f amq-kafka-bridge.yml&lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;You can see the results in Figure 7:&lt;/p&gt; &lt;div id="attachment_652977" style="width: 510px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcb36ae26e05.png"&gt;&lt;img aria-describedby="caption-attachment-652977" class="wp-image-652977" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcb36ae26e05-300x38.png" alt="The Kafka Bridge is deployed." width="500" height="63" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcb36ae26e05-300x38.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcb36ae26e05.png 726w" sizes="(max-width: 500px) 100vw, 500px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-652977" class="wp-caption-text"&gt;Figure 7: Your new Kafka Bridge.&lt;/p&gt;&lt;/div&gt; &lt;ol start="3"&gt; &lt;li&gt;Create a route so that we can access the bridge from outside the cluster:&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;$ oc expose svc simple-bridge-bridge-service --name=simple-bridge-route&lt;/pre&gt; &lt;h3&gt;Testing your HTTP protocol-based Kafka Bridge&lt;/h3&gt; &lt;ol&gt; &lt;li&gt;Create the Kafka topic config &lt;code&gt;amq-kafka-topic.yml&lt;/code&gt; and apply it to the cluster:&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;apiVersion: kafka.strimzi.io/v1beta1 kind: KafkaTopic metadata: name: simple-topic labels: strimzi.io/cluster: simple-cluster spec: partitions: 5 replicas: 1 config: retention.ms: 7200000 segment.bytes: 1073741824 oc create -f amq-kafka-topic.yml&lt;/pre&gt; &lt;ol start="2"&gt; &lt;li&gt;Get the route URL for the bridge endpoints:&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;#get the route to do the curl command oc get route NAME HOST/PORT PATH SERVICES PORT TERMINATION WILDCARD simple-bridge-route simple-bridge-route-amq-streams.apps.redhat.demo.com simple-bridge-bridge-service rest-api None&lt;/pre&gt; &lt;ol start="3"&gt; &lt;li&gt;Publish a message on &lt;code&gt;simple-topic&lt;/code&gt;:&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;curl -X POST \ http://simple-bridge-route-amq-streams.apps.redhat.demo.com/topics/simple-topic \ -H 'content-type: application/vnd.kafka.json.v2+json' \ -d '{ "records": [ { "value": "all hail the shadowman" } ] }'&lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;Here is the output:&lt;/p&gt; &lt;pre&gt;{"offsets":[{"partition":0,"offset":0}]}&lt;/pre&gt; &lt;ol start="4"&gt; &lt;li&gt;Create the consumer group &lt;code&gt;simple-rh-bridge-consumer-group&lt;/code&gt; and the instance &lt;code&gt;simple-rh-bridge-consumer&lt;/code&gt;. For this task, we set the message format to JSON:&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;curl -X POST \ http://simple-bridge-route-amq-streams.apps.redhat.demo.com/consumers/simple-rh-bridge-consumer-group \ -H 'content-type: application/vnd.kafka.v2+json' \ -d '{ "name": "simple-rh-bridge-consumer", "auto.offset.reset": "earliest", "format": "json", "enable.auto.commit": false, "fetch.min.bytes": 512, "consumer.request.timeout.ms": 30000 }'&lt;/pre&gt; &lt;ol start="5"&gt; &lt;li&gt;Create a subscriber for the &lt;code&gt;simple-topic&lt;/code&gt; created in step one:&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;curl -X POST http://simple-bridge-route-amq-streams.apps.redhat.demo.com/consumers/simple-rh-bridge-consumer-group/instances/simple-rh-bridge-consumer/subscription \ -H 'content-type: application/vnd.kafka.v2+json' \ -d '{ "topics": [ "simple-topic" ] }'&lt;/pre&gt; &lt;ol start="6"&gt; &lt;li&gt;Consume the messages (note that the first request will register and the subsequent calls will provide the array of messages):&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;curl -X GET http://simple-bridge-route-amq-streams.apps.redhat.demo.com/consumers/simple-rh-bridge-consumer-group/instances/simple-rh-bridge-consumer/records \ -H 'accept: application/vnd.kafka.json.v2+json'&lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;Here is the output:&lt;/p&gt; &lt;pre&gt;[] curl -X GET http://simple-bridge-route-amq-streams.apps.redhat.demo.com/consumers/simple-rh-bridge-consumer-group/instances/simple-rh-bridge-consumer/records \ -H 'accept: application/vnd.kafka.json.v2+json'&lt;/pre&gt; &lt;p style="padding-left: 40px;"&gt;And the additional output:&lt;/p&gt; &lt;pre&gt;[{"topic":"simple-topic","key":null,"value":"all hail the shadowman","partition":0,"offset":0}]&lt;/pre&gt; &lt;h2&gt;Mirror Maker&lt;/h2&gt; &lt;p&gt;Kafka Mirror Maker replicates data from one Kafka cluster to another. The usual use case is across different data centers.&lt;/p&gt; &lt;p&gt;For the purpose of this demo, we use two different namespaces and projects, namely &lt;code&gt;amq-streams&lt;/code&gt; and &lt;code&gt;amq-streams-dc2&lt;/code&gt;. Doing so is the same as having multiple data centers with the same names. This setup is shown in Figure 8:&lt;/p&gt; &lt;div id="attachment_653107" style="width: 510px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcb7b940409f.png"&gt;&lt;img aria-describedby="caption-attachment-653107" class="wp-image-653107" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcb7b940409f-300x212.png" alt="Our structure for replicating multiple data centers." width="500" height="354" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcb7b940409f-300x212.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcb7b940409f-768x543.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcb7b940409f.png 942w" sizes="(max-width: 500px) 100vw, 500px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-653107" class="wp-caption-text"&gt;Figure 8: Replicating multiple data centers with Kafka Mirror Maker.&lt;/p&gt;&lt;/div&gt; &lt;p&gt;Kafka Mirror maker consumes from the active Kafka cluster and produces to the mirror (backup) Kafka cluster.&lt;/p&gt; &lt;h3&gt;Setting up for the example&lt;/h3&gt; &lt;p&gt;To demo the Kafka Mirror Maker, we need to create another namespace and Kafka cluster. First, create the new namespace &lt;code&gt;amq-streams-dc2&lt;/code&gt;:&lt;/p&gt; &lt;pre&gt;$ oc new-project amq-streams-dc2&lt;/pre&gt; &lt;p&gt;Next, create a new Kafka cluster:&lt;/p&gt; &lt;pre&gt;$ sed -i 's/namespace: .*/namespace: amq-streams-dc2/' install/cluster-operator/*RoleBinding*.yaml&lt;/pre&gt; &lt;p&gt;On macOS, use the following instead:&lt;/p&gt; &lt;pre&gt;$ sed -i '' 's/namespace: .*/namespace: amq-streams-dc2/' install/cluster-operator/*RoleBinding*.yaml $ oc apply -f install/cluster-operator -n amq-streams-dc2 $ oc apply -f amq-kafka-cluster.yml -n amq-streams-dc2&lt;/pre&gt; &lt;p&gt;You can see the result in Figure 9:&lt;/p&gt; &lt;div id="attachment_653477" style="width: 510px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcc8dd449192.png"&gt;&lt;img aria-describedby="caption-attachment-653477" class="wp-image-653477" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcc8dd449192-300x178.png" alt="All of the components installed so far." width="500" height="296" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcc8dd449192-300x178.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcc8dd449192-768x455.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcc8dd449192.png 941w" sizes="(max-width: 500px) 100vw, 500px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-653477" class="wp-caption-text"&gt;Figure 9: All of the pieces are in place so far.&lt;/p&gt;&lt;/div&gt; &lt;h3&gt;Creating a mirror with Kafka Mirror Maker&lt;/h3&gt; &lt;p&gt;Create a &lt;code&gt;kafka-mirror-maker&lt;/code&gt; config &lt;code&gt;amq-kafka-mirror-maker.yml&lt;/code&gt;. In this file, we increase the consumer stream to two for faster response and use the group ID &lt;code&gt;simple-source-group-id&lt;/code&gt; for the consumer. Additionally, we whitelist all of the topics using wildcards. This example file present in &lt;code&gt;examples/kafka-mirror-maker/kafka-mirror-maker.yaml&lt;/code&gt; was used as a reference for the config:&lt;/p&gt; &lt;div&gt; &lt;div&gt; &lt;pre&gt;apiVersion: kafka.strimzi.io/v1beta1 kind: KafkaMirrorMaker metadata: name: simple-mirror-maker spec: version: 2.3.0 replicas: 1 consumer: bootstrapServers: simple-cluster-kafka-bootstrap:9092 groupId: simple-source-group-id numStreams: 2 producer: bootstrapServers: simple-cluster-kafka-bootstrap.amq-streams-dc2.svc:9092 whitelist: ".*"&lt;/pre&gt; &lt;div&gt;Create the Mirror Maker in the &lt;code&gt;amq-streams&lt;/code&gt; namespace:&lt;/div&gt; &lt;/div&gt; &lt;pre&gt;$ oc create -f amq-kafka-mirror-maker.yml -n amq-streams&lt;/pre&gt; &lt;div&gt; &lt;p&gt;You can see the result in Figure 10:&lt;/p&gt; &lt;div id="attachment_653487" style="width: 510px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcc8df7977ec.png"&gt;&lt;img aria-describedby="caption-attachment-653487" class="wp-image-653487" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcc8df7977ec-300x30.png" alt="Mirror Maker is deployed." width="500" height="50" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcc8df7977ec-300x30.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcc8df7977ec.png 729w" sizes="(max-width: 500px) 100vw, 500px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-653487" class="wp-caption-text"&gt;Figure 10: Your new Mirror Maker instance.&lt;/p&gt;&lt;/div&gt; &lt;/div&gt; &lt;h3&gt;Testing Kafka Mirror Maker&lt;/h3&gt; &lt;p&gt;To test the Mirror Maker, create the following two namespaces: &lt;code&gt;amq-streams&lt;/code&gt; and &lt;code&gt;amq-streams-dc2&lt;/code&gt;. The &lt;code&gt;amq-streams&lt;/code&gt; namespace will contain the producer sample app to produce new messages, and the consumer sample app to consume new messages. The &lt;code&gt;amq-streams-dc2&lt;/code&gt; namespace will contain the consumer sample app so it can consume new messages, so it can show that the messages are getting pushed to the DC2 cluster.&lt;/p&gt; &lt;ol&gt; &lt;li&gt;Create a producer sample app and consumer sample app in the &lt;code&gt;amq-streams&lt;/code&gt; namespace:&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;$ oc project amq-streams $ oc run kafka-producer -ti --image=registry.redhat.io/amq7/amq-streams-kafka-23:1.3.0 --rm=true --restart=Never -- bin/kafka-console-producer.sh --broker-list simple-cluster-kafka-bootstrap:9092 --topic redhat-demo-topics $ oc run kafka-consumer -ti --image=registry.redhat.io/amq7/amq-streams-kafka-23:1.3.0 --rm=true --restart=Never -- bin/kafka-console-consumer.sh --bootstrap-server simple-cluster-kafka-bootstrap:9092 --topic redhat-demo-topics&lt;/pre&gt; &lt;ol start="2"&gt; &lt;li&gt;Create a Consumer sample app in the &lt;code&gt;amq-streams-dc2&lt;/code&gt; namespace&lt;/li&gt; &lt;/ol&gt; &lt;pre&gt;$ oc project amq-streams-dc2 $ oc run kafka-consumer -ti --image=registry.redhat.io/amq7/amq-streams-kafka-23:1.3.0 --rm=true --restart=Never -- bin/kafka-console-consumer.sh --bootstrap-server simple-cluster-kafka-bootstrap:9092 --topic redhat-demo-topics&lt;/pre&gt; &lt;ol start="3"&gt; &lt;li&gt;Send a message from the producer sample app.&lt;/li&gt; &lt;/ol&gt; &lt;p&gt;Is Mirror Maker working? You should see the message in the consumer app in both the namespaces, as shown in Figure 11:&lt;/p&gt; &lt;div id="attachment_653507" style="width: 510px" class="wp-caption aligncenter"&gt;&lt;a href="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcc92af84135.png"&gt;&lt;img aria-describedby="caption-attachment-653507" class="wp-image-653507" src="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcc92af84135-300x144.png" alt="The message flowing through the components." width="500" height="239" srcset="https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcc92af84135-300x144.png 300w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcc92af84135-768x368.png 768w, https://developers.redhat.com/blog/wp-content/uploads/2019/11/img_5dcc92af84135.png 942w" sizes="(max-width: 500px) 100vw, 500px" /&gt;&lt;/a&gt;&lt;p id="caption-attachment-653507" class="wp-caption-text"&gt;Figure 11: Your message flowing from the producer to both the consumer and the backup consumer.&lt;/p&gt;&lt;/div&gt; &lt;h2&gt;Conclusion&lt;/h2&gt; &lt;p&gt;In this article, we explored Red Hat AMQ Streams components like Kafka Connect, Kafka Bridge, and Mirror Maker. In the third and final part of the series, we will cover monitoring and administration.&lt;/p&gt; &lt;h3&gt;References&lt;/h3&gt; &lt;ul&gt; &lt;li&gt;&lt;a href="https://docs.confluent.io/current/connect/index.html" target="_blank" rel="noopener noreferrer"&gt;Kafka Connect&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://access.redhat.com/documentation/en-us/red_hat_amq/7.5/html-single/using_amq_streams_on_openshift/index" target="_blank" rel="noopener noreferrer"&gt;Using AMQ Streams on OpenShift&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://github.com/ppatierno/amqp-kafka-demo" target="_blank" rel="noopener noreferrer"&gt;AMQP Kafka Demo&lt;/a&gt;&lt;/li&gt; &lt;li&gt;&lt;a href="https://strimzi.io/docs/latest/" target="_blank" rel="noopener noreferrer"&gt;Using Strimzi (latest)&lt;/a&gt;&lt;/li&gt; &lt;/ul&gt; &lt;/div&gt; &lt;p&gt;&lt;a class="a2a_button_facebook" href="https://www.addtoany.com/add_to/facebook?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F05%2Funderstanding-red-hat-amq-streams-components-for-openshift-and-kubernetes-part-2%2F&amp;#38;linkname=Understanding%20Red%20Hat%20AMQ%20Streams%20components%20for%20OpenShift%20and%20Kubernetes%3A%20Part%202" title="Facebook" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_twitter" href="https://www.addtoany.com/add_to/twitter?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F05%2Funderstanding-red-hat-amq-streams-components-for-openshift-and-kubernetes-part-2%2F&amp;#38;linkname=Understanding%20Red%20Hat%20AMQ%20Streams%20components%20for%20OpenShift%20and%20Kubernetes%3A%20Part%202" title="Twitter" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_linkedin" href="https://www.addtoany.com/add_to/linkedin?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F05%2Funderstanding-red-hat-amq-streams-components-for-openshift-and-kubernetes-part-2%2F&amp;#38;linkname=Understanding%20Red%20Hat%20AMQ%20Streams%20components%20for%20OpenShift%20and%20Kubernetes%3A%20Part%202" title="LinkedIn" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_email" href="https://www.addtoany.com/add_to/email?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F05%2Funderstanding-red-hat-amq-streams-components-for-openshift-and-kubernetes-part-2%2F&amp;#38;linkname=Understanding%20Red%20Hat%20AMQ%20Streams%20components%20for%20OpenShift%20and%20Kubernetes%3A%20Part%202" title="Email" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_print" href="https://www.addtoany.com/add_to/print?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F05%2Funderstanding-red-hat-amq-streams-components-for-openshift-and-kubernetes-part-2%2F&amp;#38;linkname=Understanding%20Red%20Hat%20AMQ%20Streams%20components%20for%20OpenShift%20and%20Kubernetes%3A%20Part%202" title="Print" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_reddit" href="https://www.addtoany.com/add_to/reddit?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F05%2Funderstanding-red-hat-amq-streams-components-for-openshift-and-kubernetes-part-2%2F&amp;#38;linkname=Understanding%20Red%20Hat%20AMQ%20Streams%20components%20for%20OpenShift%20and%20Kubernetes%3A%20Part%202" title="Reddit" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_button_flipboard" href="https://www.addtoany.com/add_to/flipboard?linkurl=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F05%2Funderstanding-red-hat-amq-streams-components-for-openshift-and-kubernetes-part-2%2F&amp;#38;linkname=Understanding%20Red%20Hat%20AMQ%20Streams%20components%20for%20OpenShift%20and%20Kubernetes%3A%20Part%202" title="Flipboard" rel="nofollow noopener" target="_blank"&gt;&lt;/a&gt;&lt;a class="a2a_dd addtoany_share_save addtoany_share" href="https://www.addtoany.com/share#url=https%3A%2F%2Fdevelopers.redhat.com%2Fblog%2F2019%2F12%2F05%2Funderstanding-red-hat-amq-streams-components-for-openshift-and-kubernetes-part-2%2F&amp;#038;title=Understanding%20Red%20Hat%20AMQ%20Streams%20components%20for%20OpenShift%20and%20Kubernetes%3A%20Part%202" data-a2a-url="https://developers.redhat.com/blog/2019/12/05/understanding-red-hat-amq-streams-components-for-openshift-and-kubernetes-part-2/" data-a2a-title="Understanding Red Hat AMQ Streams components for OpenShift and Kubernetes: Part 2"&gt;&lt;img src="https://static.addtoany.com/buttons/favicon.png" alt="Share"&gt;&lt;/a&gt;&lt;/p&gt;&lt;p&gt;The post &lt;a rel="nofollow" href="https://developers.redhat.com/blog/2019/12/05/understanding-red-hat-amq-streams-components-for-openshift-and-kubernetes-part-2/"&gt;Understanding Red Hat AMQ Streams components for OpenShift and Kubernetes: Part 2&lt;/a&gt; appeared first on &lt;a rel="nofollow" href="https://developers.redhat.com/blog"&gt;Red Hat Developer&lt;/a&gt;.&lt;/p&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/XV4puC8LLGM" height="1" width="1" alt=""/&gt;</content><summary>In the previous article in this series, we discussed the basics of Red Hat AMQ Streams on Red Hat OpenShift. Here are a few key points to keep in mind before we proceed: AMQ Streams is based on Apache Kafka. AMQ Streams for the OpenShift Container Platform is based on the Strimzi project. AMQ Streams on containers has multiple components, such as the Cluster Operator, Entity Operator, Mirror Maker...</summary><dc:creator>Pramod Padmanabhan</dc:creator><dc:date>2019-12-05T08:00:07Z</dc:date><feedburner:origLink>https://developers.redhat.com/blog/2019/12/05/understanding-red-hat-amq-streams-components-for-openshift-and-kubernetes-part-2/</feedburner:origLink></entry><entry><title>Narayana 5.10.1.Final released</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/-t0Osugw5bA/narayana-5101final-released.html" /><category term="feed_group_name_jbosstransactions" scheme="searchisko:content:tags" /><category term="feed_name_transactions" scheme="searchisko:content:tags" /><category term="narayana transaction manager release 5.10.1.Final" scheme="searchisko:content:tags" /><author><name>Michael Musgrove</name></author><id>searchisko:content:id:jbossorg_blog-narayana_5_10_1_final_released</id><updated>2019-12-04T15:17:33Z</updated><published>2019-12-04T15:17:00Z</published><content type="html">The team are pleased to announce our latest release of Narayana - the premier open source transaction manager.&lt;br /&gt;&lt;br /&gt;The release is available for &lt;a href="http://narayana.io/downloads/index.html"&gt;download&lt;/a&gt; from our website.&lt;br /&gt;It is a bug fix release and a list of what we fixed is available in the &lt;a href="https://issues.jboss.org/secure/ReleaseNote.jspa?projectId=12310200&amp;amp;version=12343104"&gt;release notes&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;We always generate comparative TPS figures for each release and this new release &lt;a href="https://github.com/jbosstm/artifacts/blob/master/jobs/tm-comparison/benchmark.png"&gt;performs&lt;/a&gt; favourably against other open source transaction managers.&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/-t0Osugw5bA" height="1" width="1" alt=""/&gt;</content><summary>The team are pleased to announce our latest release of Narayana - the premier open source transaction manager. The release is available for download from our website. It is a bug fix release and a list of what we fixed is available in the release notes. We always generate comparative TPS figures for each release and this new release performs favourably against other open source transaction manager...</summary><dc:creator>Michael Musgrove</dc:creator><dc:date>2019-12-04T15:17:00Z</dc:date><feedburner:origLink>http://jbossts.blogspot.com/2019/12/narayana-5101final-released.html</feedburner:origLink></entry><entry><title>Apache Camel 3 - Whats New Top 10</title><link rel="alternate" href="http://feedproxy.google.com/~r/jbossbuzz/~3/Fa5Om9oz54s/apache-camel-3-whats-new-top-10.html" /><category term="apache camel" scheme="searchisko:content:tags" /><category term="feed_group_name_fusesource" scheme="searchisko:content:tags" /><category term="feed_name_clausibsen" scheme="searchisko:content:tags" /><category term="release" scheme="searchisko:content:tags" /><category term="roadmap" scheme="searchisko:content:tags" /><author><name>Claus Ibsen</name></author><id>searchisko:content:id:jbossorg_blog-apache_camel_3_whats_new_top_10</id><updated>2019-12-04T11:02:14Z</updated><published>2019-12-04T11:01:00Z</published><content type="html">&lt;div dir="ltr" style="text-align: left;" trbidi="on"&gt;Apache Camel 3 was released last thursday November 28th 2019, which also happens to be the day of the US Thanksgiving. This was not intentionally but we can say its a big thanks from us to the community with a brand new major version of Camel - this does not come by often. In fact it's 10 years since Camel 2 hit the streets. So this 3rd generation is long overdue.&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://camel.apache.org/blog/Camel3-Whatsnew/camel3-3humps_hu7ba293cf525bac57712ef8f5199c56b4_332440_800x0_resize_q95_gaussian_2.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="687" data-original-width="800" height="274" src="https://camel.apache.org/blog/Camel3-Whatsnew/camel3-3humps_hu7ba293cf525bac57712ef8f5199c56b4_332440_800x0_resize_q95_gaussian_2.png" width="320" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;This blog post highlights the noteworthy new features and improvements in Camel v3.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;1) CAMEL IS NOW A FAMILY OF PROJECTS&lt;/b&gt;&lt;br /&gt;Apache Camel, is now a family of projects (3 at this time of writing):&lt;br /&gt;&lt;br /&gt;&lt;ul style="text-align: left;"&gt;&lt;li&gt;&lt;a href="https://github.com/apache/camel"&gt;Camel 3&lt;/a&gt;: Integration Framework Swiss knife of integration&lt;/li&gt;&lt;li&gt;&lt;a href="https://github.com/apache/camel-k/"&gt;Camel K&lt;/a&gt;: Lightweight Serverless Integration Platform Camel on Kubernetes &amp;amp; Knative&lt;/li&gt;&lt;li&gt;&lt;a href="https://github.com/apache/camel-quarkus"&gt;Camel Quarkus&lt;/a&gt;: Camel extensions for Quarkus Optimised JVM &amp;amp; Native compiled Java (GraalVM)&lt;/li&gt;&lt;/ul&gt;&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://camel.apache.org/blog/Camel3-Whatsnew/camel3-projects_hu14eb14882812af4ef4cf988ec2e12bd3_88043_800x0_resize_q95_gaussian_2.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="338" data-original-width="800" height="168" src="https://camel.apache.org/blog/Camel3-Whatsnew/camel3-projects_hu14eb14882812af4ef4cf988ec2e12bd3_88043_800x0_resize_q95_gaussian_2.png" width="400" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;The Camel code-base is very large, and we have setup sub-projects for new innovative projects using Camel. The first sub-project was to run Camel as cloud-native on Kubernetes in a serverless manner which became Camel K. Then Camel Quarkus came to make Java and Camel with very fast startup and very small memory footprint primary for container based deployments.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;2) NEW WEBSITE&lt;/b&gt;&lt;br /&gt;A major goal for Camel 3 was to finally revamp the old aging website to use modern technologies and be able to auto-generate content from the source code. This has taken years to get to this point as we have built tools over the last many Camel 2.x releases that could take us closer. At end of 2019 then the Camel community and others stepped up and provided the new art-work, logo, and look and feel for the new website - thank you very much!.&lt;br /&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://camel.apache.org/blog/Camel3-Whatsnew/camel3-website.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="372" data-original-width="800" height="185" src="https://camel.apache.org/blog/Camel3-Whatsnew/camel3-website.png" width="400" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;b&gt;&lt;br /&gt;&lt;/b&gt;For Camel 3.x we will continue to improve the website and the documentation. This is much easier for us to do, and also for people to contribute changes as its just a regular github PR to provide updates. We love contributions.&lt;br /&gt;&lt;br /&gt;&lt;br /&gt;Zoran had some fun with the new look and feel and he added a little gem; if you stare at the front page, then you should see a little animation of the curved bezel ;)&lt;br /&gt;&lt;br /&gt;&lt;b&gt;3) JAVA 11&lt;/b&gt;&lt;br /&gt;Camel 3 is the first official release that supports Java 11. Java 8 will still be supported for the first number of 3.x releases, but is expected to be dropped later in 2020. However we wanted to provide Java 8 support to help migrate Camel 2.x users whom may be restricted to Java 8 for some time to come.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;4) MODULARIZED CAMEL-CORE&lt;/b&gt;&lt;br /&gt;The camel-core has been modularized from 1 JAR to 33 JARs. The core functionality has been splitup into:&lt;br /&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;camel-api&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;camel-base&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;camel-caffeine-lrucache&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;camel-cloud&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;camel-core&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;camel-core-engine&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;camel-core-osgi&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;camel-core-xml&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;camel-endpointdsl&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;camel-headersmap&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;camel-jaxp&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;camel-main&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;camel-management-api&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;camel-management-impl&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;camel-support&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;camel-util&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;camel-util-json&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;For Camel end users then only a few JARs is relevant.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;camel-api&lt;/b&gt; contains the public API for Camel (eg interfaces such as CamelContext, Endpoint, Exchange, Message, and so on).&lt;br /&gt;&lt;br /&gt;&lt;b&gt;camel-support &lt;/b&gt;contains the base classes and RouteBuilder which you would use to build Camel routes and applications. This JAR is also contains necessary base classes for building custom Camel components, and other kinds of plugins.&lt;br /&gt;&lt;br /&gt;The components that resided in camel-core has also be externalized into individual components:&lt;br /&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;camel-bean&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;camel-log&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;camel-stub&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;camel-browse&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;camel-mock&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;camel-timer&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;camel-controlbus&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;camel-properties&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;camel-validator&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;camel-dataformat&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;camel-ref&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;camel-vm&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;camel-direct&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;camel-rest&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;camel-xpath&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;camel-directvm&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;camel-saga&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;camel-xslt&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;camel-file&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;camel-scheduler&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;camel-zip-deflater&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;camel-language&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;camel-seda&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;Camel end users can then pick and choose exactly only what they need, or keep using everything.&lt;br /&gt;&lt;br /&gt;Therefore we have camel-core and camel-core-engine as two starting dependencies. You can use camel-core which gives you all the JARs which is similar to Camel 2.x. When you use camel-core-engine you get the minimum set of JARs that makes a functional Camel.&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://camel.apache.org/blog/Camel3-Whatsnew/camel3-core-vs-engine.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="217" data-original-width="652" height="132" src="https://camel.apache.org/blog/Camel3-Whatsnew/camel3-core-vs-engine.png" width="400" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;&lt;b&gt;camel-core&lt;/b&gt; contains 33 JARs and &lt;b&gt;camel-core-engine&lt;/b&gt; contains 12 JARs.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;5) FASTER STARTUP AND LOWER FOOTPRINT&lt;/b&gt;&lt;br /&gt;We have reduced the size of core Camel and the number of classes loaded. For example in Camel 2 about 5200 classes was loaded, which has been reduced to about 4300 loaded classes in Camel 3.&lt;br /&gt;&lt;br /&gt;We have also done many smaller optimizations in the core, to reduce the number of allocated Java objects, and speeup initialization and other means. We have used JVM profiling tools to assist and find the bottlenecks.&lt;br /&gt;&lt;br /&gt;Another area of improvement is to reduce Java reflections. In Camel 2 then all the configuration of Camel components, endpoints, and routes are reflection based. In Camel 3 we have source code generated Java code for configuration that allows us to use direct Java calls instead of reflections.&lt;br /&gt;&lt;br /&gt;Another similar area is Camel’s type converters which in Camel 2 are Java reflection based (you could build custom type converts that were not reflection based). In Camel 3 we also generate Java source code which means that type converting is direct Java calls at runtime.&lt;br /&gt;&lt;br /&gt;We have also moved initialization logic to earlier phases when it was possible. For example there is a new build phase which allows Camel to do special initialization during building your project (this requires Camel Quarkus).&lt;br /&gt;&lt;br /&gt;All this optimization improves the startup performance of Camel and reduces the memory overhead. With Camel Quarkus you can natively compile your Camel application and make it startup in 30 milli seconds and consume only 10mb of memory (RSS) with a full blown HTTP REST server and health-checks and metrics.&lt;br /&gt;&lt;br /&gt;&lt;div class="separator" style="clear: both; text-align: center;"&gt;&lt;a href="https://camel.apache.org/blog/Camel3-Whatsnew/camel3-quarkus_huba2c5d62ef8e8448d234c82a5572ee1a_737648_800x0_resize_q95_gaussian_2.png" imageanchor="1" style="margin-left: 1em; margin-right: 1em;"&gt;&lt;img border="0" data-original-height="595" data-original-width="800" height="297" src="https://camel.apache.org/blog/Camel3-Whatsnew/camel3-quarkus_huba2c5d62ef8e8448d234c82a5572ee1a_737648_800x0_resize_q95_gaussian_2.png" width="400" /&gt;&lt;/a&gt;&lt;/div&gt;&lt;br /&gt;There are still a few items on the agenda that we want to work on in Camel 3.x to further optimize Camel core.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;6) TYPE SAFE ENDPOINT DSL&lt;/b&gt;&lt;br /&gt;Camel end users whom has configured endpoints using URI strings, would all have experienced the problem when you make a configuration mistake in the endpoint, which then makes Camel fail on startup.&lt;br /&gt;&lt;br /&gt;In Camel 3, we have a new type-safe DSL for endpoints which you can use in Java routes. You can continue to use the classic URI strings, but if you want to try the endpoint DSL, then you need to add camel-endpointdsl to your classpath. Then you should extend EndpointRouteBuilder instead of RouteBuilder to access the endpoint DSL.&lt;br /&gt;&lt;br /&gt;Here is a basic example without and with the endpoint DSL:&lt;br /&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;from("timer:click?period=3000&amp;amp;fixedRate=true")&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&amp;nbsp; &amp;nbsp; .to("seda:foo?blockWhenFull=true");&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&lt;br /&gt;&lt;/span&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;from(timer("click").period(3000).fixedRate(true))&lt;/span&gt;&lt;br /&gt;&lt;span style="font-family: &amp;quot;courier new&amp;quot; , &amp;quot;courier&amp;quot; , monospace;"&gt;&amp;nbsp; &amp;nbsp; .to(seda("foo").blockWhenFull(true));&lt;/span&gt;&lt;br /&gt;&lt;br /&gt;You can also find a &lt;a href="https://github.com/apache/camel/tree/master/examples/camel-example-cafe-endpointdsl"&gt;little example&lt;/a&gt; in the source code.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;7) REACTIVE ROUTING ENGINE&lt;/b&gt;&lt;br /&gt;The routing engine in Camel has internally been reactive’fied and all EIPs has been retrofitted to work in a reactive manner. However this is internal only, and the Camel API for both end users and component developers are based on existing callback behavior.&lt;br /&gt;&lt;br /&gt;We will later introduce and work on a client-side facing reactive API after we have jumped to Java 11 as minimum version (then we can support Java 9 flowable API).&lt;br /&gt;&lt;br /&gt;Camel already have integration with reactive frameworks such as Vert.X, RxJava and Reactor Core in the dedicated Camel components.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;8) CAMEL MAIN&lt;/b&gt;&lt;br /&gt;We have introduced camel-main as a standalone JAR that makes it easier to run just Camel. There are a couple of examples with the source code that demonstrates how to do that.&lt;br /&gt;&lt;br /&gt;We also use camel-main to have common code to configure and bootstrap Camel for standalone, Spring Boot, Camel K, and Camel Quarkus. This allows us to share the same code, and configuration options.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;9) CAMEL MICROPROFILE&lt;/b&gt;&lt;br /&gt;Camel 3 now integrates better with Eclipse Microprofile and we have Camel components for Microprofile configuration, metrics, health checks, and fault tolerance (on the way).&lt;br /&gt;&lt;br /&gt;More components to come in upcoming Camel releases. These microprofile components are also used by Camel Quarkus.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;10) MISCELLANEOUS IMPROVEMENTS&lt;/b&gt;&lt;br /&gt;Camel 3 now supports JUnit 5 for unit tests, with the test components that have -junit5 as suffix.&lt;br /&gt;&lt;br /&gt;The Camel Registry is now also writeable, so you can add beans to the registry at runtime, or from unit tests etc.&lt;br /&gt;&lt;br /&gt;You can also configure endpoints (producer) to lazy start. By default Camel works in a fail-fast mode, which means that Camel components that fails to connect to external systems during startup may cause the route to fail on startup. For Camel 3 you can now configure these endpoints to lazy start, which means the route will startup and they will first fail when a message is routed to the endpoint.&lt;br /&gt;&lt;br /&gt;Camel also allows to configure your routes to be supervised during startup, which allows Camel to more intelligently start routes in a more safe manner, by restarting routes that failed.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;11) MIGRATING TO CAMEL 3&lt;/b&gt;&lt;br /&gt;We have of course cleaned up the code base, such as removing all deprecated APIs and components. We have also adjusted some APIs to make them easier to use from end users, and more Java 8 lambda friendly.&lt;br /&gt;&lt;br /&gt;Internally we have also adjusted the route model, to make it easier to extend into new DSLs; and there is a YAML DSL on the way which was initiated in Camel K.&lt;br /&gt;&lt;br /&gt;In terms of backwards compatibility then Camel 3 is mostly compatibility for regular Camel applications. However if you are using some of the more advanced features and other plugins in Camel then migration is needed. Also custom components must be migrated and recompiled. There are other adjustments such as Spring Boot users must use org.apache.camel.springboot as groupId instead of org.apache.camel etc. All details can be seen in the &lt;a href="https://camel.apache.org/manual/latest/camel-3-migration-guide.html"&gt;migration guide&lt;/a&gt;.&lt;br /&gt;&lt;br /&gt;Good luck with your migration if you decide to continue your Camel journey. And for new users to Camel then good luck getting onboard.&lt;br /&gt;&lt;br /&gt;&lt;b&gt;12) BONUS: NEW COMPONENTS&lt;/b&gt;&lt;br /&gt;There are 30 net new components in Camel 3, such as more stuff for Amazon AWS, and with GraphQL, and also worthwhile to mention is integration with Debezium, which is a change data capture project to grab change events from databases.&amp;nbsp;&lt;/div&gt;&lt;div class="feedflare"&gt; &lt;a href="http://feeds.feedburner.com/~ff/ApacheCamel?a=kTqFtzpfqvU:aj7D0skvf-g:yIl2AUoC8zA"&gt;&lt;img src="http://feeds.feedburner.com/~ff/ApacheCamel?d=yIl2AUoC8zA" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/ApacheCamel?a=kTqFtzpfqvU:aj7D0skvf-g:4cEx4HpKnUU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/ApacheCamel?i=kTqFtzpfqvU:aj7D0skvf-g:4cEx4HpKnUU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/ApacheCamel?a=kTqFtzpfqvU:aj7D0skvf-g:F7zBnMyn0Lo"&gt;&lt;img src="http://feeds.feedburner.com/~ff/ApacheCamel?i=kTqFtzpfqvU:aj7D0skvf-g:F7zBnMyn0Lo" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;a href="http://feeds.feedburner.com/~ff/ApacheCamel?a=kTqFtzpfqvU:aj7D0skvf-g:V_sGLiPBpWU"&gt;&lt;img src="http://feeds.feedburner.com/~ff/ApacheCamel?i=kTqFtzpfqvU:aj7D0skvf-g:V_sGLiPBpWU" border="0"&gt;&lt;/img&gt;&lt;/a&gt; &lt;/div&gt;&lt;img src="http://feeds.feedburner.com/~r/ApacheCamel/~4/kTqFtzpfqvU" height="1" width="1" alt=""/&gt;&lt;img src="http://feeds.feedburner.com/~r/jbossbuzz/~4/Fa5Om9oz54s" height="1" width="1" alt=""/&gt;</content><summary>Apache Camel 3 was released last thursday November 28th 2019, which also happens to be the day of the US Thanksgiving. This was not intentionally but we can say its a big thanks from us to the community with a brand new major version of Camel - this does not come by often. In fact it's 10 years since Camel 2 hit the streets. So this 3rd generation is long overdue. This blog post highlights the not...</summary><dc:creator>Claus Ibsen</dc:creator><dc:date>2019-12-04T11:01:00Z</dc:date><feedburner:origLink>http://feedproxy.google.com/~r/ApacheCamel/~3/kTqFtzpfqvU/apache-camel-3-whats-new-top-10.html</feedburner:origLink></entry></feed>
